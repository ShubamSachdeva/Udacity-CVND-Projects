{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** My final architecture was a Resnet50 as CNN encoder and an single layer LSTM as RNN decoder. I also tried increasing the `num_layers` of the LSTM to $2$ and $3$ with `dropout` as $0.01$, $0.02$ and $0.03$. But,in every case the predicted captions were same for all the images. This was the reason why I finally went with the single layer LSTM architecture. \n",
    "\n",
    "I chose the `embed_size` and `hidden_size` value both of them as 512 as used in the paper [this paper](https://arxiv.org/pdf/1411.4555.pdf). I trained the model for 2 epochs. For the `epoch=1`, I used a `batch_size` as `64` and then increased to `128` for `epoch=2`. The initial `batch_size` of 64 was inspired from [this paper](https://arxiv.org/pdf/1502.03044.pdf). The training stats can be viewed for $1$st `epoch` in **training_log.txt** and $2$nd `epoch` in **training_log_4.txt**.\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** I went with the default values, since the `resnet50` architecture is trained on images of shape (224, 224, 3). I believe, if I had used a different image size, then the predictions of the encoder would have been affected. Also, I was getting pretty decent captions with the default values in the first model itself, so I did not switch. \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** Since, we are using a pretrained model for the encoder, it doesn't make sense to train them again. Although, we would like to fine tune the linear layer (`encoder.embed`) that we add to the `resnet50` architecture.\n",
    "For the decoder, since we are not using a pretrained network, we would have to train the complete decoder network(`decoder`).\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** I used `Adam` optimiser for all the model that I experimented with. The reason for using Adam is that **(1)** It can lead to convergence faster than SGD esecially in deep networks. **(2)** It uses adaptive learning rates which has found to be more efficient in updating the weights. \n",
    "\n",
    "I trained the final model for $1$st `epoch` with `learning_rate=0.001`. Then, I retrained the model for another `epoch` with `learning_rate=0.002`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=1.02s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1147/414113 [00:00<01:16, 5407.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:05<00:00, 6300.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 128         # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 1             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log_4.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [00:05<00:00, 20020235.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of steps: 3236\n"
     ]
    }
   ],
   "source": [
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "print (vocab_size)\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# loading previous models for retraining\n",
    "# encoder.load_state_dict(torch.load('./models/encoder-1.pkl'))\n",
    "# decoder.load_state_dict(torch.load('./models/decoder-1.pkl'))\n",
    "\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.002)\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)\n",
    "print ('total no of steps: {0}'.format(total_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderCNN(\n",
       "  (resnet): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (8): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  )\n",
       "  (embed): Linear(in_features=2048, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.002\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embed): Embedding(6335, 512)\n",
       "  (lstm): LSTM(512, 512, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=6335, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1/3236], Loss: 1.9984, Perplexity: 7.3770CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2/3236], Loss: 2.1711, Perplexity: 8.7683CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3/3236], Loss: 2.3664, Perplexity: 10.6592CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [4/3236], Loss: 2.0900, Perplexity: 8.0848CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [5/3236], Loss: 2.2010, Perplexity: 9.0339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [6/3236], Loss: 2.4364, Perplexity: 11.4321CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [7/3236], Loss: 2.1467, Perplexity: 8.5562CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [8/3236], Loss: 2.4034, Perplexity: 11.0612CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [9/3236], Loss: 2.1296, Perplexity: 8.4117CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [10/3236], Loss: 2.3893, Perplexity: 10.9060CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [11/3236], Loss: 2.1514, Perplexity: 8.5967CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [12/3236], Loss: 2.1030, Perplexity: 8.1911CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [13/3236], Loss: 2.1094, Perplexity: 8.2434CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [14/3236], Loss: 2.0735, Perplexity: 7.9528CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [15/3236], Loss: 2.2644, Perplexity: 9.6254CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [16/3236], Loss: 2.2713, Perplexity: 9.6923CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [17/3236], Loss: 2.2449, Perplexity: 9.4393CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [18/3236], Loss: 2.2507, Perplexity: 9.4945CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [19/3236], Loss: 2.4763, Perplexity: 11.8967CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [20/3236], Loss: 2.2886, Perplexity: 9.8613CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [21/3236], Loss: 2.2368, Perplexity: 9.3634CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [22/3236], Loss: 2.2802, Perplexity: 9.7785CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [23/3236], Loss: 2.1878, Perplexity: 8.9155CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [24/3236], Loss: 2.2956, Perplexity: 9.9300CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [25/3236], Loss: 2.1717, Perplexity: 8.7731CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [26/3236], Loss: 2.1249, Perplexity: 8.3717CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [27/3236], Loss: 2.0826, Perplexity: 8.0252CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [28/3236], Loss: 2.0998, Perplexity: 8.1642CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [29/3236], Loss: 2.1739, Perplexity: 8.7922CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [30/3236], Loss: 2.2012, Perplexity: 9.0362CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [31/3236], Loss: 1.9541, Perplexity: 7.0579CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [32/3236], Loss: 2.3185, Perplexity: 10.1600CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [33/3236], Loss: 2.2334, Perplexity: 9.3318CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [34/3236], Loss: 2.2397, Perplexity: 9.3904CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [35/3236], Loss: 2.4377, Perplexity: 11.4469CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [36/3236], Loss: 2.2409, Perplexity: 9.4019CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [37/3236], Loss: 2.2011, Perplexity: 9.0352CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [38/3236], Loss: 2.0574, Perplexity: 7.8258CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [39/3236], Loss: 2.2267, Perplexity: 9.2688CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [40/3236], Loss: 2.2318, Perplexity: 9.3170CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [41/3236], Loss: 2.2211, Perplexity: 9.2177CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [42/3236], Loss: 2.2436, Perplexity: 9.4268CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [43/3236], Loss: 2.0178, Perplexity: 7.5218CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [44/3236], Loss: 2.1559, Perplexity: 8.6354CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [45/3236], Loss: 2.8475, Perplexity: 17.2439CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [46/3236], Loss: 2.4283, Perplexity: 11.3400CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [47/3236], Loss: 2.3181, Perplexity: 10.1567CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [48/3236], Loss: 2.1999, Perplexity: 9.0240CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [49/3236], Loss: 2.1219, Perplexity: 8.3469CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [50/3236], Loss: 2.2061, Perplexity: 9.0803CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [51/3236], Loss: 2.2628, Perplexity: 9.6096CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [52/3236], Loss: 2.2418, Perplexity: 9.4102CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [53/3236], Loss: 2.1931, Perplexity: 8.9632CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [54/3236], Loss: 2.3076, Perplexity: 10.0500CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [55/3236], Loss: 2.8603, Perplexity: 17.4663CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [56/3236], Loss: 2.5378, Perplexity: 12.6521CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [57/3236], Loss: 2.3924, Perplexity: 10.9392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [58/3236], Loss: 2.5355, Perplexity: 12.6227CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [59/3236], Loss: 2.1593, Perplexity: 8.6648CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [60/3236], Loss: 2.4018, Perplexity: 11.0434CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [61/3236], Loss: 2.0877, Perplexity: 8.0662CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [62/3236], Loss: 2.3490, Perplexity: 10.4754CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [63/3236], Loss: 2.2699, Perplexity: 9.6787CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [64/3236], Loss: 2.1559, Perplexity: 8.6352CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [65/3236], Loss: 2.3503, Perplexity: 10.4890CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [66/3236], Loss: 2.2798, Perplexity: 9.7752CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [67/3236], Loss: 2.3153, Perplexity: 10.1282CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [68/3236], Loss: 2.3015, Perplexity: 9.9891CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [69/3236], Loss: 2.0769, Perplexity: 7.9799CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [70/3236], Loss: 2.1851, Perplexity: 8.8911CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [71/3236], Loss: 2.1888, Perplexity: 8.9248CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [72/3236], Loss: 2.1708, Perplexity: 8.7657CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [73/3236], Loss: 2.1677, Perplexity: 8.7380CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [74/3236], Loss: 2.4695, Perplexity: 11.8167CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [75/3236], Loss: 2.1868, Perplexity: 8.9066CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [76/3236], Loss: 2.4818, Perplexity: 11.9626CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [77/3236], Loss: 2.2576, Perplexity: 9.5604CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [78/3236], Loss: 2.1250, Perplexity: 8.3727CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [79/3236], Loss: 2.1533, Perplexity: 8.6131CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [80/3236], Loss: 2.8826, Perplexity: 17.8604CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [81/3236], Loss: 2.2636, Perplexity: 9.6179CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [82/3236], Loss: 2.3818, Perplexity: 10.8244CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [83/3236], Loss: 2.1043, Perplexity: 8.2015CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [84/3236], Loss: 2.1989, Perplexity: 9.0151CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [85/3236], Loss: 2.0714, Perplexity: 7.9362CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [86/3236], Loss: 2.2419, Perplexity: 9.4116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [87/3236], Loss: 2.1835, Perplexity: 8.8777CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [88/3236], Loss: 2.2020, Perplexity: 9.0430CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [89/3236], Loss: 2.1623, Perplexity: 8.6915CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [90/3236], Loss: 2.0256, Perplexity: 7.5807CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [91/3236], Loss: 2.5922, Perplexity: 13.3592CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [92/3236], Loss: 2.1627, Perplexity: 8.6944CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [93/3236], Loss: 2.4315, Perplexity: 11.3758CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [94/3236], Loss: 2.2470, Perplexity: 9.4592CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [95/3236], Loss: 2.6360, Perplexity: 13.9575CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [96/3236], Loss: 2.2073, Perplexity: 9.0909CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [97/3236], Loss: 2.0868, Perplexity: 8.0588CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [98/3236], Loss: 2.0563, Perplexity: 7.8172CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [99/3236], Loss: 2.2088, Perplexity: 9.1048CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [100/3236], Loss: 2.2579, Perplexity: 9.5630\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [101/3236], Loss: 2.2441, Perplexity: 9.4319CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [102/3236], Loss: 3.0277, Perplexity: 20.6500CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [103/3236], Loss: 2.0520, Perplexity: 7.7833CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [104/3236], Loss: 2.2070, Perplexity: 9.0885CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [105/3236], Loss: 2.2853, Perplexity: 9.8284CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [106/3236], Loss: 2.2231, Perplexity: 9.2363CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [107/3236], Loss: 2.5203, Perplexity: 12.4320CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [108/3236], Loss: 2.2884, Perplexity: 9.8587CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [109/3236], Loss: 2.2113, Perplexity: 9.1278CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [110/3236], Loss: 2.2747, Perplexity: 9.7249CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [111/3236], Loss: 2.2457, Perplexity: 9.4471CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [112/3236], Loss: 2.2452, Perplexity: 9.4425CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [113/3236], Loss: 2.2042, Perplexity: 9.0634CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [114/3236], Loss: 2.0908, Perplexity: 8.0913CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [115/3236], Loss: 2.1809, Perplexity: 8.8543CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [116/3236], Loss: 2.2494, Perplexity: 9.4817CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [117/3236], Loss: 2.1724, Perplexity: 8.7797CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [118/3236], Loss: 2.2783, Perplexity: 9.7597CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [119/3236], Loss: 2.1764, Perplexity: 8.8147CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [120/3236], Loss: 2.2009, Perplexity: 9.0329CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [121/3236], Loss: 2.4898, Perplexity: 12.0589CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [122/3236], Loss: 2.0708, Perplexity: 7.9312CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [123/3236], Loss: 2.1169, Perplexity: 8.3051CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [124/3236], Loss: 2.1038, Perplexity: 8.1973CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [125/3236], Loss: 2.9515, Perplexity: 19.1355CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [126/3236], Loss: 2.2203, Perplexity: 9.2098CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [127/3236], Loss: 2.3491, Perplexity: 10.4760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [128/3236], Loss: 2.2218, Perplexity: 9.2237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [129/3236], Loss: 2.0777, Perplexity: 7.9857CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [130/3236], Loss: 2.1739, Perplexity: 8.7924CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [131/3236], Loss: 2.4793, Perplexity: 11.9335CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [132/3236], Loss: 2.2394, Perplexity: 9.3876CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [133/3236], Loss: 2.2095, Perplexity: 9.1110CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [134/3236], Loss: 2.1817, Perplexity: 8.8614CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [135/3236], Loss: 2.2042, Perplexity: 9.0631CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [136/3236], Loss: 2.2874, Perplexity: 9.8496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [137/3236], Loss: 2.8547, Perplexity: 17.3699CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [138/3236], Loss: 2.1836, Perplexity: 8.8784CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [139/3236], Loss: 2.0950, Perplexity: 8.1258CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [140/3236], Loss: 2.2102, Perplexity: 9.1178CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [141/3236], Loss: 2.3003, Perplexity: 9.9767CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [142/3236], Loss: 2.3651, Perplexity: 10.6452CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [143/3236], Loss: 2.3804, Perplexity: 10.8092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [144/3236], Loss: 2.0377, Perplexity: 7.6730CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [145/3236], Loss: 2.0605, Perplexity: 7.8496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [146/3236], Loss: 2.3275, Perplexity: 10.2528CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [147/3236], Loss: 2.2698, Perplexity: 9.6771CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [148/3236], Loss: 2.1081, Perplexity: 8.2324CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [149/3236], Loss: 2.3508, Perplexity: 10.4939CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [150/3236], Loss: 2.4599, Perplexity: 11.7034CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [151/3236], Loss: 2.1240, Perplexity: 8.3644CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [152/3236], Loss: 2.1473, Perplexity: 8.5621CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [153/3236], Loss: 2.4461, Perplexity: 11.5435CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [154/3236], Loss: 2.1282, Perplexity: 8.3997CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [155/3236], Loss: 2.3686, Perplexity: 10.6828CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [156/3236], Loss: 2.1747, Perplexity: 8.7997CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [157/3236], Loss: 2.2916, Perplexity: 9.8905CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [158/3236], Loss: 2.3091, Perplexity: 10.0653CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [159/3236], Loss: 2.1311, Perplexity: 8.4245CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [160/3236], Loss: 2.1756, Perplexity: 8.8071CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [161/3236], Loss: 2.1195, Perplexity: 8.3268CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [162/3236], Loss: 2.1593, Perplexity: 8.6654CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [163/3236], Loss: 2.2249, Perplexity: 9.2528CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [164/3236], Loss: 2.1852, Perplexity: 8.8927CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [165/3236], Loss: 2.0367, Perplexity: 7.6650CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [166/3236], Loss: 2.2321, Perplexity: 9.3199CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [167/3236], Loss: 2.0179, Perplexity: 7.5227CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [168/3236], Loss: 2.1404, Perplexity: 8.5026CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [169/3236], Loss: 2.1386, Perplexity: 8.4878CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [170/3236], Loss: 2.0587, Perplexity: 7.8354CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [171/3236], Loss: 2.2898, Perplexity: 9.8733CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [172/3236], Loss: 2.1861, Perplexity: 8.9002CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [173/3236], Loss: 2.2566, Perplexity: 9.5503CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [174/3236], Loss: 2.7830, Perplexity: 16.1679CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [175/3236], Loss: 2.2197, Perplexity: 9.2045CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [176/3236], Loss: 2.1202, Perplexity: 8.3324CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [177/3236], Loss: 2.3001, Perplexity: 9.9752CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [178/3236], Loss: 2.6229, Perplexity: 13.7751CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [179/3236], Loss: 2.1415, Perplexity: 8.5121CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [180/3236], Loss: 2.1198, Perplexity: 8.3297CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [181/3236], Loss: 2.0858, Perplexity: 8.0510CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [182/3236], Loss: 2.3825, Perplexity: 10.8316CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [183/3236], Loss: 2.0014, Perplexity: 7.3991CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [184/3236], Loss: 2.1573, Perplexity: 8.6474CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [185/3236], Loss: 2.5335, Perplexity: 12.5972CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [186/3236], Loss: 2.1890, Perplexity: 8.9258CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [187/3236], Loss: 2.0820, Perplexity: 8.0204CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [188/3236], Loss: 2.9390, Perplexity: 18.8978CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [189/3236], Loss: 2.2108, Perplexity: 9.1231CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [190/3236], Loss: 2.0433, Perplexity: 7.7158CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [191/3236], Loss: 2.1975, Perplexity: 9.0028CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [192/3236], Loss: 2.2306, Perplexity: 9.3057CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [193/3236], Loss: 2.0790, Perplexity: 7.9967CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [194/3236], Loss: 2.2337, Perplexity: 9.3341CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [195/3236], Loss: 2.1588, Perplexity: 8.6609CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [196/3236], Loss: 2.0673, Perplexity: 7.9036CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [197/3236], Loss: 2.5255, Perplexity: 12.4976CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [198/3236], Loss: 2.1263, Perplexity: 8.3835CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [199/3236], Loss: 2.0838, Perplexity: 8.0349CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [200/3236], Loss: 2.1895, Perplexity: 8.9306\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [201/3236], Loss: 2.1603, Perplexity: 8.6739CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [202/3236], Loss: 2.2056, Perplexity: 9.0761CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [203/3236], Loss: 2.2282, Perplexity: 9.2831CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [204/3236], Loss: 2.1832, Perplexity: 8.8751CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [205/3236], Loss: 2.1275, Perplexity: 8.3939CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [206/3236], Loss: 2.3284, Perplexity: 10.2612CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [207/3236], Loss: 2.0918, Perplexity: 8.0996CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [208/3236], Loss: 2.0929, Perplexity: 8.1085CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [209/3236], Loss: 2.2368, Perplexity: 9.3630CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [210/3236], Loss: 1.9970, Perplexity: 7.3672CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [211/3236], Loss: 2.4838, Perplexity: 11.9863CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [212/3236], Loss: 2.8009, Perplexity: 16.4594CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [213/3236], Loss: 2.0686, Perplexity: 7.9141CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [214/3236], Loss: 2.0194, Perplexity: 7.5336CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [215/3236], Loss: 2.0622, Perplexity: 7.8631CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [216/3236], Loss: 2.1137, Perplexity: 8.2787CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [217/3236], Loss: 2.0471, Perplexity: 7.7458CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [218/3236], Loss: 2.2260, Perplexity: 9.2625CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [219/3236], Loss: 2.2874, Perplexity: 9.8493CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [220/3236], Loss: 2.0549, Perplexity: 7.8062CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [221/3236], Loss: 2.2127, Perplexity: 9.1405CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [222/3236], Loss: 2.4760, Perplexity: 11.8937CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [223/3236], Loss: 2.3147, Perplexity: 10.1222CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [224/3236], Loss: 2.4740, Perplexity: 11.8695CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [225/3236], Loss: 2.0538, Perplexity: 7.7979CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [226/3236], Loss: 2.1108, Perplexity: 8.2550CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [227/3236], Loss: 2.0842, Perplexity: 8.0378CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [228/3236], Loss: 2.1955, Perplexity: 8.9849CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [229/3236], Loss: 2.2412, Perplexity: 9.4044CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [230/3236], Loss: 2.2303, Perplexity: 9.3023CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [231/3236], Loss: 2.0606, Perplexity: 7.8505CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [232/3236], Loss: 2.3076, Perplexity: 10.0500CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [233/3236], Loss: 2.1110, Perplexity: 8.2563CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [234/3236], Loss: 2.4679, Perplexity: 11.7982CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [235/3236], Loss: 2.1360, Perplexity: 8.4658CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [236/3236], Loss: 2.1287, Perplexity: 8.4038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [237/3236], Loss: 2.1699, Perplexity: 8.7570CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [238/3236], Loss: 2.1263, Perplexity: 8.3836CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [239/3236], Loss: 2.1652, Perplexity: 8.7164CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [240/3236], Loss: 2.2667, Perplexity: 9.6480CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [241/3236], Loss: 2.1370, Perplexity: 8.4740CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [242/3236], Loss: 2.3428, Perplexity: 10.4105CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [243/3236], Loss: 2.6364, Perplexity: 13.9633CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [244/3236], Loss: 2.3796, Perplexity: 10.8008CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [245/3236], Loss: 2.5295, Perplexity: 12.5473CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [246/3236], Loss: 2.5010, Perplexity: 12.1948CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [247/3236], Loss: 2.0748, Perplexity: 7.9630CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [248/3236], Loss: 2.0717, Perplexity: 7.9384CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [249/3236], Loss: 2.1449, Perplexity: 8.5414CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [250/3236], Loss: 2.1647, Perplexity: 8.7117CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [251/3236], Loss: 2.2679, Perplexity: 9.6594CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [252/3236], Loss: 2.7301, Perplexity: 15.3339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [253/3236], Loss: 3.0062, Perplexity: 20.2102CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [254/3236], Loss: 2.1949, Perplexity: 8.9789CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [255/3236], Loss: 2.4259, Perplexity: 11.3126CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [256/3236], Loss: 2.1881, Perplexity: 8.9183CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [257/3236], Loss: 2.1253, Perplexity: 8.3756CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [258/3236], Loss: 2.3050, Perplexity: 10.0239CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [259/3236], Loss: 2.4745, Perplexity: 11.8756CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [260/3236], Loss: 2.2176, Perplexity: 9.1852CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [261/3236], Loss: 2.2739, Perplexity: 9.7171CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [262/3236], Loss: 2.2002, Perplexity: 9.0271CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [263/3236], Loss: 2.0742, Perplexity: 7.9582CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [264/3236], Loss: 2.1884, Perplexity: 8.9213CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [265/3236], Loss: 2.3008, Perplexity: 9.9818CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [266/3236], Loss: 2.1213, Perplexity: 8.3420CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [267/3236], Loss: 2.4050, Perplexity: 11.0780CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [268/3236], Loss: 2.1762, Perplexity: 8.8126CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [269/3236], Loss: 2.2788, Perplexity: 9.7651CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [270/3236], Loss: 2.3092, Perplexity: 10.0659CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [271/3236], Loss: 2.0948, Perplexity: 8.1239CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [272/3236], Loss: 2.1251, Perplexity: 8.3734CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [273/3236], Loss: 2.7873, Perplexity: 16.2371CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [274/3236], Loss: 2.1473, Perplexity: 8.5614CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [275/3236], Loss: 3.0842, Perplexity: 21.8509CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [276/3236], Loss: 2.1784, Perplexity: 8.8320CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [277/3236], Loss: 2.2725, Perplexity: 9.7038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [278/3236], Loss: 2.3420, Perplexity: 10.4017CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [279/3236], Loss: 2.1904, Perplexity: 8.9384CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [280/3236], Loss: 2.0607, Perplexity: 7.8512CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [281/3236], Loss: 2.0906, Perplexity: 8.0900CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [282/3236], Loss: 2.4868, Perplexity: 12.0227CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [283/3236], Loss: 2.1804, Perplexity: 8.8496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [284/3236], Loss: 2.2517, Perplexity: 9.5035CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [285/3236], Loss: 2.1711, Perplexity: 8.7677CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [286/3236], Loss: 2.2459, Perplexity: 9.4493CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [287/3236], Loss: 2.1717, Perplexity: 8.7732CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [288/3236], Loss: 2.0720, Perplexity: 7.9408CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [289/3236], Loss: 2.1949, Perplexity: 8.9792CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [290/3236], Loss: 1.9944, Perplexity: 7.3477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [291/3236], Loss: 2.1206, Perplexity: 8.3365CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [292/3236], Loss: 2.0722, Perplexity: 7.9423CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [293/3236], Loss: 2.3207, Perplexity: 10.1827CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [294/3236], Loss: 2.2620, Perplexity: 9.6021CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [295/3236], Loss: 2.3053, Perplexity: 10.0277CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [296/3236], Loss: 2.1391, Perplexity: 8.4918CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [297/3236], Loss: 2.2185, Perplexity: 9.1936CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [298/3236], Loss: 2.2496, Perplexity: 9.4842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [299/3236], Loss: 2.2913, Perplexity: 9.8874CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [300/3236], Loss: 2.4333, Perplexity: 11.3963\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [301/3236], Loss: 2.1153, Perplexity: 8.2923CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [302/3236], Loss: 2.2974, Perplexity: 9.9480CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [303/3236], Loss: 2.1574, Perplexity: 8.6485CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [304/3236], Loss: 2.1590, Perplexity: 8.6627CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [305/3236], Loss: 2.2459, Perplexity: 9.4491CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [306/3236], Loss: 2.3319, Perplexity: 10.2978CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [307/3236], Loss: 2.3173, Perplexity: 10.1478CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [308/3236], Loss: 2.4773, Perplexity: 11.9091CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [309/3236], Loss: 2.2514, Perplexity: 9.5006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [310/3236], Loss: 2.1131, Perplexity: 8.2737CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [311/3236], Loss: 2.2733, Perplexity: 9.7110CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [312/3236], Loss: 2.3000, Perplexity: 9.9737CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [313/3236], Loss: 2.1234, Perplexity: 8.3598CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [314/3236], Loss: 2.3832, Perplexity: 10.8393CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [315/3236], Loss: 2.7320, Perplexity: 15.3638CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [316/3236], Loss: 2.1765, Perplexity: 8.8158CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [317/3236], Loss: 2.4819, Perplexity: 11.9635CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [318/3236], Loss: 2.0650, Perplexity: 7.8851CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [319/3236], Loss: 2.6058, Perplexity: 13.5414CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [320/3236], Loss: 2.2435, Perplexity: 9.4262CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [321/3236], Loss: 2.1737, Perplexity: 8.7906CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [322/3236], Loss: 2.5645, Perplexity: 12.9941CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [323/3236], Loss: 2.2611, Perplexity: 9.5938CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [324/3236], Loss: 2.3098, Perplexity: 10.0726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [325/3236], Loss: 2.2136, Perplexity: 9.1489CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [326/3236], Loss: 2.1044, Perplexity: 8.2022CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [327/3236], Loss: 2.0703, Perplexity: 7.9276CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [328/3236], Loss: 2.1489, Perplexity: 8.5753CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [329/3236], Loss: 2.0678, Perplexity: 7.9076CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [330/3236], Loss: 1.9988, Perplexity: 7.3799CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [331/3236], Loss: 2.2341, Perplexity: 9.3384CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [332/3236], Loss: 2.1809, Perplexity: 8.8546CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [333/3236], Loss: 2.1636, Perplexity: 8.7022CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [334/3236], Loss: 2.2723, Perplexity: 9.7018CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [335/3236], Loss: 2.1867, Perplexity: 8.9058CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [336/3236], Loss: 2.1258, Perplexity: 8.3792CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [337/3236], Loss: 2.4737, Perplexity: 11.8664CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [338/3236], Loss: 2.1933, Perplexity: 8.9647CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [339/3236], Loss: 2.1215, Perplexity: 8.3434CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [340/3236], Loss: 2.1575, Perplexity: 8.6495CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [341/3236], Loss: 2.3002, Perplexity: 9.9757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [342/3236], Loss: 1.9571, Perplexity: 7.0790CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [343/3236], Loss: 2.0776, Perplexity: 7.9855CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [344/3236], Loss: 2.1431, Perplexity: 8.5259CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [345/3236], Loss: 2.0640, Perplexity: 7.8776CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [346/3236], Loss: 2.2228, Perplexity: 9.2328CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [347/3236], Loss: 2.0135, Perplexity: 7.4894CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [348/3236], Loss: 2.2025, Perplexity: 9.0475CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [349/3236], Loss: 2.0210, Perplexity: 7.5459CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [350/3236], Loss: 2.1885, Perplexity: 8.9215CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [351/3236], Loss: 2.2886, Perplexity: 9.8615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [352/3236], Loss: 2.1863, Perplexity: 8.9022CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [353/3236], Loss: 2.2586, Perplexity: 9.5694CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [354/3236], Loss: 2.8965, Perplexity: 18.1115CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [355/3236], Loss: 2.6669, Perplexity: 14.3951CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [356/3236], Loss: 2.3062, Perplexity: 10.0359CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [357/3236], Loss: 2.3426, Perplexity: 10.4085CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [358/3236], Loss: 2.0804, Perplexity: 8.0077CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [359/3236], Loss: 2.1768, Perplexity: 8.8183CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [360/3236], Loss: 2.2208, Perplexity: 9.2149CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [361/3236], Loss: 2.1656, Perplexity: 8.7199CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [362/3236], Loss: 2.0894, Perplexity: 8.0799CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [363/3236], Loss: 2.1683, Perplexity: 8.7438CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [364/3236], Loss: 2.6091, Perplexity: 13.5864CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [365/3236], Loss: 2.1189, Perplexity: 8.3216CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [366/3236], Loss: 2.1676, Perplexity: 8.7376CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [367/3236], Loss: 2.0267, Perplexity: 7.5888CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [368/3236], Loss: 2.0402, Perplexity: 7.6920CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [369/3236], Loss: 2.1810, Perplexity: 8.8552CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [370/3236], Loss: 2.1456, Perplexity: 8.5471CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [371/3236], Loss: 2.1234, Perplexity: 8.3594CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [372/3236], Loss: 2.2526, Perplexity: 9.5127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [373/3236], Loss: 2.1917, Perplexity: 8.9508CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 27])\n",
      "Epoch [1/1], Step [374/3236], Loss: 3.0528, Perplexity: 21.1741CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [375/3236], Loss: 2.1086, Perplexity: 8.2365CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [376/3236], Loss: 2.5597, Perplexity: 12.9318CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [377/3236], Loss: 2.3789, Perplexity: 10.7929CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [378/3236], Loss: 2.0956, Perplexity: 8.1306CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [379/3236], Loss: 2.2620, Perplexity: 9.6023CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [380/3236], Loss: 2.0766, Perplexity: 7.9770CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [381/3236], Loss: 2.0095, Perplexity: 7.4593CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [382/3236], Loss: 2.2597, Perplexity: 9.5801CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [383/3236], Loss: 2.2050, Perplexity: 9.0704CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [384/3236], Loss: 2.0564, Perplexity: 7.8178CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [385/3236], Loss: 2.1635, Perplexity: 8.7016CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [386/3236], Loss: 2.0256, Perplexity: 7.5806CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [387/3236], Loss: 2.5790, Perplexity: 13.1837CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [388/3236], Loss: 2.4281, Perplexity: 11.3372CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [389/3236], Loss: 2.2104, Perplexity: 9.1189CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [390/3236], Loss: 2.1441, Perplexity: 8.5343CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [391/3236], Loss: 2.1742, Perplexity: 8.7950CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [392/3236], Loss: 2.0839, Perplexity: 8.0354CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [393/3236], Loss: 2.2551, Perplexity: 9.5361CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [394/3236], Loss: 2.0671, Perplexity: 7.9021CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [395/3236], Loss: 2.0455, Perplexity: 7.7329CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [396/3236], Loss: 2.0681, Perplexity: 7.9100CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [397/3236], Loss: 2.1165, Perplexity: 8.3023CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [398/3236], Loss: 2.1624, Perplexity: 8.6918CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [399/3236], Loss: 1.9984, Perplexity: 7.3773CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [400/3236], Loss: 2.0270, Perplexity: 7.5914\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [401/3236], Loss: 2.1809, Perplexity: 8.8540CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [402/3236], Loss: 2.0948, Perplexity: 8.1239CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [403/3236], Loss: 2.1669, Perplexity: 8.7314CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [404/3236], Loss: 2.4933, Perplexity: 12.1006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [405/3236], Loss: 2.1529, Perplexity: 8.6097CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [406/3236], Loss: 2.1132, Perplexity: 8.2747CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [407/3236], Loss: 2.3779, Perplexity: 10.7821CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [408/3236], Loss: 2.0495, Perplexity: 7.7641CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [409/3236], Loss: 2.2363, Perplexity: 9.3589CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [410/3236], Loss: 2.2097, Perplexity: 9.1129CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [411/3236], Loss: 2.0952, Perplexity: 8.1267CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [412/3236], Loss: 2.2960, Perplexity: 9.9340CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [413/3236], Loss: 2.4416, Perplexity: 11.4919CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [414/3236], Loss: 2.0878, Perplexity: 8.0673CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [415/3236], Loss: 2.3143, Perplexity: 10.1180CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [416/3236], Loss: 2.1308, Perplexity: 8.4219CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [417/3236], Loss: 2.4759, Perplexity: 11.8921CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [418/3236], Loss: 2.1314, Perplexity: 8.4265CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [419/3236], Loss: 2.0756, Perplexity: 7.9690CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [420/3236], Loss: 2.1950, Perplexity: 8.9802CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [421/3236], Loss: 2.0188, Perplexity: 7.5292CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [422/3236], Loss: 2.3051, Perplexity: 10.0252CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [423/3236], Loss: 2.1599, Perplexity: 8.6700CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [424/3236], Loss: 1.9945, Perplexity: 7.3487CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [425/3236], Loss: 2.0886, Perplexity: 8.0732CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [426/3236], Loss: 2.0525, Perplexity: 7.7877CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [427/3236], Loss: 1.9729, Perplexity: 7.1918CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [428/3236], Loss: 2.0765, Perplexity: 7.9765CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [429/3236], Loss: 2.0956, Perplexity: 8.1299CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [430/3236], Loss: 2.0499, Perplexity: 7.7672CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [431/3236], Loss: 2.0839, Perplexity: 8.0354CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [432/3236], Loss: 2.1748, Perplexity: 8.8008CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [433/3236], Loss: 2.2638, Perplexity: 9.6193CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [434/3236], Loss: 2.0235, Perplexity: 7.5650CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [435/3236], Loss: 2.1407, Perplexity: 8.5054CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [436/3236], Loss: 2.0965, Perplexity: 8.1379CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [437/3236], Loss: 2.0300, Perplexity: 7.6140CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [438/3236], Loss: 2.9353, Perplexity: 18.8274CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [439/3236], Loss: 2.1745, Perplexity: 8.7980CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [440/3236], Loss: 2.4832, Perplexity: 11.9800CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [441/3236], Loss: 2.1874, Perplexity: 8.9118CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [442/3236], Loss: 1.9286, Perplexity: 6.8800CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [443/3236], Loss: 2.2666, Perplexity: 9.6463CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [444/3236], Loss: 2.1543, Perplexity: 8.6221CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [445/3236], Loss: 2.0565, Perplexity: 7.8187CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [446/3236], Loss: 2.2531, Perplexity: 9.5174CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [447/3236], Loss: 2.0220, Perplexity: 7.5534CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [448/3236], Loss: 2.2534, Perplexity: 9.5204CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [449/3236], Loss: 1.9896, Perplexity: 7.3129CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [450/3236], Loss: 2.0815, Perplexity: 8.0167CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [451/3236], Loss: 2.0336, Perplexity: 7.6418CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [452/3236], Loss: 2.0483, Perplexity: 7.7545CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [453/3236], Loss: 2.1528, Perplexity: 8.6089CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [454/3236], Loss: 2.0826, Perplexity: 8.0253CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [455/3236], Loss: 2.0959, Perplexity: 8.1329CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [456/3236], Loss: 2.0665, Perplexity: 7.8969CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [457/3236], Loss: 2.6240, Perplexity: 13.7903CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [458/3236], Loss: 2.2451, Perplexity: 9.4417CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [459/3236], Loss: 2.0348, Perplexity: 7.6509CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [460/3236], Loss: 2.2352, Perplexity: 9.3486CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [461/3236], Loss: 2.0573, Perplexity: 7.8246CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [462/3236], Loss: 2.1816, Perplexity: 8.8609CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [463/3236], Loss: 2.1325, Perplexity: 8.4355CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [464/3236], Loss: 2.1376, Perplexity: 8.4789CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [465/3236], Loss: 2.1186, Perplexity: 8.3197CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [466/3236], Loss: 2.0926, Perplexity: 8.1063CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [467/3236], Loss: 2.1904, Perplexity: 8.9386CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [468/3236], Loss: 2.1340, Perplexity: 8.4482CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [469/3236], Loss: 2.3210, Perplexity: 10.1861CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [470/3236], Loss: 2.2110, Perplexity: 9.1250CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [471/3236], Loss: 2.2270, Perplexity: 9.2717CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [472/3236], Loss: 2.1571, Perplexity: 8.6459CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [473/3236], Loss: 2.9201, Perplexity: 18.5425CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [474/3236], Loss: 2.1546, Perplexity: 8.6242CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [475/3236], Loss: 2.1293, Perplexity: 8.4092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [476/3236], Loss: 2.1743, Perplexity: 8.7964CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [477/3236], Loss: 2.0942, Perplexity: 8.1187CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [478/3236], Loss: 2.0350, Perplexity: 7.6521CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [479/3236], Loss: 2.7848, Perplexity: 16.1967CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [480/3236], Loss: 2.1676, Perplexity: 8.7370CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [481/3236], Loss: 2.3785, Perplexity: 10.7885CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [482/3236], Loss: 2.1994, Perplexity: 9.0200CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [483/3236], Loss: 2.0650, Perplexity: 7.8855CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [484/3236], Loss: 2.0990, Perplexity: 8.1583CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [485/3236], Loss: 2.1037, Perplexity: 8.1965CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [486/3236], Loss: 2.2922, Perplexity: 9.8971CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [487/3236], Loss: 2.1116, Perplexity: 8.2613CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [488/3236], Loss: 1.9585, Perplexity: 7.0885CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [489/3236], Loss: 2.1603, Perplexity: 8.6740CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [490/3236], Loss: 2.1230, Perplexity: 8.3562CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [491/3236], Loss: 2.1645, Perplexity: 8.7105CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [492/3236], Loss: 2.6028, Perplexity: 13.5020CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [493/3236], Loss: 2.2828, Perplexity: 9.8044CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [494/3236], Loss: 2.2694, Perplexity: 9.6736CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [495/3236], Loss: 2.1193, Perplexity: 8.3254CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [496/3236], Loss: 2.0631, Perplexity: 7.8703CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [497/3236], Loss: 2.1833, Perplexity: 8.8757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [498/3236], Loss: 2.1151, Perplexity: 8.2907CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [499/3236], Loss: 2.1008, Perplexity: 8.1726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [500/3236], Loss: 2.0735, Perplexity: 7.9529\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [501/3236], Loss: 2.0956, Perplexity: 8.1301CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [502/3236], Loss: 2.1051, Perplexity: 8.2079CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [503/3236], Loss: 2.1878, Perplexity: 8.9156CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [504/3236], Loss: 2.0474, Perplexity: 7.7475CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [505/3236], Loss: 2.0830, Perplexity: 8.0283CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [506/3236], Loss: 2.2378, Perplexity: 9.3725CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [507/3236], Loss: 2.1956, Perplexity: 8.9857CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [508/3236], Loss: 2.1381, Perplexity: 8.4836CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [509/3236], Loss: 1.9341, Perplexity: 6.9176CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [510/3236], Loss: 2.5014, Perplexity: 12.2002CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [511/3236], Loss: 2.0860, Perplexity: 8.0525CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [512/3236], Loss: 2.0360, Perplexity: 7.6600CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [513/3236], Loss: 2.0787, Perplexity: 7.9938CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [514/3236], Loss: 2.3541, Perplexity: 10.5284CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [515/3236], Loss: 2.2870, Perplexity: 9.8450CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [516/3236], Loss: 2.0905, Perplexity: 8.0886CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [517/3236], Loss: 2.1596, Perplexity: 8.6673CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [518/3236], Loss: 2.2736, Perplexity: 9.7142CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [519/3236], Loss: 2.1085, Perplexity: 8.2356CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [520/3236], Loss: 2.1317, Perplexity: 8.4293CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [521/3236], Loss: 2.1208, Perplexity: 8.3378CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [522/3236], Loss: 2.0340, Perplexity: 7.6449CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [523/3236], Loss: 2.2044, Perplexity: 9.0644CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [524/3236], Loss: 2.2227, Perplexity: 9.2322CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [525/3236], Loss: 2.0003, Perplexity: 7.3915CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [526/3236], Loss: 2.4417, Perplexity: 11.4925CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [527/3236], Loss: 2.1918, Perplexity: 8.9509CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [528/3236], Loss: 2.1251, Perplexity: 8.3734CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [529/3236], Loss: 2.2444, Perplexity: 9.4352CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [530/3236], Loss: 2.1179, Perplexity: 8.3137CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [531/3236], Loss: 2.0385, Perplexity: 7.6789CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [532/3236], Loss: 2.1072, Perplexity: 8.2251CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [533/3236], Loss: 2.1092, Perplexity: 8.2419CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [534/3236], Loss: 2.4642, Perplexity: 11.7539CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [535/3236], Loss: 2.3537, Perplexity: 10.5246CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [536/3236], Loss: 2.1103, Perplexity: 8.2504CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [537/3236], Loss: 2.5302, Perplexity: 12.5556CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [538/3236], Loss: 2.3527, Perplexity: 10.5144CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [539/3236], Loss: 2.1427, Perplexity: 8.5225CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [540/3236], Loss: 2.2139, Perplexity: 9.1516CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [541/3236], Loss: 2.0713, Perplexity: 7.9352CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [542/3236], Loss: 2.0681, Perplexity: 7.9099CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [543/3236], Loss: 2.0842, Perplexity: 8.0381CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [544/3236], Loss: 2.2123, Perplexity: 9.1369CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [545/3236], Loss: 2.1852, Perplexity: 8.8926CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [546/3236], Loss: 2.2370, Perplexity: 9.3651CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [547/3236], Loss: 2.1875, Perplexity: 8.9127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [548/3236], Loss: 2.0749, Perplexity: 7.9635CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [549/3236], Loss: 2.0256, Perplexity: 7.5804CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [550/3236], Loss: 2.4196, Perplexity: 11.2411CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [551/3236], Loss: 2.3794, Perplexity: 10.7986CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [552/3236], Loss: 2.1259, Perplexity: 8.3804CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [553/3236], Loss: 2.1069, Perplexity: 8.2223CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [554/3236], Loss: 2.2949, Perplexity: 9.9233CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [555/3236], Loss: 2.0045, Perplexity: 7.4220CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [556/3236], Loss: 2.5177, Perplexity: 12.4006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [557/3236], Loss: 2.0377, Perplexity: 7.6727CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [558/3236], Loss: 2.1115, Perplexity: 8.2608CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [559/3236], Loss: 2.0777, Perplexity: 7.9864CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [560/3236], Loss: 2.2034, Perplexity: 9.0557CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [561/3236], Loss: 2.2454, Perplexity: 9.4446CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [562/3236], Loss: 2.1854, Perplexity: 8.8941CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [563/3236], Loss: 2.2676, Perplexity: 9.6562CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [564/3236], Loss: 2.2307, Perplexity: 9.3065CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [565/3236], Loss: 2.2237, Perplexity: 9.2412CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [566/3236], Loss: 2.1811, Perplexity: 8.8556CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [567/3236], Loss: 2.3217, Perplexity: 10.1934CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [568/3236], Loss: 2.2590, Perplexity: 9.5736CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [569/3236], Loss: 2.4350, Perplexity: 11.4160CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [570/3236], Loss: 2.1682, Perplexity: 8.7424CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [571/3236], Loss: 2.1884, Perplexity: 8.9207CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [572/3236], Loss: 2.9383, Perplexity: 18.8839CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [573/3236], Loss: 2.4425, Perplexity: 11.5021CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [574/3236], Loss: 2.1017, Perplexity: 8.1800CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [575/3236], Loss: 2.5115, Perplexity: 12.3237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [576/3236], Loss: 2.0795, Perplexity: 8.0009CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [577/3236], Loss: 2.1003, Perplexity: 8.1682CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [578/3236], Loss: 2.3108, Perplexity: 10.0827CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [579/3236], Loss: 2.0572, Perplexity: 7.8237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [580/3236], Loss: 2.8300, Perplexity: 16.9457CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [581/3236], Loss: 2.0678, Perplexity: 7.9075CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [582/3236], Loss: 2.8098, Perplexity: 16.6061CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [583/3236], Loss: 1.9970, Perplexity: 7.3670CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [584/3236], Loss: 2.2432, Perplexity: 9.4231CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [585/3236], Loss: 2.1713, Perplexity: 8.7695CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [586/3236], Loss: 2.2449, Perplexity: 9.4392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [587/3236], Loss: 2.1158, Perplexity: 8.2963CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [588/3236], Loss: 2.0714, Perplexity: 7.9360CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [589/3236], Loss: 2.1416, Perplexity: 8.5131CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [590/3236], Loss: 2.3892, Perplexity: 10.9049CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [591/3236], Loss: 2.2176, Perplexity: 9.1855CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [592/3236], Loss: 2.4138, Perplexity: 11.1759CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [593/3236], Loss: 2.6843, Perplexity: 14.6482CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [594/3236], Loss: 2.1651, Perplexity: 8.7155CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [595/3236], Loss: 2.4835, Perplexity: 11.9829CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [596/3236], Loss: 2.0916, Perplexity: 8.0980CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [597/3236], Loss: 2.0506, Perplexity: 7.7726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [598/3236], Loss: 2.2990, Perplexity: 9.9646CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [599/3236], Loss: 2.2168, Perplexity: 9.1777CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [600/3236], Loss: 2.7624, Perplexity: 15.8383\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [601/3236], Loss: 2.2069, Perplexity: 9.0871CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [602/3236], Loss: 2.2316, Perplexity: 9.3149CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [603/3236], Loss: 2.0357, Perplexity: 7.6573CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [604/3236], Loss: 2.3726, Perplexity: 10.7252CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [605/3236], Loss: 2.0005, Perplexity: 7.3929CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [606/3236], Loss: 2.1081, Perplexity: 8.2324CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [607/3236], Loss: 2.2081, Perplexity: 9.0985CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [608/3236], Loss: 2.2542, Perplexity: 9.5280CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [609/3236], Loss: 2.2534, Perplexity: 9.5203CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [610/3236], Loss: 2.0724, Perplexity: 7.9438CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [611/3236], Loss: 2.1629, Perplexity: 8.6963CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [612/3236], Loss: 2.8055, Perplexity: 16.5353CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [613/3236], Loss: 2.0238, Perplexity: 7.5667CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [614/3236], Loss: 2.4909, Perplexity: 12.0723CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [615/3236], Loss: 2.0489, Perplexity: 7.7595CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [616/3236], Loss: 2.0487, Perplexity: 7.7579CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [617/3236], Loss: 2.2192, Perplexity: 9.1996CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [618/3236], Loss: 2.1356, Perplexity: 8.4620CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [619/3236], Loss: 2.1397, Perplexity: 8.4968CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [620/3236], Loss: 2.1066, Perplexity: 8.2203CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [621/3236], Loss: 2.2554, Perplexity: 9.5392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [622/3236], Loss: 2.0946, Perplexity: 8.1221CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [623/3236], Loss: 2.1289, Perplexity: 8.4058CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [624/3236], Loss: 2.2216, Perplexity: 9.2222CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [625/3236], Loss: 2.0576, Perplexity: 7.8271CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [626/3236], Loss: 2.1709, Perplexity: 8.7665CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [627/3236], Loss: 2.2974, Perplexity: 9.9482CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [628/3236], Loss: 2.1835, Perplexity: 8.8775CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [629/3236], Loss: 1.9721, Perplexity: 7.1856CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [630/3236], Loss: 1.9495, Perplexity: 7.0249CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [631/3236], Loss: 2.1076, Perplexity: 8.2282CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [632/3236], Loss: 2.1970, Perplexity: 8.9982CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [633/3236], Loss: 2.3286, Perplexity: 10.2633CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [634/3236], Loss: 2.0899, Perplexity: 8.0839CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [635/3236], Loss: 2.1722, Perplexity: 8.7774CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [636/3236], Loss: 2.4661, Perplexity: 11.7762CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [637/3236], Loss: 2.3680, Perplexity: 10.6757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [638/3236], Loss: 2.3203, Perplexity: 10.1783CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [639/3236], Loss: 2.1150, Perplexity: 8.2898CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [640/3236], Loss: 2.2317, Perplexity: 9.3156CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [641/3236], Loss: 2.0891, Perplexity: 8.0773CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [642/3236], Loss: 2.1250, Perplexity: 8.3730CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [643/3236], Loss: 2.1122, Perplexity: 8.2660CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [644/3236], Loss: 2.1059, Perplexity: 8.2149CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [645/3236], Loss: 2.2825, Perplexity: 9.8013CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [646/3236], Loss: 2.1302, Perplexity: 8.4163CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [647/3236], Loss: 2.3142, Perplexity: 10.1165CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [648/3236], Loss: 2.0201, Perplexity: 7.5388CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [649/3236], Loss: 2.0838, Perplexity: 8.0348CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [650/3236], Loss: 2.4389, Perplexity: 11.4601CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [651/3236], Loss: 2.2213, Perplexity: 9.2192CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [652/3236], Loss: 2.1855, Perplexity: 8.8947CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [653/3236], Loss: 2.0780, Perplexity: 7.9887CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [654/3236], Loss: 2.1876, Perplexity: 8.9134CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [655/3236], Loss: 2.5051, Perplexity: 12.2449CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [656/3236], Loss: 2.5678, Perplexity: 13.0366CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [657/3236], Loss: 2.1915, Perplexity: 8.9490CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [658/3236], Loss: 2.1484, Perplexity: 8.5708CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [659/3236], Loss: 2.0303, Perplexity: 7.6164CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [660/3236], Loss: 2.3620, Perplexity: 10.6125CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [661/3236], Loss: 2.1959, Perplexity: 8.9879CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [662/3236], Loss: 2.4289, Perplexity: 11.3463CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [663/3236], Loss: 1.9621, Perplexity: 7.1144CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [664/3236], Loss: 2.0559, Perplexity: 7.8140CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [665/3236], Loss: 2.1763, Perplexity: 8.8137CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [666/3236], Loss: 2.0882, Perplexity: 8.0704CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [667/3236], Loss: 2.1634, Perplexity: 8.7006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [668/3236], Loss: 2.2505, Perplexity: 9.4923CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [669/3236], Loss: 2.1069, Perplexity: 8.2230CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [670/3236], Loss: 2.2637, Perplexity: 9.6182CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [671/3236], Loss: 1.9264, Perplexity: 6.8646CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [672/3236], Loss: 2.1946, Perplexity: 8.9761CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [673/3236], Loss: 2.1870, Perplexity: 8.9083CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [674/3236], Loss: 2.4887, Perplexity: 12.0455CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [675/3236], Loss: 2.0889, Perplexity: 8.0762CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [676/3236], Loss: 2.0535, Perplexity: 7.7952CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [677/3236], Loss: 2.3138, Perplexity: 10.1133CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [678/3236], Loss: 2.0044, Perplexity: 7.4218CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [679/3236], Loss: 2.1266, Perplexity: 8.3864CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [680/3236], Loss: 2.0575, Perplexity: 7.8262CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [681/3236], Loss: 2.2725, Perplexity: 9.7033CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [682/3236], Loss: 2.3990, Perplexity: 11.0127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [683/3236], Loss: 2.1323, Perplexity: 8.4341CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [684/3236], Loss: 2.1263, Perplexity: 8.3834CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [685/3236], Loss: 2.1330, Perplexity: 8.4399CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [686/3236], Loss: 2.0514, Perplexity: 7.7792CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [687/3236], Loss: 2.0663, Perplexity: 7.8954CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [688/3236], Loss: 2.2366, Perplexity: 9.3615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [689/3236], Loss: 2.1946, Perplexity: 8.9765CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [690/3236], Loss: 2.1188, Perplexity: 8.3208CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [691/3236], Loss: 2.1651, Perplexity: 8.7151CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [692/3236], Loss: 1.9509, Perplexity: 7.0347CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [693/3236], Loss: 2.0650, Perplexity: 7.8853CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [694/3236], Loss: 2.0780, Perplexity: 7.9886CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [695/3236], Loss: 2.1040, Perplexity: 8.1985CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [696/3236], Loss: 2.0565, Perplexity: 7.8189CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [697/3236], Loss: 2.6890, Perplexity: 14.7172CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [698/3236], Loss: 2.4900, Perplexity: 12.0615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [699/3236], Loss: 2.5078, Perplexity: 12.2776CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [700/3236], Loss: 2.2465, Perplexity: 9.4547\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [701/3236], Loss: 2.0600, Perplexity: 7.8460CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [702/3236], Loss: 1.9414, Perplexity: 6.9682CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [703/3236], Loss: 2.0627, Perplexity: 7.8671CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [704/3236], Loss: 2.0637, Perplexity: 7.8751CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [705/3236], Loss: 2.1134, Perplexity: 8.2759CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [706/3236], Loss: 2.2072, Perplexity: 9.0903CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [707/3236], Loss: 2.1373, Perplexity: 8.4767CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [708/3236], Loss: 2.1043, Perplexity: 8.2012CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [709/3236], Loss: 2.2322, Perplexity: 9.3207CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [710/3236], Loss: 2.0635, Perplexity: 7.8737CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [711/3236], Loss: 2.1164, Perplexity: 8.3012CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [712/3236], Loss: 2.2457, Perplexity: 9.4473CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [713/3236], Loss: 2.1664, Perplexity: 8.7271CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [714/3236], Loss: 2.3272, Perplexity: 10.2496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [715/3236], Loss: 2.1582, Perplexity: 8.6555CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [716/3236], Loss: 2.3493, Perplexity: 10.4778CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [717/3236], Loss: 2.2891, Perplexity: 9.8664CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [718/3236], Loss: 2.0748, Perplexity: 7.9628CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [719/3236], Loss: 2.3099, Perplexity: 10.0731CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [720/3236], Loss: 2.0421, Perplexity: 7.7070CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [721/3236], Loss: 2.0736, Perplexity: 7.9538CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [722/3236], Loss: 2.5048, Perplexity: 12.2417CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [723/3236], Loss: 2.1186, Perplexity: 8.3194CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 31])\n",
      "Epoch [1/1], Step [724/3236], Loss: 3.5721, Perplexity: 35.5924CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [725/3236], Loss: 2.9228, Perplexity: 18.5931CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [726/3236], Loss: 2.2299, Perplexity: 9.2985CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [727/3236], Loss: 2.0834, Perplexity: 8.0314CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [728/3236], Loss: 2.2172, Perplexity: 9.1816CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [729/3236], Loss: 2.2312, Perplexity: 9.3107CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [730/3236], Loss: 2.1707, Perplexity: 8.7646CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [731/3236], Loss: 2.2840, Perplexity: 9.8159CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [732/3236], Loss: 2.0448, Perplexity: 7.7273CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [733/3236], Loss: 2.2554, Perplexity: 9.5389CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [734/3236], Loss: 2.1201, Perplexity: 8.3323CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [735/3236], Loss: 2.1447, Perplexity: 8.5392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [736/3236], Loss: 2.2175, Perplexity: 9.1840CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [737/3236], Loss: 2.0966, Perplexity: 8.1389CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [738/3236], Loss: 2.0712, Perplexity: 7.9339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [739/3236], Loss: 2.1070, Perplexity: 8.2233CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [740/3236], Loss: 2.1991, Perplexity: 9.0166CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [741/3236], Loss: 2.1880, Perplexity: 8.9173CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [742/3236], Loss: 2.0935, Perplexity: 8.1130CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [743/3236], Loss: 2.0096, Perplexity: 7.4604CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [744/3236], Loss: 2.1485, Perplexity: 8.5716CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [745/3236], Loss: 1.9605, Perplexity: 7.1029CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [746/3236], Loss: 2.0546, Perplexity: 7.8034CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [747/3236], Loss: 2.4526, Perplexity: 11.6183CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [748/3236], Loss: 2.1271, Perplexity: 8.3902CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [749/3236], Loss: 2.1436, Perplexity: 8.5297CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [750/3236], Loss: 2.0538, Perplexity: 7.7971CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [751/3236], Loss: 2.0715, Perplexity: 7.9366CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [752/3236], Loss: 2.1211, Perplexity: 8.3406CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [753/3236], Loss: 2.1815, Perplexity: 8.8599CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [754/3236], Loss: 2.1143, Perplexity: 8.2842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [755/3236], Loss: 2.0339, Perplexity: 7.6440CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [756/3236], Loss: 2.5611, Perplexity: 12.9497CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [757/3236], Loss: 2.4680, Perplexity: 11.7991CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [758/3236], Loss: 2.0747, Perplexity: 7.9621CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [759/3236], Loss: 2.0571, Perplexity: 7.8231CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [760/3236], Loss: 2.0538, Perplexity: 7.7975CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [761/3236], Loss: 2.1132, Perplexity: 8.2746CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [762/3236], Loss: 2.1524, Perplexity: 8.6057CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 24])\n",
      "Epoch [1/1], Step [763/3236], Loss: 3.2501, Perplexity: 25.7925CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [764/3236], Loss: 2.1586, Perplexity: 8.6591CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [765/3236], Loss: 2.3890, Perplexity: 10.9027CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [766/3236], Loss: 2.0331, Perplexity: 7.6381CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [767/3236], Loss: 2.4082, Perplexity: 11.1141CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [768/3236], Loss: 2.0425, Perplexity: 7.7097CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [769/3236], Loss: 2.0861, Perplexity: 8.0536CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [770/3236], Loss: 2.1119, Perplexity: 8.2636CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [771/3236], Loss: 2.1261, Perplexity: 8.3818CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [772/3236], Loss: 2.1834, Perplexity: 8.8767CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [773/3236], Loss: 2.0695, Perplexity: 7.9209CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [774/3236], Loss: 2.2873, Perplexity: 9.8480CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [775/3236], Loss: 2.2347, Perplexity: 9.3438CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [776/3236], Loss: 2.2370, Perplexity: 9.3650CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [777/3236], Loss: 2.0943, Perplexity: 8.1200CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [778/3236], Loss: 2.2004, Perplexity: 9.0285CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [779/3236], Loss: 2.4399, Perplexity: 11.4717CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [780/3236], Loss: 2.0499, Perplexity: 7.7669CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [781/3236], Loss: 2.3680, Perplexity: 10.6764CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [782/3236], Loss: 1.9974, Perplexity: 7.3701CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [783/3236], Loss: 2.0651, Perplexity: 7.8861CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [784/3236], Loss: 2.0451, Perplexity: 7.7297CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [785/3236], Loss: 2.1095, Perplexity: 8.2445CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [786/3236], Loss: 2.1505, Perplexity: 8.5889CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [787/3236], Loss: 2.0210, Perplexity: 7.5460CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [788/3236], Loss: 2.2252, Perplexity: 9.2550CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [789/3236], Loss: 2.7790, Perplexity: 16.1028CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [790/3236], Loss: 2.2739, Perplexity: 9.7176CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [791/3236], Loss: 2.0245, Perplexity: 7.5726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [792/3236], Loss: 2.1580, Perplexity: 8.6538CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [793/3236], Loss: 2.1409, Perplexity: 8.5071CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [794/3236], Loss: 2.0844, Perplexity: 8.0401CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [795/3236], Loss: 2.6825, Perplexity: 14.6218CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [796/3236], Loss: 2.1024, Perplexity: 8.1858CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [797/3236], Loss: 2.1098, Perplexity: 8.2463CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [798/3236], Loss: 2.2458, Perplexity: 9.4483CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [799/3236], Loss: 2.2164, Perplexity: 9.1745CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [800/3236], Loss: 2.0515, Perplexity: 7.7794\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [801/3236], Loss: 2.0549, Perplexity: 7.8059CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [802/3236], Loss: 2.0886, Perplexity: 8.0733CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [803/3236], Loss: 2.0555, Perplexity: 7.8110CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [804/3236], Loss: 2.1951, Perplexity: 8.9812CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [805/3236], Loss: 2.5154, Perplexity: 12.3717CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [806/3236], Loss: 2.5523, Perplexity: 12.8367CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [807/3236], Loss: 1.9509, Perplexity: 7.0348CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [808/3236], Loss: 2.0392, Perplexity: 7.6846CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [809/3236], Loss: 2.1823, Perplexity: 8.8666CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [810/3236], Loss: 2.1513, Perplexity: 8.5958CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [811/3236], Loss: 2.1963, Perplexity: 8.9917CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [812/3236], Loss: 2.0922, Perplexity: 8.1023CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [813/3236], Loss: 2.5942, Perplexity: 13.3860CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [814/3236], Loss: 2.1356, Perplexity: 8.4625CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [815/3236], Loss: 2.1292, Perplexity: 8.4077CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [816/3236], Loss: 2.0788, Perplexity: 7.9953CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [817/3236], Loss: 2.2160, Perplexity: 9.1709CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [818/3236], Loss: 2.0608, Perplexity: 7.8526CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [819/3236], Loss: 2.1638, Perplexity: 8.7041CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [820/3236], Loss: 2.7126, Perplexity: 15.0691CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [821/3236], Loss: 2.0860, Perplexity: 8.0523CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [822/3236], Loss: 2.2975, Perplexity: 9.9493CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [823/3236], Loss: 2.1867, Perplexity: 8.9055CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [824/3236], Loss: 2.8441, Perplexity: 17.1864CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [825/3236], Loss: 2.1110, Perplexity: 8.2565CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [826/3236], Loss: 2.0110, Perplexity: 7.4711CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [827/3236], Loss: 2.1578, Perplexity: 8.6520CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [828/3236], Loss: 1.9334, Perplexity: 6.9127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [829/3236], Loss: 2.0444, Perplexity: 7.7246CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [830/3236], Loss: 2.4679, Perplexity: 11.7973CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [831/3236], Loss: 2.4218, Perplexity: 11.2662CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [832/3236], Loss: 2.1744, Perplexity: 8.7969CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [833/3236], Loss: 2.0700, Perplexity: 7.9245CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [834/3236], Loss: 2.0391, Perplexity: 7.6837CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [835/3236], Loss: 2.0665, Perplexity: 7.8972CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [836/3236], Loss: 2.1578, Perplexity: 8.6519CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [837/3236], Loss: 2.1904, Perplexity: 8.9384CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [838/3236], Loss: 2.1842, Perplexity: 8.8838CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [839/3236], Loss: 2.0027, Perplexity: 7.4093CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [840/3236], Loss: 2.0385, Perplexity: 7.6793CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [841/3236], Loss: 2.0375, Perplexity: 7.6711CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [842/3236], Loss: 2.1088, Perplexity: 8.2386CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [843/3236], Loss: 2.2151, Perplexity: 9.1625CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [844/3236], Loss: 2.2800, Perplexity: 9.7769CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [845/3236], Loss: 2.2484, Perplexity: 9.4728CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [846/3236], Loss: 2.1049, Perplexity: 8.2061CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [847/3236], Loss: 2.2240, Perplexity: 9.2440CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [848/3236], Loss: 2.6573, Perplexity: 14.2572CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [849/3236], Loss: 2.0697, Perplexity: 7.9223CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [850/3236], Loss: 2.1130, Perplexity: 8.2734CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [851/3236], Loss: 2.1799, Perplexity: 8.8456CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [852/3236], Loss: 2.1048, Perplexity: 8.2056CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [853/3236], Loss: 2.0200, Perplexity: 7.5383CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [854/3236], Loss: 2.0195, Perplexity: 7.5349CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [855/3236], Loss: 2.0859, Perplexity: 8.0519CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [856/3236], Loss: 2.1379, Perplexity: 8.4816CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [857/3236], Loss: 2.1467, Perplexity: 8.5569CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [858/3236], Loss: 2.1939, Perplexity: 8.9700CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [859/3236], Loss: 2.4403, Perplexity: 11.4765CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [860/3236], Loss: 2.0871, Perplexity: 8.0615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [861/3236], Loss: 2.2010, Perplexity: 9.0338CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [862/3236], Loss: 2.0127, Perplexity: 7.4832CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [863/3236], Loss: 1.9989, Perplexity: 7.3812CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [864/3236], Loss: 2.2370, Perplexity: 9.3649CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [865/3236], Loss: 2.2601, Perplexity: 9.5844CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [866/3236], Loss: 2.1560, Perplexity: 8.6365CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [867/3236], Loss: 2.2062, Perplexity: 9.0809CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [868/3236], Loss: 2.0263, Perplexity: 7.5862CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [869/3236], Loss: 2.6638, Perplexity: 14.3501CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [870/3236], Loss: 2.0486, Perplexity: 7.7567CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [871/3236], Loss: 2.3441, Perplexity: 10.4243CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [872/3236], Loss: 2.2588, Perplexity: 9.5718CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [873/3236], Loss: 2.0399, Perplexity: 7.6899CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [874/3236], Loss: 2.0003, Perplexity: 7.3913CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [875/3236], Loss: 2.2162, Perplexity: 9.1726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [876/3236], Loss: 2.4797, Perplexity: 11.9380CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [877/3236], Loss: 2.0899, Perplexity: 8.0839CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [878/3236], Loss: 2.1505, Perplexity: 8.5896CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [879/3236], Loss: 2.4018, Perplexity: 11.0434CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [880/3236], Loss: 2.1173, Perplexity: 8.3087CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [881/3236], Loss: 1.9200, Perplexity: 6.8207CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [882/3236], Loss: 2.0476, Perplexity: 7.7496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [883/3236], Loss: 2.0656, Perplexity: 7.8901CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [884/3236], Loss: 2.2203, Perplexity: 9.2098CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [885/3236], Loss: 2.1211, Perplexity: 8.3404CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [886/3236], Loss: 2.0818, Perplexity: 8.0188CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [887/3236], Loss: 2.0294, Perplexity: 7.6092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [888/3236], Loss: 2.7134, Perplexity: 15.0809CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [889/3236], Loss: 2.1041, Perplexity: 8.1994CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [890/3236], Loss: 2.2634, Perplexity: 9.6153CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [891/3236], Loss: 2.1232, Perplexity: 8.3576CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [892/3236], Loss: 2.1948, Perplexity: 8.9785CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [893/3236], Loss: 2.0971, Perplexity: 8.1429CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [894/3236], Loss: 2.1899, Perplexity: 8.9339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [895/3236], Loss: 2.7553, Perplexity: 15.7263CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [896/3236], Loss: 2.1479, Perplexity: 8.5666CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [897/3236], Loss: 1.9858, Perplexity: 7.2846CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [898/3236], Loss: 2.2011, Perplexity: 9.0353CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [899/3236], Loss: 2.1171, Perplexity: 8.3069CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [900/3236], Loss: 2.0121, Perplexity: 7.4788\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [901/3236], Loss: 2.1606, Perplexity: 8.6764CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [902/3236], Loss: 2.0496, Perplexity: 7.7645CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [903/3236], Loss: 2.1647, Perplexity: 8.7119CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [904/3236], Loss: 2.0469, Perplexity: 7.7435CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [905/3236], Loss: 2.1854, Perplexity: 8.8941CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [906/3236], Loss: 2.4456, Perplexity: 11.5376CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [907/3236], Loss: 2.3676, Perplexity: 10.6718CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [908/3236], Loss: 2.2217, Perplexity: 9.2234CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [909/3236], Loss: 2.5372, Perplexity: 12.6439CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [910/3236], Loss: 2.1138, Perplexity: 8.2795CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [911/3236], Loss: 2.0576, Perplexity: 7.8268CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [912/3236], Loss: 2.0523, Perplexity: 7.7860CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [913/3236], Loss: 2.1532, Perplexity: 8.6127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [914/3236], Loss: 2.0365, Perplexity: 7.6641CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [915/3236], Loss: 2.2987, Perplexity: 9.9611CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [916/3236], Loss: 2.4073, Perplexity: 11.1040CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [917/3236], Loss: 2.1933, Perplexity: 8.9644CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [918/3236], Loss: 2.1096, Perplexity: 8.2454CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [919/3236], Loss: 2.3557, Perplexity: 10.5452CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [920/3236], Loss: 2.1273, Perplexity: 8.3925CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [921/3236], Loss: 2.0882, Perplexity: 8.0700CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [922/3236], Loss: 2.3539, Perplexity: 10.5260CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [923/3236], Loss: 2.1248, Perplexity: 8.3713CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [924/3236], Loss: 2.4434, Perplexity: 11.5118CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [925/3236], Loss: 2.1286, Perplexity: 8.4035CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [926/3236], Loss: 2.0842, Perplexity: 8.0386CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [927/3236], Loss: 2.4809, Perplexity: 11.9520CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [928/3236], Loss: 2.1069, Perplexity: 8.2230CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [929/3236], Loss: 2.1510, Perplexity: 8.5934CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [930/3236], Loss: 2.1819, Perplexity: 8.8628CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [931/3236], Loss: 2.2382, Perplexity: 9.3762CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [932/3236], Loss: 2.3260, Perplexity: 10.2369CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [933/3236], Loss: 2.1928, Perplexity: 8.9600CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [934/3236], Loss: 2.0620, Perplexity: 7.8613CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [935/3236], Loss: 2.1531, Perplexity: 8.6116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [936/3236], Loss: 2.1040, Perplexity: 8.1990CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [937/3236], Loss: 2.0012, Perplexity: 7.3981CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [938/3236], Loss: 2.0230, Perplexity: 7.5607CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [939/3236], Loss: 2.0873, Perplexity: 8.0627CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [940/3236], Loss: 2.0797, Perplexity: 8.0023CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [941/3236], Loss: 2.0381, Perplexity: 7.6758CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [942/3236], Loss: 2.2095, Perplexity: 9.1111CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [943/3236], Loss: 2.0847, Perplexity: 8.0422CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [944/3236], Loss: 2.1105, Perplexity: 8.2523CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [945/3236], Loss: 2.3063, Perplexity: 10.0373CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [946/3236], Loss: 2.0485, Perplexity: 7.7560CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [947/3236], Loss: 2.1797, Perplexity: 8.8441CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [948/3236], Loss: 2.1932, Perplexity: 8.9636CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [949/3236], Loss: 2.1911, Perplexity: 8.9448CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [950/3236], Loss: 2.1571, Perplexity: 8.6463CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [951/3236], Loss: 2.1360, Perplexity: 8.4659CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [952/3236], Loss: 2.0240, Perplexity: 7.5688CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [953/3236], Loss: 2.4053, Perplexity: 11.0822CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [954/3236], Loss: 2.1847, Perplexity: 8.8881CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [955/3236], Loss: 2.1192, Perplexity: 8.3249CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [956/3236], Loss: 1.9834, Perplexity: 7.2677CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [957/3236], Loss: 2.7611, Perplexity: 15.8173CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [958/3236], Loss: 1.8960, Perplexity: 6.6590CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [959/3236], Loss: 2.0566, Perplexity: 7.8191CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [960/3236], Loss: 2.3356, Perplexity: 10.3355CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [961/3236], Loss: 2.0941, Perplexity: 8.1181CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [962/3236], Loss: 2.0901, Perplexity: 8.0858CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [963/3236], Loss: 2.0982, Perplexity: 8.1512CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [964/3236], Loss: 2.1290, Perplexity: 8.4061CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [965/3236], Loss: 2.2193, Perplexity: 9.2013CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [966/3236], Loss: 1.9971, Perplexity: 7.3674CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [967/3236], Loss: 2.2530, Perplexity: 9.5164CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [968/3236], Loss: 2.4332, Perplexity: 11.3948CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [969/3236], Loss: 2.0788, Perplexity: 7.9952CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [970/3236], Loss: 2.1003, Perplexity: 8.1682CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [971/3236], Loss: 2.0785, Perplexity: 7.9925CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [972/3236], Loss: 2.1645, Perplexity: 8.7102CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [973/3236], Loss: 1.9937, Perplexity: 7.3425CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [974/3236], Loss: 2.3096, Perplexity: 10.0705CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [975/3236], Loss: 2.2233, Perplexity: 9.2377CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [976/3236], Loss: 2.2062, Perplexity: 9.0808CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [977/3236], Loss: 2.0929, Perplexity: 8.1081CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [978/3236], Loss: 2.5452, Perplexity: 12.7454CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [979/3236], Loss: 2.1038, Perplexity: 8.1969CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [980/3236], Loss: 1.9809, Perplexity: 7.2492CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [981/3236], Loss: 2.0741, Perplexity: 7.9571CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [982/3236], Loss: 2.2251, Perplexity: 9.2540CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [983/3236], Loss: 2.1061, Perplexity: 8.2162CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [984/3236], Loss: 2.0429, Perplexity: 7.7127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [985/3236], Loss: 1.9196, Perplexity: 6.8185CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [986/3236], Loss: 2.2041, Perplexity: 9.0624CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [987/3236], Loss: 2.0483, Perplexity: 7.7544CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [988/3236], Loss: 1.9872, Perplexity: 7.2954CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [989/3236], Loss: 2.0825, Perplexity: 8.0246CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [990/3236], Loss: 2.0069, Perplexity: 7.4399CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [991/3236], Loss: 2.7667, Perplexity: 15.9059CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [992/3236], Loss: 1.9706, Perplexity: 7.1751CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [993/3236], Loss: 2.0259, Perplexity: 7.5832CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [994/3236], Loss: 2.2215, Perplexity: 9.2208CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [995/3236], Loss: 2.0727, Perplexity: 7.9463CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [996/3236], Loss: 2.0968, Perplexity: 8.1403CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [997/3236], Loss: 1.9785, Perplexity: 7.2321CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [998/3236], Loss: 2.0072, Perplexity: 7.4422CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [999/3236], Loss: 2.1837, Perplexity: 8.8791CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1000/3236], Loss: 2.3785, Perplexity: 10.7887\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1001/3236], Loss: 2.1203, Perplexity: 8.3340CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1002/3236], Loss: 2.1131, Perplexity: 8.2737CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1003/3236], Loss: 2.0584, Perplexity: 7.8333CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1004/3236], Loss: 2.0729, Perplexity: 7.9477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1005/3236], Loss: 2.1820, Perplexity: 8.8640CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1006/3236], Loss: 2.1854, Perplexity: 8.8943CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1007/3236], Loss: 2.2806, Perplexity: 9.7822CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1008/3236], Loss: 2.1086, Perplexity: 8.2368CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1009/3236], Loss: 2.3929, Perplexity: 10.9457CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1010/3236], Loss: 2.3328, Perplexity: 10.3069CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1011/3236], Loss: 2.3174, Perplexity: 10.1492CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1012/3236], Loss: 2.1705, Perplexity: 8.7629CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1013/3236], Loss: 1.9844, Perplexity: 7.2749CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1014/3236], Loss: 2.1087, Perplexity: 8.2374CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1015/3236], Loss: 2.1001, Perplexity: 8.1668CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1016/3236], Loss: 1.9941, Perplexity: 7.3459CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1017/3236], Loss: 2.0173, Perplexity: 7.5182CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1018/3236], Loss: 2.2245, Perplexity: 9.2486CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [1019/3236], Loss: 2.5918, Perplexity: 13.3537CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1020/3236], Loss: 2.3643, Perplexity: 10.6370CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1021/3236], Loss: 2.0714, Perplexity: 7.9362CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1022/3236], Loss: 2.1608, Perplexity: 8.6779CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1023/3236], Loss: 2.1796, Perplexity: 8.8426CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1024/3236], Loss: 2.1899, Perplexity: 8.9346CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [1025/3236], Loss: 2.8019, Perplexity: 16.4760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1026/3236], Loss: 2.0627, Perplexity: 7.8670CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1027/3236], Loss: 1.9936, Perplexity: 7.3421CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1028/3236], Loss: 2.1131, Perplexity: 8.2741CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1029/3236], Loss: 2.1153, Perplexity: 8.2919CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1030/3236], Loss: 2.2908, Perplexity: 9.8826CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1031/3236], Loss: 2.2000, Perplexity: 9.0249CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [1032/3236], Loss: 2.9849, Perplexity: 19.7853CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1033/3236], Loss: 2.2479, Perplexity: 9.4676CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1034/3236], Loss: 1.9035, Perplexity: 6.7093CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1035/3236], Loss: 2.1687, Perplexity: 8.7473CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1036/3236], Loss: 2.1213, Perplexity: 8.3419CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1037/3236], Loss: 2.4520, Perplexity: 11.6114CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1038/3236], Loss: 2.0429, Perplexity: 7.7131CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1039/3236], Loss: 2.1984, Perplexity: 9.0105CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1040/3236], Loss: 2.0970, Perplexity: 8.1418CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1041/3236], Loss: 2.2976, Perplexity: 9.9501CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1042/3236], Loss: 1.9944, Perplexity: 7.3477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1043/3236], Loss: 2.1716, Perplexity: 8.7721CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [1044/3236], Loss: 2.5478, Perplexity: 12.7795CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1045/3236], Loss: 2.1328, Perplexity: 8.4388CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1046/3236], Loss: 2.1818, Perplexity: 8.8620CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1047/3236], Loss: 2.1774, Perplexity: 8.8233CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1048/3236], Loss: 2.1329, Perplexity: 8.4393CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1049/3236], Loss: 2.4068, Perplexity: 11.0981CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1050/3236], Loss: 2.2733, Perplexity: 9.7118CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1051/3236], Loss: 2.0962, Perplexity: 8.1352CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1052/3236], Loss: 2.1132, Perplexity: 8.2747CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1053/3236], Loss: 2.0328, Perplexity: 7.6355CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1054/3236], Loss: 2.1517, Perplexity: 8.5990CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1055/3236], Loss: 2.1318, Perplexity: 8.4296CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1056/3236], Loss: 2.2547, Perplexity: 9.5325CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1057/3236], Loss: 2.6165, Perplexity: 13.6876CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1058/3236], Loss: 2.1373, Perplexity: 8.4765CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1059/3236], Loss: 2.1174, Perplexity: 8.3092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1060/3236], Loss: 2.2496, Perplexity: 9.4843CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1061/3236], Loss: 2.0149, Perplexity: 7.4997CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1062/3236], Loss: 2.0736, Perplexity: 7.9535CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1063/3236], Loss: 2.0939, Perplexity: 8.1162CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1064/3236], Loss: 2.2189, Perplexity: 9.1969CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1065/3236], Loss: 2.0414, Perplexity: 7.7017CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1066/3236], Loss: 2.2752, Perplexity: 9.7295CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1067/3236], Loss: 2.2539, Perplexity: 9.5245CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1068/3236], Loss: 1.9849, Perplexity: 7.2787CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1069/3236], Loss: 2.0475, Perplexity: 7.7487CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1070/3236], Loss: 2.2943, Perplexity: 9.9175CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1071/3236], Loss: 2.2769, Perplexity: 9.7461CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1072/3236], Loss: 2.1921, Perplexity: 8.9539CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1073/3236], Loss: 2.1409, Perplexity: 8.5068CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1074/3236], Loss: 2.1353, Perplexity: 8.4595CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1075/3236], Loss: 2.1611, Perplexity: 8.6809CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1076/3236], Loss: 2.0646, Perplexity: 7.8818CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1077/3236], Loss: 2.1159, Perplexity: 8.2974CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1078/3236], Loss: 2.1391, Perplexity: 8.4917CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1079/3236], Loss: 1.9946, Perplexity: 7.3490CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1080/3236], Loss: 2.0343, Perplexity: 7.6471CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1081/3236], Loss: 2.0997, Perplexity: 8.1635CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1082/3236], Loss: 2.4604, Perplexity: 11.7093CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1083/3236], Loss: 2.1446, Perplexity: 8.5388CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1084/3236], Loss: 2.0815, Perplexity: 8.0166CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1085/3236], Loss: 2.1310, Perplexity: 8.4229CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1086/3236], Loss: 2.1784, Perplexity: 8.8320CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1087/3236], Loss: 2.0992, Perplexity: 8.1593CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1088/3236], Loss: 2.5911, Perplexity: 13.3450CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1089/3236], Loss: 2.0974, Perplexity: 8.1447CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1090/3236], Loss: 2.0227, Perplexity: 7.5586CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1091/3236], Loss: 2.0355, Perplexity: 7.6560CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1092/3236], Loss: 2.2372, Perplexity: 9.3673CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1093/3236], Loss: 2.1601, Perplexity: 8.6718CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1094/3236], Loss: 2.5204, Perplexity: 12.4340CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1095/3236], Loss: 2.0343, Perplexity: 7.6467CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1096/3236], Loss: 2.0084, Perplexity: 7.4514CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1097/3236], Loss: 2.1542, Perplexity: 8.6209CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1098/3236], Loss: 2.1604, Perplexity: 8.6746CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1099/3236], Loss: 2.2509, Perplexity: 9.4962CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1100/3236], Loss: 2.4566, Perplexity: 11.6656\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1101/3236], Loss: 2.1829, Perplexity: 8.8716CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1102/3236], Loss: 2.1018, Perplexity: 8.1812CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1103/3236], Loss: 2.4191, Perplexity: 11.2356CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1104/3236], Loss: 2.1400, Perplexity: 8.4995CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1105/3236], Loss: 2.0137, Perplexity: 7.4910CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1106/3236], Loss: 2.3071, Perplexity: 10.0451CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1107/3236], Loss: 1.9556, Perplexity: 7.0681CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1108/3236], Loss: 2.1052, Perplexity: 8.2085CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1109/3236], Loss: 2.0422, Perplexity: 7.7073CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1110/3236], Loss: 2.0436, Perplexity: 7.7181CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1111/3236], Loss: 2.1309, Perplexity: 8.4223CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1112/3236], Loss: 1.9826, Perplexity: 7.2615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1113/3236], Loss: 2.0459, Perplexity: 7.7361CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1114/3236], Loss: 2.1735, Perplexity: 8.7894CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1115/3236], Loss: 2.2882, Perplexity: 9.8574CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1116/3236], Loss: 2.0061, Perplexity: 7.4339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1117/3236], Loss: 2.3998, Perplexity: 11.0207CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1118/3236], Loss: 2.3208, Perplexity: 10.1839CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1119/3236], Loss: 1.9312, Perplexity: 6.8980CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1120/3236], Loss: 2.0108, Perplexity: 7.4696CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1121/3236], Loss: 2.1102, Perplexity: 8.2496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1122/3236], Loss: 2.0410, Perplexity: 7.6987CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1123/3236], Loss: 2.0709, Perplexity: 7.9323CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1124/3236], Loss: 1.9960, Perplexity: 7.3593CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1125/3236], Loss: 1.9346, Perplexity: 6.9212CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1126/3236], Loss: 2.0773, Perplexity: 7.9832CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1127/3236], Loss: 2.3684, Perplexity: 10.6806CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1128/3236], Loss: 2.0684, Perplexity: 7.9125CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1129/3236], Loss: 1.9579, Perplexity: 7.0847CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1130/3236], Loss: 2.5078, Perplexity: 12.2783CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1131/3236], Loss: 2.1012, Perplexity: 8.1762CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1132/3236], Loss: 2.2303, Perplexity: 9.3031CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1133/3236], Loss: 2.0805, Perplexity: 8.0085CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1134/3236], Loss: 2.1385, Perplexity: 8.4870CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1135/3236], Loss: 2.2368, Perplexity: 9.3637CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1136/3236], Loss: 2.1320, Perplexity: 8.4319CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1137/3236], Loss: 2.0528, Perplexity: 7.7894CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1138/3236], Loss: 2.1451, Perplexity: 8.5426CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1139/3236], Loss: 2.0999, Perplexity: 8.1656CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1140/3236], Loss: 2.0046, Perplexity: 7.4228CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1141/3236], Loss: 2.1390, Perplexity: 8.4906CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1142/3236], Loss: 2.1125, Perplexity: 8.2689CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1143/3236], Loss: 2.0141, Perplexity: 7.4938CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1144/3236], Loss: 2.4419, Perplexity: 11.4946CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1145/3236], Loss: 2.0556, Perplexity: 7.8112CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1146/3236], Loss: 2.0207, Perplexity: 7.5435CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1147/3236], Loss: 2.1482, Perplexity: 8.5692CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1148/3236], Loss: 2.0560, Perplexity: 7.8148CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1149/3236], Loss: 1.9132, Perplexity: 6.7750CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1150/3236], Loss: 2.1153, Perplexity: 8.2918CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1151/3236], Loss: 2.0308, Perplexity: 7.6201CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1152/3236], Loss: 2.1251, Perplexity: 8.3737CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1153/3236], Loss: 1.9842, Perplexity: 7.2733CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1154/3236], Loss: 2.3423, Perplexity: 10.4052CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1155/3236], Loss: 2.0151, Perplexity: 7.5013CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1156/3236], Loss: 1.9750, Perplexity: 7.2066CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1157/3236], Loss: 2.2138, Perplexity: 9.1504CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1158/3236], Loss: 2.0399, Perplexity: 7.6899CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1159/3236], Loss: 2.1975, Perplexity: 9.0022CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1160/3236], Loss: 2.0710, Perplexity: 7.9325CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1161/3236], Loss: 2.0927, Perplexity: 8.1066CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1162/3236], Loss: 2.3732, Perplexity: 10.7319CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1163/3236], Loss: 1.9547, Perplexity: 7.0617CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1164/3236], Loss: 2.0360, Perplexity: 7.6602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1165/3236], Loss: 2.1466, Perplexity: 8.5561CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1166/3236], Loss: 2.0691, Perplexity: 7.9177CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1167/3236], Loss: 2.5754, Perplexity: 13.1372CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1168/3236], Loss: 2.6450, Perplexity: 14.0828CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1169/3236], Loss: 2.2708, Perplexity: 9.6868CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1170/3236], Loss: 2.1891, Perplexity: 8.9270CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1171/3236], Loss: 2.0935, Perplexity: 8.1131CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1172/3236], Loss: 2.0023, Perplexity: 7.4058CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1173/3236], Loss: 2.0820, Perplexity: 8.0201CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1174/3236], Loss: 2.0766, Perplexity: 7.9775CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1175/3236], Loss: 2.0599, Perplexity: 7.8451CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1176/3236], Loss: 2.0368, Perplexity: 7.6664CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [1177/3236], Loss: 2.6155, Perplexity: 13.6738CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1178/3236], Loss: 2.0826, Perplexity: 8.0250CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1179/3236], Loss: 2.2404, Perplexity: 9.3975CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1180/3236], Loss: 1.9923, Perplexity: 7.3326CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1181/3236], Loss: 2.0553, Perplexity: 7.8094CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1182/3236], Loss: 1.9909, Perplexity: 7.3219CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1183/3236], Loss: 2.1719, Perplexity: 8.7748CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1184/3236], Loss: 2.1169, Perplexity: 8.3051CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1185/3236], Loss: 2.2263, Perplexity: 9.2654CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1186/3236], Loss: 2.1567, Perplexity: 8.6426CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1187/3236], Loss: 2.2620, Perplexity: 9.6026CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1188/3236], Loss: 1.9684, Perplexity: 7.1593CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1189/3236], Loss: 2.0019, Perplexity: 7.4032CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1190/3236], Loss: 2.0750, Perplexity: 7.9644CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1191/3236], Loss: 2.3449, Perplexity: 10.4321CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1192/3236], Loss: 2.0431, Perplexity: 7.7147CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1193/3236], Loss: 1.9470, Perplexity: 7.0079CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1194/3236], Loss: 1.9814, Perplexity: 7.2527CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1195/3236], Loss: 2.1635, Perplexity: 8.7020CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1196/3236], Loss: 1.9934, Perplexity: 7.3403CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1197/3236], Loss: 1.8596, Perplexity: 6.4210CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [1198/3236], Loss: 2.9030, Perplexity: 18.2285CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1199/3236], Loss: 2.3278, Perplexity: 10.2553CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1200/3236], Loss: 2.1295, Perplexity: 8.4109\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1201/3236], Loss: 2.1916, Perplexity: 8.9494CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1202/3236], Loss: 2.0016, Perplexity: 7.4006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1203/3236], Loss: 2.0540, Perplexity: 7.7989CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1204/3236], Loss: 2.1006, Perplexity: 8.1711CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1205/3236], Loss: 2.3327, Perplexity: 10.3052CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1206/3236], Loss: 2.1484, Perplexity: 8.5713CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1207/3236], Loss: 2.0762, Perplexity: 7.9743CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1208/3236], Loss: 2.2848, Perplexity: 9.8236CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1209/3236], Loss: 1.9814, Perplexity: 7.2530CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1210/3236], Loss: 2.2300, Perplexity: 9.3001CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1211/3236], Loss: 1.9658, Perplexity: 7.1409CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1212/3236], Loss: 2.0936, Perplexity: 8.1140CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1213/3236], Loss: 2.0482, Perplexity: 7.7539CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1214/3236], Loss: 1.9807, Perplexity: 7.2477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1215/3236], Loss: 2.0468, Perplexity: 7.7430CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1216/3236], Loss: 2.0576, Perplexity: 7.8269CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1217/3236], Loss: 2.3713, Perplexity: 10.7109CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1218/3236], Loss: 2.2776, Perplexity: 9.7530CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1219/3236], Loss: 2.0931, Perplexity: 8.1101CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1220/3236], Loss: 2.0229, Perplexity: 7.5605CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1221/3236], Loss: 1.9675, Perplexity: 7.1525CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1222/3236], Loss: 2.1524, Perplexity: 8.6059CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1223/3236], Loss: 2.1815, Perplexity: 8.8595CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1224/3236], Loss: 2.1229, Perplexity: 8.3552CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1225/3236], Loss: 2.0624, Perplexity: 7.8650CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1226/3236], Loss: 1.9521, Perplexity: 7.0431CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1227/3236], Loss: 2.0500, Perplexity: 7.7677CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1228/3236], Loss: 2.3353, Perplexity: 10.3322CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1229/3236], Loss: 2.2685, Perplexity: 9.6648CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1230/3236], Loss: 2.2520, Perplexity: 9.5067CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1231/3236], Loss: 2.0553, Perplexity: 7.8091CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1232/3236], Loss: 2.0181, Perplexity: 7.5241CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1233/3236], Loss: 2.1282, Perplexity: 8.4001CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1234/3236], Loss: 2.1182, Perplexity: 8.3161CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1235/3236], Loss: 2.0552, Perplexity: 7.8086CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1236/3236], Loss: 2.0325, Perplexity: 7.6332CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1237/3236], Loss: 1.9995, Perplexity: 7.3856CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1238/3236], Loss: 2.0846, Perplexity: 8.0411CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1239/3236], Loss: 2.2832, Perplexity: 9.8079CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1240/3236], Loss: 2.0318, Perplexity: 7.6282CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1241/3236], Loss: 2.1951, Perplexity: 8.9805CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1242/3236], Loss: 2.0322, Perplexity: 7.6312CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1243/3236], Loss: 2.2898, Perplexity: 9.8729CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1244/3236], Loss: 2.1774, Perplexity: 8.8236CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1245/3236], Loss: 2.0599, Perplexity: 7.8451CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1246/3236], Loss: 2.1259, Perplexity: 8.3804CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1247/3236], Loss: 2.0740, Perplexity: 7.9562CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1248/3236], Loss: 2.0832, Perplexity: 8.0302CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1249/3236], Loss: 2.3869, Perplexity: 10.8792CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1250/3236], Loss: 2.0096, Perplexity: 7.4602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1251/3236], Loss: 2.1073, Perplexity: 8.2258CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1252/3236], Loss: 2.2353, Perplexity: 9.3491CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1253/3236], Loss: 2.1093, Perplexity: 8.2422CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1254/3236], Loss: 2.0971, Perplexity: 8.1427CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1255/3236], Loss: 2.0159, Perplexity: 7.5074CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1256/3236], Loss: 2.1973, Perplexity: 9.0010CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1257/3236], Loss: 2.0797, Perplexity: 8.0017CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1258/3236], Loss: 2.1773, Perplexity: 8.8227CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1259/3236], Loss: 2.2451, Perplexity: 9.4416CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1260/3236], Loss: 1.9793, Perplexity: 7.2377CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1261/3236], Loss: 2.4928, Perplexity: 12.0955CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [1262/3236], Loss: 2.7561, Perplexity: 15.7388CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1263/3236], Loss: 2.3241, Perplexity: 10.2170CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1264/3236], Loss: 2.1539, Perplexity: 8.6188CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1265/3236], Loss: 2.2897, Perplexity: 9.8723CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1266/3236], Loss: 2.1960, Perplexity: 8.9892CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1267/3236], Loss: 2.0536, Perplexity: 7.7963CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1268/3236], Loss: 2.0589, Perplexity: 7.8375CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1269/3236], Loss: 2.4258, Perplexity: 11.3108CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1270/3236], Loss: 2.0909, Perplexity: 8.0922CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1271/3236], Loss: 2.0178, Perplexity: 7.5220CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1272/3236], Loss: 2.1047, Perplexity: 8.2043CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1273/3236], Loss: 2.1514, Perplexity: 8.5970CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1274/3236], Loss: 2.2835, Perplexity: 9.8105CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1275/3236], Loss: 2.1310, Perplexity: 8.4237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1276/3236], Loss: 2.2038, Perplexity: 9.0595CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1277/3236], Loss: 2.0336, Perplexity: 7.6417CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1278/3236], Loss: 2.0894, Perplexity: 8.0798CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1279/3236], Loss: 2.1244, Perplexity: 8.3682CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1280/3236], Loss: 2.0716, Perplexity: 7.9377CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1281/3236], Loss: 2.5722, Perplexity: 13.0951CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1282/3236], Loss: 2.1305, Perplexity: 8.4191CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1283/3236], Loss: 2.1406, Perplexity: 8.5047CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [1284/3236], Loss: 2.8230, Perplexity: 16.8272CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1285/3236], Loss: 1.9663, Perplexity: 7.1445CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1286/3236], Loss: 2.1042, Perplexity: 8.2002CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1287/3236], Loss: 2.0054, Perplexity: 7.4290CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1288/3236], Loss: 2.3153, Perplexity: 10.1281CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1289/3236], Loss: 1.8892, Perplexity: 6.6141CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1290/3236], Loss: 2.1239, Perplexity: 8.3640CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1291/3236], Loss: 2.1505, Perplexity: 8.5892CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1292/3236], Loss: 2.1189, Perplexity: 8.3221CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1293/3236], Loss: 2.3098, Perplexity: 10.0722CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1294/3236], Loss: 2.1940, Perplexity: 8.9712CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1295/3236], Loss: 2.1161, Perplexity: 8.2986CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1296/3236], Loss: 2.0627, Perplexity: 7.8673CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1297/3236], Loss: 2.1874, Perplexity: 8.9124CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1298/3236], Loss: 2.1382, Perplexity: 8.4840CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1299/3236], Loss: 2.0714, Perplexity: 7.9362CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1300/3236], Loss: 1.9355, Perplexity: 6.9278\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1301/3236], Loss: 2.1137, Perplexity: 8.2785CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1302/3236], Loss: 2.0745, Perplexity: 7.9602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1303/3236], Loss: 1.9927, Perplexity: 7.3351CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1304/3236], Loss: 2.0804, Perplexity: 8.0076CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1305/3236], Loss: 2.5960, Perplexity: 13.4102CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1306/3236], Loss: 2.0598, Perplexity: 7.8444CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1307/3236], Loss: 2.4290, Perplexity: 11.3477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1308/3236], Loss: 2.1524, Perplexity: 8.6052CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1309/3236], Loss: 2.0696, Perplexity: 7.9214CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1310/3236], Loss: 1.9097, Perplexity: 6.7512CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1311/3236], Loss: 2.1841, Perplexity: 8.8825CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1312/3236], Loss: 2.0322, Perplexity: 7.6306CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1313/3236], Loss: 2.3822, Perplexity: 10.8290CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1314/3236], Loss: 2.4689, Perplexity: 11.8100CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1315/3236], Loss: 2.0223, Perplexity: 7.5558CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1316/3236], Loss: 2.0415, Perplexity: 7.7020CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1317/3236], Loss: 2.0748, Perplexity: 7.9630CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1318/3236], Loss: 1.9982, Perplexity: 7.3759CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1319/3236], Loss: 1.9916, Perplexity: 7.3272CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1320/3236], Loss: 2.0055, Perplexity: 7.4295CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1321/3236], Loss: 2.1292, Perplexity: 8.4081CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1322/3236], Loss: 2.0620, Perplexity: 7.8620CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1323/3236], Loss: 2.1010, Perplexity: 8.1740CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1324/3236], Loss: 2.3494, Perplexity: 10.4795CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1325/3236], Loss: 2.1374, Perplexity: 8.4777CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1326/3236], Loss: 2.1453, Perplexity: 8.5449CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1327/3236], Loss: 2.0153, Perplexity: 7.5028CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1328/3236], Loss: 2.0097, Perplexity: 7.4613CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1329/3236], Loss: 1.8620, Perplexity: 6.4367CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1330/3236], Loss: 2.0410, Perplexity: 7.6980CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1331/3236], Loss: 2.1145, Perplexity: 8.2856CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1332/3236], Loss: 2.0803, Perplexity: 8.0070CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1333/3236], Loss: 1.8628, Perplexity: 6.4415CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1334/3236], Loss: 2.4601, Perplexity: 11.7054CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1335/3236], Loss: 1.9383, Perplexity: 6.9472CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1336/3236], Loss: 2.0712, Perplexity: 7.9341CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1337/3236], Loss: 2.1149, Perplexity: 8.2886CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1338/3236], Loss: 2.1509, Perplexity: 8.5925CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1339/3236], Loss: 2.1290, Perplexity: 8.4062CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1340/3236], Loss: 2.0538, Perplexity: 7.7972CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1341/3236], Loss: 2.3312, Perplexity: 10.2906CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1342/3236], Loss: 1.9880, Perplexity: 7.3006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1343/3236], Loss: 2.3595, Perplexity: 10.5861CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1344/3236], Loss: 2.0678, Perplexity: 7.9073CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1345/3236], Loss: 2.1840, Perplexity: 8.8814CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1346/3236], Loss: 2.1820, Perplexity: 8.8638CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1347/3236], Loss: 1.9225, Perplexity: 6.8378CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1348/3236], Loss: 2.1330, Perplexity: 8.4405CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1349/3236], Loss: 2.1362, Perplexity: 8.4672CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1350/3236], Loss: 2.1427, Perplexity: 8.5222CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1351/3236], Loss: 2.0938, Perplexity: 8.1160CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1352/3236], Loss: 2.0794, Perplexity: 7.9994CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1353/3236], Loss: 2.2466, Perplexity: 9.4551CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1354/3236], Loss: 2.0996, Perplexity: 8.1628CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1355/3236], Loss: 2.0979, Perplexity: 8.1487CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1356/3236], Loss: 2.4361, Perplexity: 11.4286CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1357/3236], Loss: 2.0054, Perplexity: 7.4289CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1358/3236], Loss: 1.9784, Perplexity: 7.2311CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1359/3236], Loss: 1.9185, Perplexity: 6.8110CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1360/3236], Loss: 2.3082, Perplexity: 10.0560CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1361/3236], Loss: 2.2620, Perplexity: 9.6022CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1362/3236], Loss: 2.1410, Perplexity: 8.5080CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1363/3236], Loss: 1.9746, Perplexity: 7.2040CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1364/3236], Loss: 2.0002, Perplexity: 7.3907CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1365/3236], Loss: 1.9887, Perplexity: 7.3059CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1366/3236], Loss: 1.9393, Perplexity: 6.9536CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1367/3236], Loss: 2.0928, Perplexity: 8.1073CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1368/3236], Loss: 2.1998, Perplexity: 9.0234CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1369/3236], Loss: 2.1105, Perplexity: 8.2524CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1370/3236], Loss: 2.0165, Perplexity: 7.5118CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1371/3236], Loss: 2.1771, Perplexity: 8.8205CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1372/3236], Loss: 2.1534, Perplexity: 8.6144CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1373/3236], Loss: 2.1661, Perplexity: 8.7243CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1374/3236], Loss: 2.0637, Perplexity: 7.8750CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1375/3236], Loss: 1.9978, Perplexity: 7.3728CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1376/3236], Loss: 2.1213, Perplexity: 8.3416CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1377/3236], Loss: 1.9545, Perplexity: 7.0606CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1378/3236], Loss: 2.0185, Perplexity: 7.5269CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1379/3236], Loss: 1.9971, Perplexity: 7.3674CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1380/3236], Loss: 2.1724, Perplexity: 8.7797CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1381/3236], Loss: 2.0730, Perplexity: 7.9488CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1382/3236], Loss: 1.9494, Perplexity: 7.0242CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1383/3236], Loss: 2.4124, Perplexity: 11.1605CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1384/3236], Loss: 2.1706, Perplexity: 8.7631CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1385/3236], Loss: 2.0536, Perplexity: 7.7960CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [1386/3236], Loss: 2.3929, Perplexity: 10.9447CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1387/3236], Loss: 1.9857, Perplexity: 7.2844CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1388/3236], Loss: 2.1679, Perplexity: 8.7402CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1389/3236], Loss: 1.9532, Perplexity: 7.0514CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1390/3236], Loss: 2.1540, Perplexity: 8.6197CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1391/3236], Loss: 2.2497, Perplexity: 9.4850CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1392/3236], Loss: 2.0420, Perplexity: 7.7061CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1393/3236], Loss: 2.6512, Perplexity: 14.1712CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1394/3236], Loss: 2.0296, Perplexity: 7.6114CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1395/3236], Loss: 2.3487, Perplexity: 10.4719CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1396/3236], Loss: 2.4168, Perplexity: 11.2100CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1397/3236], Loss: 2.0694, Perplexity: 7.9202CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1398/3236], Loss: 2.3462, Perplexity: 10.4456CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1399/3236], Loss: 2.0675, Perplexity: 7.9052CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1400/3236], Loss: 2.1978, Perplexity: 9.0049\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1401/3236], Loss: 2.5036, Perplexity: 12.2264CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1402/3236], Loss: 2.0294, Perplexity: 7.6092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1403/3236], Loss: 2.2065, Perplexity: 9.0836CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1404/3236], Loss: 2.1067, Perplexity: 8.2210CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1405/3236], Loss: 2.4643, Perplexity: 11.7557CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1406/3236], Loss: 2.1432, Perplexity: 8.5270CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1407/3236], Loss: 2.0176, Perplexity: 7.5205CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1408/3236], Loss: 2.2069, Perplexity: 9.0879CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1409/3236], Loss: 2.0118, Perplexity: 7.4766CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1410/3236], Loss: 2.2779, Perplexity: 9.7567CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1411/3236], Loss: 2.0418, Perplexity: 7.7044CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1412/3236], Loss: 2.4665, Perplexity: 11.7816CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1413/3236], Loss: 2.0059, Perplexity: 7.4325CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1414/3236], Loss: 2.0067, Perplexity: 7.4385CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1415/3236], Loss: 2.0507, Perplexity: 7.7731CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1416/3236], Loss: 2.0470, Perplexity: 7.7446CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1417/3236], Loss: 2.0858, Perplexity: 8.0514CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1418/3236], Loss: 2.2753, Perplexity: 9.7306CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1419/3236], Loss: 2.2206, Perplexity: 9.2125CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1420/3236], Loss: 2.0867, Perplexity: 8.0583CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1421/3236], Loss: 2.3995, Perplexity: 11.0176CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1422/3236], Loss: 2.1443, Perplexity: 8.5358CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1423/3236], Loss: 2.0645, Perplexity: 7.8815CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1424/3236], Loss: 2.2113, Perplexity: 9.1279CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1425/3236], Loss: 2.1565, Perplexity: 8.6406CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1426/3236], Loss: 2.0126, Perplexity: 7.4829CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1427/3236], Loss: 2.0027, Perplexity: 7.4090CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1428/3236], Loss: 2.0249, Perplexity: 7.5752CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1429/3236], Loss: 2.0471, Perplexity: 7.7451CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1430/3236], Loss: 2.1157, Perplexity: 8.2953CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [1431/3236], Loss: 2.6756, Perplexity: 14.5216CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1432/3236], Loss: 1.9977, Perplexity: 7.3721CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1433/3236], Loss: 1.9847, Perplexity: 7.2769CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1434/3236], Loss: 2.0608, Perplexity: 7.8520CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1435/3236], Loss: 1.9803, Perplexity: 7.2448CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1436/3236], Loss: 2.1424, Perplexity: 8.5198CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1437/3236], Loss: 2.2759, Perplexity: 9.7366CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1438/3236], Loss: 2.0552, Perplexity: 7.8085CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1439/3236], Loss: 2.0335, Perplexity: 7.6411CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1440/3236], Loss: 2.1222, Perplexity: 8.3496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1441/3236], Loss: 2.1050, Perplexity: 8.2069CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [1442/3236], Loss: 2.9186, Perplexity: 18.5159CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1443/3236], Loss: 2.1087, Perplexity: 8.2379CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1444/3236], Loss: 2.0959, Perplexity: 8.1331CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1445/3236], Loss: 2.2982, Perplexity: 9.9565CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1446/3236], Loss: 2.0511, Perplexity: 7.7761CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1447/3236], Loss: 2.1582, Perplexity: 8.6556CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1448/3236], Loss: 2.0304, Perplexity: 7.6174CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1449/3236], Loss: 2.4461, Perplexity: 11.5431CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1450/3236], Loss: 2.0594, Perplexity: 7.8413CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1451/3236], Loss: 2.0203, Perplexity: 7.5403CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1452/3236], Loss: 1.9667, Perplexity: 7.1471CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1453/3236], Loss: 2.1936, Perplexity: 8.9670CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1454/3236], Loss: 2.0619, Perplexity: 7.8607CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1455/3236], Loss: 2.1151, Perplexity: 8.2902CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1456/3236], Loss: 2.2514, Perplexity: 9.5006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1457/3236], Loss: 2.0219, Perplexity: 7.5525CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1458/3236], Loss: 2.1285, Perplexity: 8.4021CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1459/3236], Loss: 1.9350, Perplexity: 6.9237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1460/3236], Loss: 2.0829, Perplexity: 8.0281CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1461/3236], Loss: 1.9538, Perplexity: 7.0551CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1462/3236], Loss: 2.4151, Perplexity: 11.1908CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1463/3236], Loss: 2.5723, Perplexity: 13.0965CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1464/3236], Loss: 1.9804, Perplexity: 7.2455CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1465/3236], Loss: 2.2536, Perplexity: 9.5222CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1466/3236], Loss: 2.3764, Perplexity: 10.7658CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1467/3236], Loss: 2.0235, Perplexity: 7.5647CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [1468/3236], Loss: 2.7587, Perplexity: 15.7793CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1469/3236], Loss: 2.3223, Perplexity: 10.1986CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1470/3236], Loss: 2.1760, Perplexity: 8.8114CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1471/3236], Loss: 1.9313, Perplexity: 6.8988CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1472/3236], Loss: 2.3132, Perplexity: 10.1064CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1473/3236], Loss: 1.9182, Perplexity: 6.8089CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1474/3236], Loss: 2.1041, Perplexity: 8.1997CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1475/3236], Loss: 2.4854, Perplexity: 12.0058CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1476/3236], Loss: 2.1008, Perplexity: 8.1729CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1477/3236], Loss: 1.9881, Perplexity: 7.3014CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1478/3236], Loss: 2.0912, Perplexity: 8.0946CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1479/3236], Loss: 2.1550, Perplexity: 8.6282CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1480/3236], Loss: 2.0899, Perplexity: 8.0842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1481/3236], Loss: 2.1700, Perplexity: 8.7579CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1482/3236], Loss: 2.2331, Perplexity: 9.3291CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1483/3236], Loss: 2.0920, Perplexity: 8.1012CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1484/3236], Loss: 2.1843, Perplexity: 8.8842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1485/3236], Loss: 2.0199, Perplexity: 7.5373CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1486/3236], Loss: 2.4374, Perplexity: 11.4436CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [1487/3236], Loss: 2.7080, Perplexity: 14.9995CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1488/3236], Loss: 2.0222, Perplexity: 7.5546CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1489/3236], Loss: 2.1268, Perplexity: 8.3879CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1490/3236], Loss: 1.9899, Perplexity: 7.3146CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1491/3236], Loss: 1.9580, Perplexity: 7.0853CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1492/3236], Loss: 2.5108, Perplexity: 12.3143CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1493/3236], Loss: 2.0120, Perplexity: 7.4784CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1494/3236], Loss: 2.1692, Perplexity: 8.7514CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1495/3236], Loss: 2.1569, Perplexity: 8.6444CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1496/3236], Loss: 1.9781, Perplexity: 7.2287CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1497/3236], Loss: 2.3169, Perplexity: 10.1446CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1498/3236], Loss: 2.0461, Perplexity: 7.7376CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1499/3236], Loss: 2.0011, Perplexity: 7.3975CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1500/3236], Loss: 2.0229, Perplexity: 7.5604\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1501/3236], Loss: 2.3428, Perplexity: 10.4104CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1502/3236], Loss: 2.1674, Perplexity: 8.7351CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1503/3236], Loss: 2.0991, Perplexity: 8.1591CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1504/3236], Loss: 2.2652, Perplexity: 9.6330CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1505/3236], Loss: 2.0840, Perplexity: 8.0365CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1506/3236], Loss: 2.2104, Perplexity: 9.1192CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1507/3236], Loss: 2.0641, Perplexity: 7.8785CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1508/3236], Loss: 2.0899, Perplexity: 8.0843CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1509/3236], Loss: 2.1551, Perplexity: 8.6291CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1510/3236], Loss: 2.1864, Perplexity: 8.9032CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1511/3236], Loss: 2.3965, Perplexity: 10.9842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1512/3236], Loss: 2.1078, Perplexity: 8.2304CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1513/3236], Loss: 2.0297, Perplexity: 7.6121CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1514/3236], Loss: 1.9827, Perplexity: 7.2623CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1515/3236], Loss: 2.3174, Perplexity: 10.1497CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1516/3236], Loss: 2.0796, Perplexity: 8.0016CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1517/3236], Loss: 2.2979, Perplexity: 9.9537CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1518/3236], Loss: 2.1503, Perplexity: 8.5874CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1519/3236], Loss: 1.9861, Perplexity: 7.2870CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1520/3236], Loss: 2.0630, Perplexity: 7.8697CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1521/3236], Loss: 2.0039, Perplexity: 7.4177CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1522/3236], Loss: 1.9913, Perplexity: 7.3251CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1523/3236], Loss: 2.0377, Perplexity: 7.6730CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1524/3236], Loss: 1.8624, Perplexity: 6.4394CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1525/3236], Loss: 2.1373, Perplexity: 8.4765CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1526/3236], Loss: 1.9959, Perplexity: 7.3588CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1527/3236], Loss: 1.9355, Perplexity: 6.9273CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [1528/3236], Loss: 2.9035, Perplexity: 18.2379CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1529/3236], Loss: 2.0390, Perplexity: 7.6827CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1530/3236], Loss: 2.0477, Perplexity: 7.7497CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1531/3236], Loss: 2.0205, Perplexity: 7.5423CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1532/3236], Loss: 2.4513, Perplexity: 11.6031CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1533/3236], Loss: 2.3003, Perplexity: 9.9770CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1534/3236], Loss: 2.0969, Perplexity: 8.1412CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1535/3236], Loss: 2.1761, Perplexity: 8.8116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1536/3236], Loss: 2.0952, Perplexity: 8.1275CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1537/3236], Loss: 1.9106, Perplexity: 6.7569CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1538/3236], Loss: 2.3105, Perplexity: 10.0792CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1539/3236], Loss: 1.9937, Perplexity: 7.3428CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1540/3236], Loss: 2.4899, Perplexity: 12.0602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1541/3236], Loss: 2.3358, Perplexity: 10.3374CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1542/3236], Loss: 2.0042, Perplexity: 7.4202CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1543/3236], Loss: 2.1275, Perplexity: 8.3940CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1544/3236], Loss: 2.1468, Perplexity: 8.5573CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [1545/3236], Loss: 3.0193, Perplexity: 20.4772CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1546/3236], Loss: 2.1026, Perplexity: 8.1876CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1547/3236], Loss: 2.0049, Perplexity: 7.4251CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1548/3236], Loss: 2.0819, Perplexity: 8.0195CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1549/3236], Loss: 2.2173, Perplexity: 9.1825CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1550/3236], Loss: 2.1021, Perplexity: 8.1834CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1551/3236], Loss: 1.9759, Perplexity: 7.2133CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1552/3236], Loss: 2.0535, Perplexity: 7.7948CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1553/3236], Loss: 1.9168, Perplexity: 6.7994CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1554/3236], Loss: 2.0215, Perplexity: 7.5494CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1555/3236], Loss: 2.0885, Perplexity: 8.0726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1556/3236], Loss: 2.3096, Perplexity: 10.0706CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1557/3236], Loss: 2.0708, Perplexity: 7.9312CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1558/3236], Loss: 2.0319, Perplexity: 7.6285CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1559/3236], Loss: 2.4059, Perplexity: 11.0884CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1560/3236], Loss: 2.4529, Perplexity: 11.6226CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1561/3236], Loss: 2.3668, Perplexity: 10.6633CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1562/3236], Loss: 2.1032, Perplexity: 8.1927CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1563/3236], Loss: 2.2275, Perplexity: 9.2768CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1564/3236], Loss: 2.1057, Perplexity: 8.2132CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1565/3236], Loss: 1.9909, Perplexity: 7.3222CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1566/3236], Loss: 2.0652, Perplexity: 7.8869CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1567/3236], Loss: 2.0860, Perplexity: 8.0526CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1568/3236], Loss: 2.1833, Perplexity: 8.8756CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1569/3236], Loss: 1.9889, Perplexity: 7.3077CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1570/3236], Loss: 2.0940, Perplexity: 8.1176CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1571/3236], Loss: 2.4829, Perplexity: 11.9759CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1572/3236], Loss: 2.0110, Perplexity: 7.4708CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1573/3236], Loss: 2.0726, Perplexity: 7.9458CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1574/3236], Loss: 2.2206, Perplexity: 9.2126CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1575/3236], Loss: 2.0005, Perplexity: 7.3926CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1576/3236], Loss: 2.0437, Perplexity: 7.7193CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1577/3236], Loss: 2.0447, Perplexity: 7.7265CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1578/3236], Loss: 1.9250, Perplexity: 6.8548CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1579/3236], Loss: 2.1174, Perplexity: 8.3092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1580/3236], Loss: 2.1171, Perplexity: 8.3068CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1581/3236], Loss: 1.9710, Perplexity: 7.1780CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1582/3236], Loss: 2.1744, Perplexity: 8.7968CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1583/3236], Loss: 2.1943, Perplexity: 8.9741CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1584/3236], Loss: 2.3877, Perplexity: 10.8885CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1585/3236], Loss: 2.2208, Perplexity: 9.2147CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1586/3236], Loss: 2.1204, Perplexity: 8.3348CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1587/3236], Loss: 1.9387, Perplexity: 6.9497CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1588/3236], Loss: 2.1647, Perplexity: 8.7120CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1589/3236], Loss: 2.0091, Perplexity: 7.4565CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1590/3236], Loss: 2.0965, Perplexity: 8.1378CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1591/3236], Loss: 2.0527, Perplexity: 7.7890CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [1592/3236], Loss: 2.6975, Perplexity: 14.8425CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1593/3236], Loss: 2.1065, Perplexity: 8.2192CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1594/3236], Loss: 2.1166, Perplexity: 8.3026CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1595/3236], Loss: 2.0846, Perplexity: 8.0414CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1596/3236], Loss: 2.0334, Perplexity: 7.6403CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1597/3236], Loss: 2.1936, Perplexity: 8.9672CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1598/3236], Loss: 2.4168, Perplexity: 11.2096CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1599/3236], Loss: 2.0908, Perplexity: 8.0912CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1600/3236], Loss: 2.2337, Perplexity: 9.3348\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1601/3236], Loss: 2.0067, Perplexity: 7.4388CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1602/3236], Loss: 2.0075, Perplexity: 7.4449CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1603/3236], Loss: 2.0405, Perplexity: 7.6947CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1604/3236], Loss: 2.0815, Perplexity: 8.0168CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1605/3236], Loss: 2.1078, Perplexity: 8.2302CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1606/3236], Loss: 2.0381, Perplexity: 7.6757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1607/3236], Loss: 2.1117, Perplexity: 8.2621CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 25])\n",
      "Epoch [1/1], Step [1608/3236], Loss: 3.1828, Perplexity: 24.1150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1609/3236], Loss: 2.0771, Perplexity: 7.9816CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1610/3236], Loss: 2.1730, Perplexity: 8.7842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1611/3236], Loss: 2.0003, Perplexity: 7.3911CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1612/3236], Loss: 2.1122, Perplexity: 8.2666CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1613/3236], Loss: 2.4050, Perplexity: 11.0779CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1614/3236], Loss: 2.0198, Perplexity: 7.5370CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1615/3236], Loss: 2.0268, Perplexity: 7.5895CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1616/3236], Loss: 2.3117, Perplexity: 10.0921CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1617/3236], Loss: 2.0728, Perplexity: 7.9469CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1618/3236], Loss: 2.1287, Perplexity: 8.4043CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1619/3236], Loss: 2.1509, Perplexity: 8.5924CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1620/3236], Loss: 2.3617, Perplexity: 10.6086CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1621/3236], Loss: 2.0155, Perplexity: 7.5046CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1622/3236], Loss: 2.0410, Perplexity: 7.6981CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1623/3236], Loss: 1.9590, Perplexity: 7.0921CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1624/3236], Loss: 2.1066, Perplexity: 8.2204CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1625/3236], Loss: 1.9765, Perplexity: 7.2178CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1626/3236], Loss: 2.0336, Perplexity: 7.6418CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1627/3236], Loss: 2.1920, Perplexity: 8.9527CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1628/3236], Loss: 2.0677, Perplexity: 7.9063CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1629/3236], Loss: 2.0414, Perplexity: 7.7011CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1630/3236], Loss: 1.9362, Perplexity: 6.9322CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1631/3236], Loss: 2.5108, Perplexity: 12.3149CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1632/3236], Loss: 2.0078, Perplexity: 7.4467CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1633/3236], Loss: 2.5673, Perplexity: 13.0311CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1634/3236], Loss: 2.1444, Perplexity: 8.5371CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [1635/3236], Loss: 2.4939, Perplexity: 12.1084CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1636/3236], Loss: 2.2053, Perplexity: 9.0730CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1637/3236], Loss: 2.0714, Perplexity: 7.9356CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1638/3236], Loss: 2.0203, Perplexity: 7.5409CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1639/3236], Loss: 1.9685, Perplexity: 7.1602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1640/3236], Loss: 2.1591, Perplexity: 8.6634CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1641/3236], Loss: 2.2117, Perplexity: 9.1309CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1642/3236], Loss: 2.0449, Perplexity: 7.7284CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1643/3236], Loss: 2.1559, Perplexity: 8.6360CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1644/3236], Loss: 2.0550, Perplexity: 7.8071CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1645/3236], Loss: 1.9413, Perplexity: 6.9676CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1646/3236], Loss: 2.1336, Perplexity: 8.4455CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1647/3236], Loss: 2.0480, Perplexity: 7.7527CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1648/3236], Loss: 2.1243, Perplexity: 8.3666CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1649/3236], Loss: 2.1824, Perplexity: 8.8677CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1650/3236], Loss: 1.9667, Perplexity: 7.1468CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1651/3236], Loss: 2.0398, Perplexity: 7.6890CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1652/3236], Loss: 2.3469, Perplexity: 10.4530CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1653/3236], Loss: 2.0211, Perplexity: 7.5464CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1654/3236], Loss: 2.0299, Perplexity: 7.6135CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1655/3236], Loss: 1.9929, Perplexity: 7.3366CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1656/3236], Loss: 2.3358, Perplexity: 10.3378CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1657/3236], Loss: 2.4887, Perplexity: 12.0455CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1658/3236], Loss: 2.1318, Perplexity: 8.4299CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1659/3236], Loss: 2.0632, Perplexity: 7.8708CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1660/3236], Loss: 2.0161, Perplexity: 7.5091CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1661/3236], Loss: 2.2567, Perplexity: 9.5516CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1662/3236], Loss: 2.3381, Perplexity: 10.3615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1663/3236], Loss: 2.3771, Perplexity: 10.7739CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1664/3236], Loss: 2.1203, Perplexity: 8.3339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1665/3236], Loss: 1.9411, Perplexity: 6.9664CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1666/3236], Loss: 2.2835, Perplexity: 9.8114CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1667/3236], Loss: 2.1934, Perplexity: 8.9657CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1668/3236], Loss: 2.1303, Perplexity: 8.4172CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1669/3236], Loss: 2.0798, Perplexity: 8.0028CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1670/3236], Loss: 2.1506, Perplexity: 8.5904CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1671/3236], Loss: 2.0738, Perplexity: 7.9547CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1672/3236], Loss: 2.0526, Perplexity: 7.7882CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1673/3236], Loss: 2.3240, Perplexity: 10.2164CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1674/3236], Loss: 1.9171, Perplexity: 6.8013CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1675/3236], Loss: 2.2372, Perplexity: 9.3672CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1676/3236], Loss: 2.1539, Perplexity: 8.6184CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1677/3236], Loss: 1.9671, Perplexity: 7.1496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1678/3236], Loss: 2.0100, Perplexity: 7.4635CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1679/3236], Loss: 2.2249, Perplexity: 9.2529CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1680/3236], Loss: 2.2140, Perplexity: 9.1518CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1681/3236], Loss: 2.2033, Perplexity: 9.0549CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1682/3236], Loss: 2.2272, Perplexity: 9.2735CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1683/3236], Loss: 2.1692, Perplexity: 8.7509CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1684/3236], Loss: 2.1390, Perplexity: 8.4913CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1685/3236], Loss: 2.1880, Perplexity: 8.9171CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1686/3236], Loss: 2.0079, Perplexity: 7.4475CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1687/3236], Loss: 2.0330, Perplexity: 7.6367CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1688/3236], Loss: 2.1324, Perplexity: 8.4352CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1689/3236], Loss: 2.3553, Perplexity: 10.5417CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1690/3236], Loss: 1.9847, Perplexity: 7.2765CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1691/3236], Loss: 2.1266, Perplexity: 8.3863CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1692/3236], Loss: 2.0190, Perplexity: 7.5305CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1693/3236], Loss: 2.2688, Perplexity: 9.6675CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1694/3236], Loss: 2.4551, Perplexity: 11.6472CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1695/3236], Loss: 2.0844, Perplexity: 8.0400CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1696/3236], Loss: 2.1156, Perplexity: 8.2942CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1697/3236], Loss: 2.0977, Perplexity: 8.1478CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1698/3236], Loss: 1.9348, Perplexity: 6.9224CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1699/3236], Loss: 2.4188, Perplexity: 11.2328CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1700/3236], Loss: 2.2182, Perplexity: 9.1911\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1701/3236], Loss: 2.0289, Perplexity: 7.6056CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1702/3236], Loss: 2.1556, Perplexity: 8.6331CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1703/3236], Loss: 2.1263, Perplexity: 8.3842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1704/3236], Loss: 2.0649, Perplexity: 7.8848CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1705/3236], Loss: 2.2681, Perplexity: 9.6607CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1706/3236], Loss: 2.2177, Perplexity: 9.1860CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1707/3236], Loss: 2.1206, Perplexity: 8.3365CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1708/3236], Loss: 2.0548, Perplexity: 7.8049CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1709/3236], Loss: 2.0795, Perplexity: 8.0001CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [1710/3236], Loss: 2.7975, Perplexity: 16.4038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1711/3236], Loss: 2.0565, Perplexity: 7.8184CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1712/3236], Loss: 2.6351, Perplexity: 13.9441CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1713/3236], Loss: 2.1226, Perplexity: 8.3530CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1714/3236], Loss: 2.0958, Perplexity: 8.1319CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1715/3236], Loss: 2.0428, Perplexity: 7.7123CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1716/3236], Loss: 2.0852, Perplexity: 8.0460CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1717/3236], Loss: 2.1603, Perplexity: 8.6741CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1718/3236], Loss: 1.9059, Perplexity: 6.7253CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1719/3236], Loss: 1.9426, Perplexity: 6.9768CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 46])\n",
      "Epoch [1/1], Step [1720/3236], Loss: 4.5754, Perplexity: 97.0654CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1721/3236], Loss: 2.0853, Perplexity: 8.0468CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1722/3236], Loss: 2.0899, Perplexity: 8.0842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1723/3236], Loss: 2.2294, Perplexity: 9.2940CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1724/3236], Loss: 2.1858, Perplexity: 8.8976CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1725/3236], Loss: 2.0460, Perplexity: 7.7371CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1726/3236], Loss: 2.1913, Perplexity: 8.9466CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1727/3236], Loss: 1.9230, Perplexity: 6.8416CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1728/3236], Loss: 2.1836, Perplexity: 8.8781CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1729/3236], Loss: 2.0388, Perplexity: 7.6815CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1730/3236], Loss: 2.1608, Perplexity: 8.6781CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1731/3236], Loss: 2.1326, Perplexity: 8.4364CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 29])\n",
      "Epoch [1/1], Step [1732/3236], Loss: 3.3268, Perplexity: 27.8504CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1733/3236], Loss: 2.0029, Perplexity: 7.4106CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1734/3236], Loss: 2.1413, Perplexity: 8.5102CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1735/3236], Loss: 2.0152, Perplexity: 7.5020CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1736/3236], Loss: 2.2718, Perplexity: 9.6965CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1737/3236], Loss: 2.0879, Perplexity: 8.0679CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1738/3236], Loss: 2.1261, Perplexity: 8.3821CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1739/3236], Loss: 2.1653, Perplexity: 8.7171CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1740/3236], Loss: 2.2111, Perplexity: 9.1257CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1741/3236], Loss: 2.0942, Perplexity: 8.1186CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1742/3236], Loss: 2.0250, Perplexity: 7.5760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1743/3236], Loss: 2.3660, Perplexity: 10.6549CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1744/3236], Loss: 2.1878, Perplexity: 8.9159CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1745/3236], Loss: 2.3892, Perplexity: 10.9043CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1746/3236], Loss: 2.0286, Perplexity: 7.6036CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1747/3236], Loss: 2.0709, Perplexity: 7.9323CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1748/3236], Loss: 2.0587, Perplexity: 7.8358CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1749/3236], Loss: 2.0727, Perplexity: 7.9464CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1750/3236], Loss: 1.9845, Perplexity: 7.2754CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1751/3236], Loss: 2.1905, Perplexity: 8.9392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1752/3236], Loss: 1.9852, Perplexity: 7.2804CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1753/3236], Loss: 2.1291, Perplexity: 8.4073CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1754/3236], Loss: 2.1170, Perplexity: 8.3060CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1755/3236], Loss: 2.1134, Perplexity: 8.2760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1756/3236], Loss: 2.0915, Perplexity: 8.0974CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1757/3236], Loss: 2.0157, Perplexity: 7.5058CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1758/3236], Loss: 2.2992, Perplexity: 9.9663CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [1759/3236], Loss: 2.7507, Perplexity: 15.6542CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1760/3236], Loss: 2.0788, Perplexity: 7.9951CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1761/3236], Loss: 2.2871, Perplexity: 9.8467CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1762/3236], Loss: 2.4937, Perplexity: 12.1061CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1763/3236], Loss: 2.0545, Perplexity: 7.8029CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1764/3236], Loss: 2.4897, Perplexity: 12.0572CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1765/3236], Loss: 1.9841, Perplexity: 7.2728CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1766/3236], Loss: 1.9592, Perplexity: 7.0938CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1767/3236], Loss: 2.2063, Perplexity: 9.0821CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1768/3236], Loss: 2.0727, Perplexity: 7.9464CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1769/3236], Loss: 2.0033, Perplexity: 7.4136CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1770/3236], Loss: 2.3463, Perplexity: 10.4470CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1771/3236], Loss: 2.0514, Perplexity: 7.7788CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1772/3236], Loss: 2.0487, Perplexity: 7.7577CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1773/3236], Loss: 2.0815, Perplexity: 8.0162CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1774/3236], Loss: 2.3042, Perplexity: 10.0165CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1775/3236], Loss: 2.1165, Perplexity: 8.3018CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1776/3236], Loss: 2.2599, Perplexity: 9.5821CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1777/3236], Loss: 1.9773, Perplexity: 7.2234CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1778/3236], Loss: 1.9566, Perplexity: 7.0751CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1779/3236], Loss: 2.1697, Perplexity: 8.7556CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1780/3236], Loss: 2.1117, Perplexity: 8.2624CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1781/3236], Loss: 2.5772, Perplexity: 13.1605CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1782/3236], Loss: 2.2701, Perplexity: 9.6806CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1783/3236], Loss: 2.1220, Perplexity: 8.3479CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1784/3236], Loss: 1.9982, Perplexity: 7.3757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1785/3236], Loss: 2.1545, Perplexity: 8.6233CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1786/3236], Loss: 2.4499, Perplexity: 11.5869CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1787/3236], Loss: 1.9692, Perplexity: 7.1651CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1788/3236], Loss: 2.0906, Perplexity: 8.0895CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1789/3236], Loss: 2.0994, Perplexity: 8.1617CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1790/3236], Loss: 2.1709, Perplexity: 8.7663CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1791/3236], Loss: 2.0698, Perplexity: 7.9235CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1792/3236], Loss: 2.0817, Perplexity: 8.0183CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1793/3236], Loss: 2.2484, Perplexity: 9.4725CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1794/3236], Loss: 2.2580, Perplexity: 9.5641CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1795/3236], Loss: 2.2101, Perplexity: 9.1169CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1796/3236], Loss: 2.1153, Perplexity: 8.2923CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1797/3236], Loss: 2.0806, Perplexity: 8.0095CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1798/3236], Loss: 2.1394, Perplexity: 8.4941CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1799/3236], Loss: 1.9940, Perplexity: 7.3448CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1800/3236], Loss: 1.9151, Perplexity: 6.7878\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1801/3236], Loss: 1.9316, Perplexity: 6.9005CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1802/3236], Loss: 2.0929, Perplexity: 8.1082CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1803/3236], Loss: 2.1072, Perplexity: 8.2254CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1804/3236], Loss: 1.9735, Perplexity: 7.1960CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1805/3236], Loss: 2.0481, Perplexity: 7.7532CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1806/3236], Loss: 2.0244, Perplexity: 7.5715CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1807/3236], Loss: 2.1213, Perplexity: 8.3417CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1808/3236], Loss: 2.2904, Perplexity: 9.8787CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1809/3236], Loss: 1.9809, Perplexity: 7.2495CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1810/3236], Loss: 1.9708, Perplexity: 7.1763CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1811/3236], Loss: 2.1107, Perplexity: 8.2541CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1812/3236], Loss: 2.2750, Perplexity: 9.7277CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1813/3236], Loss: 2.0192, Perplexity: 7.5321CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1814/3236], Loss: 2.1315, Perplexity: 8.4275CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1815/3236], Loss: 2.0266, Perplexity: 7.5879CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1816/3236], Loss: 2.1261, Perplexity: 8.3823CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1817/3236], Loss: 2.7061, Perplexity: 14.9714CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1818/3236], Loss: 2.2063, Perplexity: 9.0816CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1819/3236], Loss: 2.1485, Perplexity: 8.5719CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1820/3236], Loss: 2.0608, Perplexity: 7.8525CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1821/3236], Loss: 1.9659, Perplexity: 7.1417CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1822/3236], Loss: 2.2180, Perplexity: 9.1890CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1823/3236], Loss: 2.0193, Perplexity: 7.5333CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1824/3236], Loss: 2.0504, Perplexity: 7.7714CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1825/3236], Loss: 2.1966, Perplexity: 8.9943CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1826/3236], Loss: 2.1074, Perplexity: 8.2268CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1827/3236], Loss: 2.0977, Perplexity: 8.1473CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1828/3236], Loss: 2.3002, Perplexity: 9.9760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1829/3236], Loss: 1.9952, Perplexity: 7.3533CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1830/3236], Loss: 1.9268, Perplexity: 6.8673CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1831/3236], Loss: 2.0485, Perplexity: 7.7560CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1832/3236], Loss: 2.1024, Perplexity: 8.1857CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1833/3236], Loss: 2.1707, Perplexity: 8.7648CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1834/3236], Loss: 2.4546, Perplexity: 11.6419CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1835/3236], Loss: 2.1591, Perplexity: 8.6631CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1836/3236], Loss: 2.1992, Perplexity: 9.0177CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1837/3236], Loss: 2.0007, Perplexity: 7.3945CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1838/3236], Loss: 2.1325, Perplexity: 8.4357CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1839/3236], Loss: 2.1365, Perplexity: 8.4694CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1840/3236], Loss: 2.0260, Perplexity: 7.5838CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1841/3236], Loss: 2.1300, Perplexity: 8.4150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1842/3236], Loss: 2.0979, Perplexity: 8.1488CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1843/3236], Loss: 2.0838, Perplexity: 8.0350CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1844/3236], Loss: 1.9870, Perplexity: 7.2934CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1845/3236], Loss: 2.0679, Perplexity: 7.9079CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1846/3236], Loss: 2.0771, Perplexity: 7.9810CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1847/3236], Loss: 2.4648, Perplexity: 11.7615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1848/3236], Loss: 2.0371, Perplexity: 7.6687CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1849/3236], Loss: 2.2226, Perplexity: 9.2317CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1850/3236], Loss: 1.9786, Perplexity: 7.2329CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1851/3236], Loss: 2.4291, Perplexity: 11.3490CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1852/3236], Loss: 2.1353, Perplexity: 8.4600CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1853/3236], Loss: 2.0412, Perplexity: 7.7001CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1854/3236], Loss: 1.9945, Perplexity: 7.3488CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1855/3236], Loss: 2.1107, Perplexity: 8.2537CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1856/3236], Loss: 1.8878, Perplexity: 6.6047CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1857/3236], Loss: 1.9636, Perplexity: 7.1251CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1858/3236], Loss: 2.2032, Perplexity: 9.0537CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1859/3236], Loss: 2.0884, Perplexity: 8.0719CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1860/3236], Loss: 2.0255, Perplexity: 7.5797CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1861/3236], Loss: 2.1802, Perplexity: 8.8481CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1862/3236], Loss: 2.1153, Perplexity: 8.2919CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [1863/3236], Loss: 2.6816, Perplexity: 14.6083CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1864/3236], Loss: 1.9126, Perplexity: 6.7708CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 25])\n",
      "Epoch [1/1], Step [1865/3236], Loss: 3.0113, Perplexity: 20.3132CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1866/3236], Loss: 2.0353, Perplexity: 7.6543CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1867/3236], Loss: 2.1952, Perplexity: 8.9814CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1868/3236], Loss: 2.1131, Perplexity: 8.2739CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1869/3236], Loss: 2.0095, Perplexity: 7.4597CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1870/3236], Loss: 2.0270, Perplexity: 7.5913CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1871/3236], Loss: 1.9976, Perplexity: 7.3714CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1872/3236], Loss: 2.1497, Perplexity: 8.5822CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1873/3236], Loss: 2.3091, Perplexity: 10.0650CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1874/3236], Loss: 2.0119, Perplexity: 7.4772CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1875/3236], Loss: 2.1089, Perplexity: 8.2392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1876/3236], Loss: 2.0467, Perplexity: 7.7426CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1877/3236], Loss: 2.1606, Perplexity: 8.6760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1878/3236], Loss: 2.2291, Perplexity: 9.2918CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1879/3236], Loss: 1.8729, Perplexity: 6.5073CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1880/3236], Loss: 2.1327, Perplexity: 8.4379CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1881/3236], Loss: 2.0456, Perplexity: 7.7336CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1882/3236], Loss: 2.0479, Perplexity: 7.7520CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1883/3236], Loss: 2.0586, Perplexity: 7.8353CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1884/3236], Loss: 1.9710, Perplexity: 7.1775CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1885/3236], Loss: 2.0781, Perplexity: 7.9890CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1886/3236], Loss: 1.9572, Perplexity: 7.0796CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1887/3236], Loss: 2.0344, Perplexity: 7.6475CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1888/3236], Loss: 2.0295, Perplexity: 7.6105CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1889/3236], Loss: 2.0563, Perplexity: 7.8171CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1890/3236], Loss: 1.9361, Perplexity: 6.9315CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1891/3236], Loss: 2.1915, Perplexity: 8.9482CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1892/3236], Loss: 2.1328, Perplexity: 8.4386CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1893/3236], Loss: 2.1412, Perplexity: 8.5094CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1894/3236], Loss: 2.1250, Perplexity: 8.3727CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1895/3236], Loss: 2.0784, Perplexity: 7.9920CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1896/3236], Loss: 1.9070, Perplexity: 6.7326CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1897/3236], Loss: 1.9232, Perplexity: 6.8427CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1898/3236], Loss: 2.2815, Perplexity: 9.7918CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1899/3236], Loss: 2.2367, Perplexity: 9.3620CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1900/3236], Loss: 2.0149, Perplexity: 7.4997\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1901/3236], Loss: 2.0605, Perplexity: 7.8499CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1902/3236], Loss: 2.0668, Perplexity: 7.8999CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1903/3236], Loss: 2.2668, Perplexity: 9.6485CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1904/3236], Loss: 2.0560, Perplexity: 7.8143CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1905/3236], Loss: 1.9603, Perplexity: 7.1017CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1906/3236], Loss: 2.0361, Perplexity: 7.6610CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [1907/3236], Loss: 2.8640, Perplexity: 17.5318CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1908/3236], Loss: 1.9573, Perplexity: 7.0804CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1909/3236], Loss: 2.2161, Perplexity: 9.1719CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [1910/3236], Loss: 2.7727, Perplexity: 16.0018CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1911/3236], Loss: 2.1095, Perplexity: 8.2439CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1912/3236], Loss: 2.3875, Perplexity: 10.8861CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1913/3236], Loss: 1.9563, Perplexity: 7.0734CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1914/3236], Loss: 2.1746, Perplexity: 8.7983CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1915/3236], Loss: 1.9259, Perplexity: 6.8613CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [1916/3236], Loss: 2.5490, Perplexity: 12.7945CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1917/3236], Loss: 2.1643, Perplexity: 8.7088CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1918/3236], Loss: 1.9975, Perplexity: 7.3706CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1919/3236], Loss: 2.1673, Perplexity: 8.7344CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1920/3236], Loss: 2.1515, Perplexity: 8.5981CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1921/3236], Loss: 2.1494, Perplexity: 8.5796CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1922/3236], Loss: 2.0981, Perplexity: 8.1505CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1923/3236], Loss: 2.0433, Perplexity: 7.7160CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1924/3236], Loss: 2.0251, Perplexity: 7.5768CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1925/3236], Loss: 2.0849, Perplexity: 8.0441CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1926/3236], Loss: 2.1116, Perplexity: 8.2615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [1927/3236], Loss: 2.8877, Perplexity: 17.9527CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1928/3236], Loss: 2.0824, Perplexity: 8.0237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1929/3236], Loss: 2.0904, Perplexity: 8.0881CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1930/3236], Loss: 2.3657, Perplexity: 10.6514CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1931/3236], Loss: 2.1000, Perplexity: 8.1663CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1932/3236], Loss: 2.0256, Perplexity: 7.5804CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1933/3236], Loss: 2.0733, Perplexity: 7.9507CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1934/3236], Loss: 2.0935, Perplexity: 8.1130CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1935/3236], Loss: 2.0985, Perplexity: 8.1540CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1936/3236], Loss: 2.0753, Perplexity: 7.9670CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1937/3236], Loss: 2.0050, Perplexity: 7.4261CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1938/3236], Loss: 1.9371, Perplexity: 6.9387CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1939/3236], Loss: 2.1665, Perplexity: 8.7273CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1940/3236], Loss: 2.1247, Perplexity: 8.3702CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1941/3236], Loss: 2.0757, Perplexity: 7.9699CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1942/3236], Loss: 1.9066, Perplexity: 6.7299CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1943/3236], Loss: 2.0025, Perplexity: 7.4077CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1944/3236], Loss: 2.1179, Perplexity: 8.3139CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1945/3236], Loss: 2.1973, Perplexity: 9.0009CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1946/3236], Loss: 2.2693, Perplexity: 9.6722CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1947/3236], Loss: 1.9280, Perplexity: 6.8755CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1948/3236], Loss: 1.9050, Perplexity: 6.7196CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [1949/3236], Loss: 2.3452, Perplexity: 10.4353CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1950/3236], Loss: 2.0670, Perplexity: 7.9013CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1951/3236], Loss: 2.0209, Perplexity: 7.5449CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1952/3236], Loss: 2.2235, Perplexity: 9.2393CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1953/3236], Loss: 2.0977, Perplexity: 8.1472CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1954/3236], Loss: 2.0610, Perplexity: 7.8541CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1955/3236], Loss: 1.9708, Perplexity: 7.1761CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1956/3236], Loss: 2.1429, Perplexity: 8.5243CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1957/3236], Loss: 2.1015, Perplexity: 8.1780CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1958/3236], Loss: 2.1527, Perplexity: 8.6077CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 27])\n",
      "Epoch [1/1], Step [1959/3236], Loss: 3.1900, Perplexity: 24.2884CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1960/3236], Loss: 1.9214, Perplexity: 6.8306CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1961/3236], Loss: 2.0005, Perplexity: 7.3924CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1962/3236], Loss: 1.9898, Perplexity: 7.3140CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [1963/3236], Loss: 2.4327, Perplexity: 11.3898CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1964/3236], Loss: 2.2689, Perplexity: 9.6683CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1965/3236], Loss: 2.0446, Perplexity: 7.7258CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1966/3236], Loss: 2.0814, Perplexity: 8.0156CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1967/3236], Loss: 2.4157, Perplexity: 11.1976CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1968/3236], Loss: 2.0429, Perplexity: 7.7126CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1969/3236], Loss: 2.1530, Perplexity: 8.6109CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1970/3236], Loss: 2.0549, Perplexity: 7.8061CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [1971/3236], Loss: 2.7080, Perplexity: 14.9988CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1972/3236], Loss: 1.9948, Perplexity: 7.3509CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1973/3236], Loss: 2.2780, Perplexity: 9.7569CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1974/3236], Loss: 2.0072, Perplexity: 7.4427CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1975/3236], Loss: 2.1175, Perplexity: 8.3106CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1976/3236], Loss: 2.1285, Perplexity: 8.4023CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1977/3236], Loss: 1.9486, Perplexity: 7.0191CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1978/3236], Loss: 2.2346, Perplexity: 9.3428CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [1979/3236], Loss: 2.2991, Perplexity: 9.9652CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [1980/3236], Loss: 2.3288, Perplexity: 10.2657CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [1981/3236], Loss: 2.0688, Perplexity: 7.9150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1982/3236], Loss: 1.9371, Perplexity: 6.9387CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1983/3236], Loss: 1.9829, Perplexity: 7.2636CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1984/3236], Loss: 2.0773, Perplexity: 7.9827CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1985/3236], Loss: 2.1560, Perplexity: 8.6364CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1986/3236], Loss: 1.9916, Perplexity: 7.3273CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1987/3236], Loss: 2.0293, Perplexity: 7.6089CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1988/3236], Loss: 2.1733, Perplexity: 8.7874CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1989/3236], Loss: 2.0731, Perplexity: 7.9498CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [1990/3236], Loss: 2.1089, Perplexity: 8.2389CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [1991/3236], Loss: 2.0309, Perplexity: 7.6213CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1992/3236], Loss: 2.1464, Perplexity: 8.5541CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1993/3236], Loss: 2.0507, Perplexity: 7.7730CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1994/3236], Loss: 2.0927, Perplexity: 8.1066CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [1995/3236], Loss: 2.0561, Perplexity: 7.8154CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1996/3236], Loss: 1.9398, Perplexity: 6.9572CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1997/3236], Loss: 1.9742, Perplexity: 7.2010CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1998/3236], Loss: 2.0533, Perplexity: 7.7934CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [1999/3236], Loss: 1.9931, Perplexity: 7.3381CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2000/3236], Loss: 2.0121, Perplexity: 7.4790\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2001/3236], Loss: 2.0305, Perplexity: 7.6181CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2002/3236], Loss: 2.0683, Perplexity: 7.9116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2003/3236], Loss: 2.0254, Perplexity: 7.5795CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2004/3236], Loss: 2.8400, Perplexity: 17.1157CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2005/3236], Loss: 2.1573, Perplexity: 8.6481CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2006/3236], Loss: 1.9792, Perplexity: 7.2370CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2007/3236], Loss: 2.5234, Perplexity: 12.4712CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2008/3236], Loss: 2.1993, Perplexity: 9.0190CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2009/3236], Loss: 2.0927, Perplexity: 8.1064CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2010/3236], Loss: 2.0272, Perplexity: 7.5930CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2011/3236], Loss: 2.0158, Perplexity: 7.5064CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2012/3236], Loss: 2.2481, Perplexity: 9.4693CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2013/3236], Loss: 2.0463, Perplexity: 7.7392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2014/3236], Loss: 2.3569, Perplexity: 10.5577CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2015/3236], Loss: 2.1959, Perplexity: 8.9880CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2016/3236], Loss: 2.0908, Perplexity: 8.0910CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2017/3236], Loss: 2.0035, Perplexity: 7.4149CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2018/3236], Loss: 2.0917, Perplexity: 8.0983CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2019/3236], Loss: 1.9724, Perplexity: 7.1876CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2020/3236], Loss: 1.9438, Perplexity: 6.9853CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2021/3236], Loss: 2.1666, Perplexity: 8.7287CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2022/3236], Loss: 2.3563, Perplexity: 10.5517CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2023/3236], Loss: 2.1567, Perplexity: 8.6427CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2024/3236], Loss: 2.0777, Perplexity: 7.9862CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2025/3236], Loss: 2.0656, Perplexity: 7.8902CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2026/3236], Loss: 1.9966, Perplexity: 7.3637CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2027/3236], Loss: 1.9681, Perplexity: 7.1568CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2028/3236], Loss: 2.0160, Perplexity: 7.5083CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2029/3236], Loss: 2.1660, Perplexity: 8.7235CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2030/3236], Loss: 1.9711, Perplexity: 7.1787CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2031/3236], Loss: 2.3784, Perplexity: 10.7874CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2032/3236], Loss: 2.1398, Perplexity: 8.4978CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2033/3236], Loss: 2.2784, Perplexity: 9.7610CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2034/3236], Loss: 2.3020, Perplexity: 9.9937CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2035/3236], Loss: 1.9932, Perplexity: 7.3391CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2036/3236], Loss: 2.2452, Perplexity: 9.4420CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2037/3236], Loss: 2.0868, Perplexity: 8.0588CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2038/3236], Loss: 2.1025, Perplexity: 8.1865CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2039/3236], Loss: 2.1465, Perplexity: 8.5545CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2040/3236], Loss: 2.0135, Perplexity: 7.4895CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2041/3236], Loss: 2.1502, Perplexity: 8.5864CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2042/3236], Loss: 2.0819, Perplexity: 8.0200CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2043/3236], Loss: 1.9706, Perplexity: 7.1751CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2044/3236], Loss: 2.2549, Perplexity: 9.5348CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2045/3236], Loss: 2.1044, Perplexity: 8.2024CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2046/3236], Loss: 1.9924, Perplexity: 7.3334CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2047/3236], Loss: 2.1279, Perplexity: 8.3971CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2048/3236], Loss: 2.0381, Perplexity: 7.6757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2049/3236], Loss: 2.1178, Perplexity: 8.3129CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2050/3236], Loss: 1.9612, Perplexity: 7.1079CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2051/3236], Loss: 1.9471, Perplexity: 7.0084CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2052/3236], Loss: 2.0546, Perplexity: 7.8040CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2053/3236], Loss: 2.1577, Perplexity: 8.6515CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2054/3236], Loss: 2.0708, Perplexity: 7.9309CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2055/3236], Loss: 2.0646, Perplexity: 7.8824CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2056/3236], Loss: 2.2559, Perplexity: 9.5438CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2057/3236], Loss: 2.0209, Perplexity: 7.5448CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2058/3236], Loss: 1.9831, Perplexity: 7.2653CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2059/3236], Loss: 1.8992, Perplexity: 6.6807CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2060/3236], Loss: 1.9877, Perplexity: 7.2989CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2061/3236], Loss: 2.0807, Perplexity: 8.0103CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2062/3236], Loss: 1.9428, Perplexity: 6.9783CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2063/3236], Loss: 2.3553, Perplexity: 10.5409CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2064/3236], Loss: 2.1287, Perplexity: 8.4035CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2065/3236], Loss: 2.1975, Perplexity: 9.0027CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2066/3236], Loss: 1.8911, Perplexity: 6.6264CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2067/3236], Loss: 2.6846, Perplexity: 14.6516CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2068/3236], Loss: 2.1143, Perplexity: 8.2840CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2069/3236], Loss: 2.0622, Perplexity: 7.8634CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2070/3236], Loss: 2.0378, Perplexity: 7.6737CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2071/3236], Loss: 2.0057, Perplexity: 7.4316CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2072/3236], Loss: 2.1343, Perplexity: 8.4514CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2073/3236], Loss: 2.0026, Perplexity: 7.4085CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [2074/3236], Loss: 2.7859, Perplexity: 16.2151CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2075/3236], Loss: 2.0734, Perplexity: 7.9519CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2076/3236], Loss: 2.2647, Perplexity: 9.6285CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2077/3236], Loss: 2.2139, Perplexity: 9.1513CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2078/3236], Loss: 2.1776, Perplexity: 8.8253CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2079/3236], Loss: 1.9896, Perplexity: 7.3123CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2080/3236], Loss: 2.0111, Perplexity: 7.4714CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2081/3236], Loss: 2.6418, Perplexity: 14.0391CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2082/3236], Loss: 1.9328, Perplexity: 6.9088CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2083/3236], Loss: 2.1024, Perplexity: 8.1854CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2084/3236], Loss: 2.0226, Perplexity: 7.5579CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [2085/3236], Loss: 2.8932, Perplexity: 18.0502CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2086/3236], Loss: 1.9039, Perplexity: 6.7122CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2087/3236], Loss: 2.1946, Perplexity: 8.9763CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2088/3236], Loss: 2.1806, Perplexity: 8.8516CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2089/3236], Loss: 2.0320, Perplexity: 7.6293CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2090/3236], Loss: 2.2241, Perplexity: 9.2450CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2091/3236], Loss: 1.9609, Perplexity: 7.1054CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2092/3236], Loss: 2.0310, Perplexity: 7.6220CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2093/3236], Loss: 2.0294, Perplexity: 7.6094CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2094/3236], Loss: 2.0077, Perplexity: 7.4461CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2095/3236], Loss: 2.0749, Perplexity: 7.9639CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2096/3236], Loss: 2.2284, Perplexity: 9.2846CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2097/3236], Loss: 2.1116, Perplexity: 8.2613CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2098/3236], Loss: 1.9903, Perplexity: 7.3180CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2099/3236], Loss: 1.9977, Perplexity: 7.3724CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2100/3236], Loss: 2.0729, Perplexity: 7.9479\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2101/3236], Loss: 2.1487, Perplexity: 8.5740CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2102/3236], Loss: 2.0528, Perplexity: 7.7898CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2103/3236], Loss: 2.1705, Perplexity: 8.7628CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2104/3236], Loss: 2.1928, Perplexity: 8.9601CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2105/3236], Loss: 2.0021, Perplexity: 7.4044CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2106/3236], Loss: 2.4812, Perplexity: 11.9554CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2107/3236], Loss: 2.7399, Perplexity: 15.4847CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2108/3236], Loss: 2.0188, Perplexity: 7.5293CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2109/3236], Loss: 2.0495, Perplexity: 7.7639CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2110/3236], Loss: 1.9766, Perplexity: 7.2181CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2111/3236], Loss: 1.9962, Perplexity: 7.3614CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2112/3236], Loss: 2.0187, Perplexity: 7.5286CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2113/3236], Loss: 1.9196, Perplexity: 6.8184CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2114/3236], Loss: 2.1763, Perplexity: 8.8134CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2115/3236], Loss: 2.4108, Perplexity: 11.1432CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2116/3236], Loss: 2.2895, Perplexity: 9.8700CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2117/3236], Loss: 2.0786, Perplexity: 7.9933CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2118/3236], Loss: 2.0297, Perplexity: 7.6116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2119/3236], Loss: 2.4239, Perplexity: 11.2900CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2120/3236], Loss: 2.0873, Perplexity: 8.0632CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2121/3236], Loss: 2.0286, Perplexity: 7.6038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2122/3236], Loss: 2.5423, Perplexity: 12.7082CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2123/3236], Loss: 1.9603, Perplexity: 7.1014CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2124/3236], Loss: 2.1625, Perplexity: 8.6929CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2125/3236], Loss: 2.5870, Perplexity: 13.2896CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2126/3236], Loss: 1.8987, Perplexity: 6.6771CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2127/3236], Loss: 2.0086, Perplexity: 7.4528CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2128/3236], Loss: 2.0133, Perplexity: 7.4878CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2129/3236], Loss: 2.0849, Perplexity: 8.0439CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2130/3236], Loss: 2.0338, Perplexity: 7.6428CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2131/3236], Loss: 2.0609, Perplexity: 7.8533CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2132/3236], Loss: 2.1231, Perplexity: 8.3573CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2133/3236], Loss: 2.5304, Perplexity: 12.5581CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2134/3236], Loss: 1.9273, Perplexity: 6.8710CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2135/3236], Loss: 2.4079, Perplexity: 11.1102CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2136/3236], Loss: 1.9170, Perplexity: 6.8003CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2137/3236], Loss: 2.1872, Perplexity: 8.9100CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2138/3236], Loss: 2.0512, Perplexity: 7.7775CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2139/3236], Loss: 2.0410, Perplexity: 7.6979CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2140/3236], Loss: 1.9091, Perplexity: 6.7473CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2141/3236], Loss: 2.0349, Perplexity: 7.6518CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [2142/3236], Loss: 2.7380, Perplexity: 15.4560CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2143/3236], Loss: 2.2223, Perplexity: 9.2286CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2144/3236], Loss: 2.0866, Perplexity: 8.0575CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2145/3236], Loss: 1.9275, Perplexity: 6.8723CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2146/3236], Loss: 2.0480, Perplexity: 7.7524CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2147/3236], Loss: 2.0577, Perplexity: 7.8280CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2148/3236], Loss: 2.0012, Perplexity: 7.3981CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2149/3236], Loss: 2.0854, Perplexity: 8.0481CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2150/3236], Loss: 2.0028, Perplexity: 7.4098CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2151/3236], Loss: 2.1341, Perplexity: 8.4496CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2152/3236], Loss: 1.9838, Perplexity: 7.2706CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2153/3236], Loss: 2.1637, Perplexity: 8.7034CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2154/3236], Loss: 2.2691, Perplexity: 9.6703CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2155/3236], Loss: 2.1696, Perplexity: 8.7545CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2156/3236], Loss: 2.2867, Perplexity: 9.8428CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2157/3236], Loss: 2.0762, Perplexity: 7.9739CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2158/3236], Loss: 2.1475, Perplexity: 8.5635CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2159/3236], Loss: 2.0104, Perplexity: 7.4666CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 24])\n",
      "Epoch [1/1], Step [2160/3236], Loss: 3.0854, Perplexity: 21.8761CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2161/3236], Loss: 2.3240, Perplexity: 10.2168CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2162/3236], Loss: 1.8889, Perplexity: 6.6120CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2163/3236], Loss: 1.9510, Perplexity: 7.0359CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2164/3236], Loss: 2.0267, Perplexity: 7.5893CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2165/3236], Loss: 2.1469, Perplexity: 8.5581CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2166/3236], Loss: 2.1499, Perplexity: 8.5841CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2167/3236], Loss: 2.2027, Perplexity: 9.0492CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2168/3236], Loss: 2.1882, Perplexity: 8.9190CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2169/3236], Loss: 2.0978, Perplexity: 8.1482CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2170/3236], Loss: 2.1847, Perplexity: 8.8882CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2171/3236], Loss: 2.1860, Perplexity: 8.8998CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2172/3236], Loss: 2.0379, Perplexity: 7.6747CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2173/3236], Loss: 1.9948, Perplexity: 7.3510CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 28])\n",
      "Epoch [1/1], Step [2174/3236], Loss: 3.3854, Perplexity: 29.5287CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2175/3236], Loss: 2.0243, Perplexity: 7.5705CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2176/3236], Loss: 1.9159, Perplexity: 6.7932CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2177/3236], Loss: 2.1710, Perplexity: 8.7673CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2178/3236], Loss: 2.6268, Perplexity: 13.8297CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2179/3236], Loss: 2.0472, Perplexity: 7.7462CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2180/3236], Loss: 2.0302, Perplexity: 7.6153CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2181/3236], Loss: 2.1112, Perplexity: 8.2582CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2182/3236], Loss: 2.2961, Perplexity: 9.9349CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2183/3236], Loss: 2.0994, Perplexity: 8.1610CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [2184/3236], Loss: 2.8380, Perplexity: 17.0823CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2185/3236], Loss: 2.0650, Perplexity: 7.8857CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2186/3236], Loss: 1.9741, Perplexity: 7.1998CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2187/3236], Loss: 2.0863, Perplexity: 8.0547CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2188/3236], Loss: 2.5781, Perplexity: 13.1726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2189/3236], Loss: 2.3819, Perplexity: 10.8251CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2190/3236], Loss: 1.9802, Perplexity: 7.2444CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2191/3236], Loss: 2.2593, Perplexity: 9.5764CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2192/3236], Loss: 2.0186, Perplexity: 7.5279CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2193/3236], Loss: 1.9830, Perplexity: 7.2645CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2194/3236], Loss: 2.0936, Perplexity: 8.1144CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2195/3236], Loss: 2.1439, Perplexity: 8.5328CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2196/3236], Loss: 2.0501, Perplexity: 7.7690CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2197/3236], Loss: 2.0890, Perplexity: 8.0769CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2198/3236], Loss: 2.0747, Perplexity: 7.9621CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2199/3236], Loss: 2.4962, Perplexity: 12.1361CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2200/3236], Loss: 2.1258, Perplexity: 8.3796\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2201/3236], Loss: 2.2895, Perplexity: 9.8700CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2202/3236], Loss: 2.1510, Perplexity: 8.5931CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2203/3236], Loss: 2.3758, Perplexity: 10.7595CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2204/3236], Loss: 2.1356, Perplexity: 8.4617CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2205/3236], Loss: 2.1309, Perplexity: 8.4225CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2206/3236], Loss: 1.9577, Perplexity: 7.0832CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2207/3236], Loss: 2.2333, Perplexity: 9.3311CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2208/3236], Loss: 2.0622, Perplexity: 7.8636CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2209/3236], Loss: 2.1167, Perplexity: 8.3038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2210/3236], Loss: 2.0560, Perplexity: 7.8147CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2211/3236], Loss: 1.9896, Perplexity: 7.3122CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2212/3236], Loss: 2.1888, Perplexity: 8.9244CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2213/3236], Loss: 2.1061, Perplexity: 8.2161CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2214/3236], Loss: 2.5143, Perplexity: 12.3577CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2215/3236], Loss: 2.0158, Perplexity: 7.5064CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2216/3236], Loss: 2.1468, Perplexity: 8.5573CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2217/3236], Loss: 1.9792, Perplexity: 7.2368CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2218/3236], Loss: 2.0680, Perplexity: 7.9090CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2219/3236], Loss: 2.0238, Perplexity: 7.5672CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2220/3236], Loss: 1.9864, Perplexity: 7.2890CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2221/3236], Loss: 2.0101, Perplexity: 7.4638CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2222/3236], Loss: 2.2081, Perplexity: 9.0981CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2223/3236], Loss: 2.1231, Perplexity: 8.3568CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2224/3236], Loss: 2.0473, Perplexity: 7.7470CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2225/3236], Loss: 1.9891, Perplexity: 7.3091CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2226/3236], Loss: 1.9024, Perplexity: 6.7017CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2227/3236], Loss: 2.0270, Perplexity: 7.5913CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2228/3236], Loss: 2.7417, Perplexity: 15.5139CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2229/3236], Loss: 2.1070, Perplexity: 8.2238CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2230/3236], Loss: 2.1587, Perplexity: 8.6600CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2231/3236], Loss: 2.0596, Perplexity: 7.8429CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2232/3236], Loss: 2.0109, Perplexity: 7.4703CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2233/3236], Loss: 1.9807, Perplexity: 7.2480CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2234/3236], Loss: 2.0771, Perplexity: 7.9813CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2235/3236], Loss: 2.0228, Perplexity: 7.5592CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2236/3236], Loss: 1.9625, Perplexity: 7.1170CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2237/3236], Loss: 2.1000, Perplexity: 8.1665CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2238/3236], Loss: 2.1973, Perplexity: 9.0006CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2239/3236], Loss: 1.9892, Perplexity: 7.3095CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2240/3236], Loss: 2.0681, Perplexity: 7.9099CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2241/3236], Loss: 2.1448, Perplexity: 8.5405CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2242/3236], Loss: 2.5818, Perplexity: 13.2212CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2243/3236], Loss: 2.1795, Perplexity: 8.8420CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2244/3236], Loss: 2.1280, Perplexity: 8.3984CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2245/3236], Loss: 1.8776, Perplexity: 6.5380CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2246/3236], Loss: 2.0953, Perplexity: 8.1282CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2247/3236], Loss: 2.1905, Perplexity: 8.9394CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2248/3236], Loss: 2.4180, Perplexity: 11.2235CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2249/3236], Loss: 2.1407, Perplexity: 8.5052CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2250/3236], Loss: 2.0779, Perplexity: 7.9880CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2251/3236], Loss: 2.1103, Perplexity: 8.2506CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2252/3236], Loss: 1.9394, Perplexity: 6.9546CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2253/3236], Loss: 1.9425, Perplexity: 6.9764CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2254/3236], Loss: 1.9599, Perplexity: 7.0983CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2255/3236], Loss: 2.0313, Perplexity: 7.6243CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2256/3236], Loss: 2.0659, Perplexity: 7.8923CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2257/3236], Loss: 2.0365, Perplexity: 7.6639CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2258/3236], Loss: 1.9419, Perplexity: 6.9720CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2259/3236], Loss: 2.0877, Perplexity: 8.0660CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2260/3236], Loss: 1.9853, Perplexity: 7.2811CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2261/3236], Loss: 1.9404, Perplexity: 6.9614CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2262/3236], Loss: 2.1508, Perplexity: 8.5914CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2263/3236], Loss: 2.0045, Perplexity: 7.4226CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2264/3236], Loss: 2.1909, Perplexity: 8.9436CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2265/3236], Loss: 1.9468, Perplexity: 7.0059CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2266/3236], Loss: 2.0600, Perplexity: 7.8462CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2267/3236], Loss: 2.0673, Perplexity: 7.9038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2268/3236], Loss: 2.0082, Perplexity: 7.4499CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2269/3236], Loss: 2.0382, Perplexity: 7.6767CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2270/3236], Loss: 1.9891, Perplexity: 7.3088CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2271/3236], Loss: 2.0678, Perplexity: 7.9074CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2272/3236], Loss: 2.0821, Perplexity: 8.0215CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2273/3236], Loss: 2.1360, Perplexity: 8.4654CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 27])\n",
      "Epoch [1/1], Step [2274/3236], Loss: 3.1273, Perplexity: 22.8116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 27])\n",
      "Epoch [1/1], Step [2275/3236], Loss: 3.0485, Perplexity: 21.0830CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2276/3236], Loss: 2.2197, Perplexity: 9.2045CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2277/3236], Loss: 2.0402, Perplexity: 7.6920CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2278/3236], Loss: 2.2907, Perplexity: 9.8821CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2279/3236], Loss: 2.2738, Perplexity: 9.7161CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2280/3236], Loss: 2.1292, Perplexity: 8.4079CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2281/3236], Loss: 2.1838, Perplexity: 8.8801CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2282/3236], Loss: 2.0366, Perplexity: 7.6643CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2283/3236], Loss: 2.0905, Perplexity: 8.0887CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2284/3236], Loss: 2.0981, Perplexity: 8.1505CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2285/3236], Loss: 2.1877, Perplexity: 8.9147CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2286/3236], Loss: 2.1787, Perplexity: 8.8344CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2287/3236], Loss: 2.0751, Perplexity: 7.9653CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2288/3236], Loss: 2.4873, Perplexity: 12.0286CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2289/3236], Loss: 2.0399, Perplexity: 7.6901CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2290/3236], Loss: 2.1169, Perplexity: 8.3057CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2291/3236], Loss: 2.2144, Perplexity: 9.1558CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2292/3236], Loss: 2.0181, Perplexity: 7.5241CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2293/3236], Loss: 2.2221, Perplexity: 9.2269CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2294/3236], Loss: 2.0866, Perplexity: 8.0579CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2295/3236], Loss: 2.0488, Perplexity: 7.7582CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2296/3236], Loss: 2.0776, Perplexity: 7.9852CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2297/3236], Loss: 1.9152, Perplexity: 6.7885CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2298/3236], Loss: 2.0585, Perplexity: 7.8344CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2299/3236], Loss: 2.1570, Perplexity: 8.6448CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2300/3236], Loss: 2.0891, Perplexity: 8.0775\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2301/3236], Loss: 1.9485, Perplexity: 7.0179CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2302/3236], Loss: 2.0360, Perplexity: 7.6602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2303/3236], Loss: 2.1098, Perplexity: 8.2463CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2304/3236], Loss: 2.5061, Perplexity: 12.2576CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2305/3236], Loss: 2.1106, Perplexity: 8.2533CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2306/3236], Loss: 1.9681, Perplexity: 7.1569CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2307/3236], Loss: 1.9757, Perplexity: 7.2115CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2308/3236], Loss: 2.1854, Perplexity: 8.8939CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2309/3236], Loss: 2.2486, Perplexity: 9.4744CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2310/3236], Loss: 2.1513, Perplexity: 8.5963CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2311/3236], Loss: 2.3219, Perplexity: 10.1945CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2312/3236], Loss: 2.0475, Perplexity: 7.7484CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2313/3236], Loss: 2.3923, Perplexity: 10.9387CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2314/3236], Loss: 2.2355, Perplexity: 9.3510CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2315/3236], Loss: 2.3858, Perplexity: 10.8683CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2316/3236], Loss: 2.0786, Perplexity: 7.9937CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2317/3236], Loss: 2.4683, Perplexity: 11.8018CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2318/3236], Loss: 2.1055, Perplexity: 8.2108CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2319/3236], Loss: 2.1806, Perplexity: 8.8519CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2320/3236], Loss: 2.0271, Perplexity: 7.5919CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2321/3236], Loss: 2.2440, Perplexity: 9.4312CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2322/3236], Loss: 2.2944, Perplexity: 9.9181CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2323/3236], Loss: 2.1929, Perplexity: 8.9611CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2324/3236], Loss: 2.1968, Perplexity: 8.9963CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2325/3236], Loss: 1.9991, Perplexity: 7.3822CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2326/3236], Loss: 2.0899, Perplexity: 8.0843CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2327/3236], Loss: 2.0947, Perplexity: 8.1229CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2328/3236], Loss: 2.0042, Perplexity: 7.4205CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2329/3236], Loss: 2.0777, Perplexity: 7.9862CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2330/3236], Loss: 2.0956, Perplexity: 8.1303CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2331/3236], Loss: 2.0981, Perplexity: 8.1507CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2332/3236], Loss: 2.3267, Perplexity: 10.2443CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2333/3236], Loss: 2.3372, Perplexity: 10.3525CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2334/3236], Loss: 2.0236, Perplexity: 7.5658CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2335/3236], Loss: 1.9486, Perplexity: 7.0189CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2336/3236], Loss: 2.1812, Perplexity: 8.8570CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2337/3236], Loss: 2.0180, Perplexity: 7.5230CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [2338/3236], Loss: 2.8583, Perplexity: 17.4312CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2339/3236], Loss: 1.9899, Perplexity: 7.3150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2340/3236], Loss: 2.2787, Perplexity: 9.7640CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2341/3236], Loss: 1.9334, Perplexity: 6.9127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2342/3236], Loss: 2.0638, Perplexity: 7.8755CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2343/3236], Loss: 2.3232, Perplexity: 10.2082CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2344/3236], Loss: 2.3185, Perplexity: 10.1605CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2345/3236], Loss: 2.0532, Perplexity: 7.7930CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2346/3236], Loss: 1.9500, Perplexity: 7.0287CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2347/3236], Loss: 1.9731, Perplexity: 7.1929CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2348/3236], Loss: 2.0220, Perplexity: 7.5535CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2349/3236], Loss: 1.9894, Perplexity: 7.3110CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2350/3236], Loss: 2.1595, Perplexity: 8.6670CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2351/3236], Loss: 2.0023, Perplexity: 7.4064CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2352/3236], Loss: 2.3021, Perplexity: 9.9951CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2353/3236], Loss: 2.0626, Perplexity: 7.8663CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2354/3236], Loss: 2.0687, Perplexity: 7.9142CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2355/3236], Loss: 2.0617, Perplexity: 7.8593CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2356/3236], Loss: 2.1156, Perplexity: 8.2946CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2357/3236], Loss: 2.1501, Perplexity: 8.5858CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2358/3236], Loss: 1.9703, Perplexity: 7.1731CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2359/3236], Loss: 1.9906, Perplexity: 7.3201CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2360/3236], Loss: 2.0977, Perplexity: 8.1470CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2361/3236], Loss: 2.0000, Perplexity: 7.3894CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2362/3236], Loss: 1.9451, Perplexity: 6.9945CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2363/3236], Loss: 2.6754, Perplexity: 14.5181CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2364/3236], Loss: 2.0442, Perplexity: 7.7231CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2365/3236], Loss: 1.9803, Perplexity: 7.2450CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2366/3236], Loss: 2.2095, Perplexity: 9.1110CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2367/3236], Loss: 1.9439, Perplexity: 6.9861CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2368/3236], Loss: 2.0443, Perplexity: 7.7235CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2369/3236], Loss: 2.0265, Perplexity: 7.5874CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2370/3236], Loss: 1.9129, Perplexity: 6.7728CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2371/3236], Loss: 2.0348, Perplexity: 7.6506CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2372/3236], Loss: 2.6032, Perplexity: 13.5068CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2373/3236], Loss: 1.9747, Perplexity: 7.2042CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2374/3236], Loss: 1.9141, Perplexity: 6.7807CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2375/3236], Loss: 2.1668, Perplexity: 8.7305CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2376/3236], Loss: 2.0859, Perplexity: 8.0522CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2377/3236], Loss: 2.0712, Perplexity: 7.9344CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2378/3236], Loss: 1.9363, Perplexity: 6.9327CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2379/3236], Loss: 2.0010, Perplexity: 7.3962CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2380/3236], Loss: 1.8716, Perplexity: 6.4984CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2381/3236], Loss: 2.0883, Perplexity: 8.0713CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2382/3236], Loss: 2.1155, Perplexity: 8.2935CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2383/3236], Loss: 2.1587, Perplexity: 8.6596CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2384/3236], Loss: 2.0001, Perplexity: 7.3895CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2385/3236], Loss: 2.0866, Perplexity: 8.0579CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2386/3236], Loss: 2.0921, Perplexity: 8.1020CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2387/3236], Loss: 1.8947, Perplexity: 6.6503CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2388/3236], Loss: 2.1773, Perplexity: 8.8223CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2389/3236], Loss: 1.9992, Perplexity: 7.3832CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2390/3236], Loss: 2.2448, Perplexity: 9.4389CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2391/3236], Loss: 2.0442, Perplexity: 7.7228CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2392/3236], Loss: 2.0619, Perplexity: 7.8611CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2393/3236], Loss: 2.1766, Perplexity: 8.8166CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2394/3236], Loss: 2.1786, Perplexity: 8.8344CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2395/3236], Loss: 2.0273, Perplexity: 7.5935CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2396/3236], Loss: 1.9909, Perplexity: 7.3225CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2397/3236], Loss: 1.9918, Perplexity: 7.3290CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2398/3236], Loss: 2.0181, Perplexity: 7.5239CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2399/3236], Loss: 2.3811, Perplexity: 10.8165CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2400/3236], Loss: 2.3177, Perplexity: 10.1525\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2401/3236], Loss: 1.9880, Perplexity: 7.3012CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2402/3236], Loss: 2.3004, Perplexity: 9.9780CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2403/3236], Loss: 2.7246, Perplexity: 15.2508CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2404/3236], Loss: 1.9665, Perplexity: 7.1454CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2405/3236], Loss: 2.4410, Perplexity: 11.4842CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2406/3236], Loss: 2.3367, Perplexity: 10.3469CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2407/3236], Loss: 2.0661, Perplexity: 7.8938CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2408/3236], Loss: 1.9213, Perplexity: 6.8299CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2409/3236], Loss: 2.3317, Perplexity: 10.2958CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2410/3236], Loss: 1.9491, Perplexity: 7.0225CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2411/3236], Loss: 1.9278, Perplexity: 6.8742CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2412/3236], Loss: 1.9961, Perplexity: 7.3602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2413/3236], Loss: 2.0441, Perplexity: 7.7219CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2414/3236], Loss: 2.3384, Perplexity: 10.3643CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2415/3236], Loss: 2.0885, Perplexity: 8.0729CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2416/3236], Loss: 2.1268, Perplexity: 8.3882CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2417/3236], Loss: 2.1079, Perplexity: 8.2312CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2418/3236], Loss: 2.0585, Perplexity: 7.8339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2419/3236], Loss: 2.0828, Perplexity: 8.0269CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2420/3236], Loss: 2.0091, Perplexity: 7.4564CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2421/3236], Loss: 2.2701, Perplexity: 9.6802CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2422/3236], Loss: 2.5322, Perplexity: 12.5808CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 24])\n",
      "Epoch [1/1], Step [2423/3236], Loss: 2.9368, Perplexity: 18.8550CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2424/3236], Loss: 2.0154, Perplexity: 7.5034CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2425/3236], Loss: 2.1392, Perplexity: 8.4924CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2426/3236], Loss: 2.0661, Perplexity: 7.8941CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2427/3236], Loss: 2.2460, Perplexity: 9.4499CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2428/3236], Loss: 2.0462, Perplexity: 7.7381CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2429/3236], Loss: 2.0655, Perplexity: 7.8889CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2430/3236], Loss: 2.0695, Perplexity: 7.9212CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2431/3236], Loss: 2.0526, Perplexity: 7.7884CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2432/3236], Loss: 2.1398, Perplexity: 8.4980CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2433/3236], Loss: 1.9045, Perplexity: 6.7162CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2434/3236], Loss: 2.0875, Perplexity: 8.0650CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2435/3236], Loss: 1.8976, Perplexity: 6.6696CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2436/3236], Loss: 2.0538, Perplexity: 7.7971CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2437/3236], Loss: 2.3075, Perplexity: 10.0494CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2438/3236], Loss: 2.0803, Perplexity: 8.0068CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2439/3236], Loss: 2.1421, Perplexity: 8.5172CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2440/3236], Loss: 2.0901, Perplexity: 8.0854CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2441/3236], Loss: 2.0043, Perplexity: 7.4211CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2442/3236], Loss: 2.0306, Perplexity: 7.6183CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [2443/3236], Loss: 2.7039, Perplexity: 14.9375CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2444/3236], Loss: 2.0122, Perplexity: 7.4801CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [2445/3236], Loss: 2.7851, Perplexity: 16.2010CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2446/3236], Loss: 2.1606, Perplexity: 8.6764CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2447/3236], Loss: 2.1191, Perplexity: 8.3238CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2448/3236], Loss: 1.9877, Perplexity: 7.2986CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2449/3236], Loss: 2.1359, Perplexity: 8.4646CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2450/3236], Loss: 2.0466, Perplexity: 7.7417CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2451/3236], Loss: 2.1430, Perplexity: 8.5249CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2452/3236], Loss: 2.1489, Perplexity: 8.5757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2453/3236], Loss: 2.3505, Perplexity: 10.4908CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2454/3236], Loss: 2.1089, Perplexity: 8.2396CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2455/3236], Loss: 1.9929, Perplexity: 7.3365CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2456/3236], Loss: 2.0602, Perplexity: 7.8477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2457/3236], Loss: 1.9915, Perplexity: 7.3265CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2458/3236], Loss: 2.0108, Perplexity: 7.4690CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2459/3236], Loss: 2.0249, Perplexity: 7.5756CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2460/3236], Loss: 2.0915, Perplexity: 8.0974CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2461/3236], Loss: 1.9762, Perplexity: 7.2150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2462/3236], Loss: 2.0617, Perplexity: 7.8594CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2463/3236], Loss: 2.0304, Perplexity: 7.6170CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2464/3236], Loss: 2.0329, Perplexity: 7.6360CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2465/3236], Loss: 2.1146, Perplexity: 8.2865CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2466/3236], Loss: 1.9731, Perplexity: 7.1927CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2467/3236], Loss: 2.0681, Perplexity: 7.9095CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2468/3236], Loss: 2.0831, Perplexity: 8.0292CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2469/3236], Loss: 2.2545, Perplexity: 9.5310CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2470/3236], Loss: 2.4384, Perplexity: 11.4546CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2471/3236], Loss: 2.0106, Perplexity: 7.4681CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2472/3236], Loss: 2.0344, Perplexity: 7.6477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2473/3236], Loss: 2.1767, Perplexity: 8.8172CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2474/3236], Loss: 1.9437, Perplexity: 6.9843CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2475/3236], Loss: 1.9958, Perplexity: 7.3581CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2476/3236], Loss: 1.9149, Perplexity: 6.7859CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2477/3236], Loss: 2.0483, Perplexity: 7.7545CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2478/3236], Loss: 1.9518, Perplexity: 7.0414CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2479/3236], Loss: 2.1262, Perplexity: 8.3830CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2480/3236], Loss: 1.9847, Perplexity: 7.2769CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2481/3236], Loss: 2.0433, Perplexity: 7.7157CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2482/3236], Loss: 1.9587, Perplexity: 7.0903CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2483/3236], Loss: 1.9546, Perplexity: 7.0611CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2484/3236], Loss: 2.5660, Perplexity: 13.0135CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2485/3236], Loss: 2.3154, Perplexity: 10.1292CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2486/3236], Loss: 2.2262, Perplexity: 9.2645CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2487/3236], Loss: 1.9598, Perplexity: 7.0980CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2488/3236], Loss: 2.0682, Perplexity: 7.9102CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2489/3236], Loss: 2.1332, Perplexity: 8.4420CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2490/3236], Loss: 2.1822, Perplexity: 8.8655CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2491/3236], Loss: 2.1137, Perplexity: 8.2786CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2492/3236], Loss: 2.0076, Perplexity: 7.4452CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2493/3236], Loss: 2.0321, Perplexity: 7.6302CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2494/3236], Loss: 1.9498, Perplexity: 7.0271CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2495/3236], Loss: 2.2088, Perplexity: 9.1051CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2496/3236], Loss: 2.1380, Perplexity: 8.4824CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2497/3236], Loss: 2.0894, Perplexity: 8.0797CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2498/3236], Loss: 2.1950, Perplexity: 8.9798CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2499/3236], Loss: 1.9909, Perplexity: 7.3224CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2500/3236], Loss: 1.9239, Perplexity: 6.8478\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2501/3236], Loss: 1.9888, Perplexity: 7.3067CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2502/3236], Loss: 2.0500, Perplexity: 7.7677CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2503/3236], Loss: 2.4012, Perplexity: 11.0363CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2504/3236], Loss: 2.0912, Perplexity: 8.0949CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2505/3236], Loss: 2.0202, Perplexity: 7.5402CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2506/3236], Loss: 2.0691, Perplexity: 7.9177CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2507/3236], Loss: 2.0208, Perplexity: 7.5443CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2508/3236], Loss: 2.1791, Perplexity: 8.8387CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2509/3236], Loss: 1.9050, Perplexity: 6.7194CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2510/3236], Loss: 2.1301, Perplexity: 8.4153CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2511/3236], Loss: 2.1061, Perplexity: 8.2163CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2512/3236], Loss: 2.1287, Perplexity: 8.4038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2513/3236], Loss: 2.0775, Perplexity: 7.9843CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2514/3236], Loss: 2.1351, Perplexity: 8.4576CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2515/3236], Loss: 2.0650, Perplexity: 7.8851CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2516/3236], Loss: 2.2849, Perplexity: 9.8243CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2517/3236], Loss: 2.0607, Perplexity: 7.8514CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2518/3236], Loss: 2.3178, Perplexity: 10.1532CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2519/3236], Loss: 2.0849, Perplexity: 8.0436CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2520/3236], Loss: 2.0898, Perplexity: 8.0833CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2521/3236], Loss: 1.9707, Perplexity: 7.1757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2522/3236], Loss: 2.3255, Perplexity: 10.2316CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2523/3236], Loss: 1.9810, Perplexity: 7.2499CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2524/3236], Loss: 2.0134, Perplexity: 7.4885CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2525/3236], Loss: 2.0472, Perplexity: 7.7458CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2526/3236], Loss: 2.2897, Perplexity: 9.8723CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2527/3236], Loss: 2.0704, Perplexity: 7.9278CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2528/3236], Loss: 2.0809, Perplexity: 8.0116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2529/3236], Loss: 2.0240, Perplexity: 7.5687CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2530/3236], Loss: 2.0613, Perplexity: 7.8562CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2531/3236], Loss: 2.0539, Perplexity: 7.7981CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2532/3236], Loss: 2.0988, Perplexity: 8.1567CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2533/3236], Loss: 2.1433, Perplexity: 8.5277CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2534/3236], Loss: 2.0606, Perplexity: 7.8505CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2535/3236], Loss: 2.1643, Perplexity: 8.7085CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2536/3236], Loss: 2.0007, Perplexity: 7.3945CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2537/3236], Loss: 2.0440, Perplexity: 7.7213CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2538/3236], Loss: 2.0306, Perplexity: 7.6185CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2539/3236], Loss: 1.9603, Perplexity: 7.1017CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2540/3236], Loss: 2.0192, Perplexity: 7.5323CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2541/3236], Loss: 2.3050, Perplexity: 10.0239CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2542/3236], Loss: 2.2829, Perplexity: 9.8050CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2543/3236], Loss: 1.8850, Perplexity: 6.5864CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2544/3236], Loss: 2.1907, Perplexity: 8.9411CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2545/3236], Loss: 1.9719, Perplexity: 7.1846CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2546/3236], Loss: 2.0077, Perplexity: 7.4461CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2547/3236], Loss: 2.1543, Perplexity: 8.6216CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2548/3236], Loss: 1.9428, Perplexity: 6.9781CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2549/3236], Loss: 2.0412, Perplexity: 7.7001CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2550/3236], Loss: 2.0174, Perplexity: 7.5186CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2551/3236], Loss: 2.1402, Perplexity: 8.5012CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2552/3236], Loss: 2.0755, Perplexity: 7.9688CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2553/3236], Loss: 2.0192, Perplexity: 7.5327CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2554/3236], Loss: 2.1878, Perplexity: 8.9159CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2555/3236], Loss: 2.0609, Perplexity: 7.8532CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2556/3236], Loss: 2.3751, Perplexity: 10.7519CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2557/3236], Loss: 2.0714, Perplexity: 7.9357CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2558/3236], Loss: 2.0074, Perplexity: 7.4440CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2559/3236], Loss: 2.2406, Perplexity: 9.3990CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2560/3236], Loss: 2.0022, Perplexity: 7.4055CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2561/3236], Loss: 1.9953, Perplexity: 7.3541CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2562/3236], Loss: 2.0649, Perplexity: 7.8847CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2563/3236], Loss: 2.3017, Perplexity: 9.9916CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2564/3236], Loss: 2.0466, Perplexity: 7.7412CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2565/3236], Loss: 2.2296, Perplexity: 9.2958CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2566/3236], Loss: 1.9351, Perplexity: 6.9249CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2567/3236], Loss: 1.9987, Perplexity: 7.3798CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2568/3236], Loss: 1.9655, Perplexity: 7.1384CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2569/3236], Loss: 2.1383, Perplexity: 8.4851CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2570/3236], Loss: 1.9864, Perplexity: 7.2893CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2571/3236], Loss: 2.0713, Perplexity: 7.9350CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2572/3236], Loss: 1.8272, Perplexity: 6.2164CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [2573/3236], Loss: 2.5009, Perplexity: 12.1938CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2574/3236], Loss: 2.3331, Perplexity: 10.3094CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2575/3236], Loss: 2.2371, Perplexity: 9.3664CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2576/3236], Loss: 2.0128, Perplexity: 7.4844CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2577/3236], Loss: 1.9207, Perplexity: 6.8255CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2578/3236], Loss: 1.9902, Perplexity: 7.3170CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2579/3236], Loss: 2.0335, Perplexity: 7.6411CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2580/3236], Loss: 2.0714, Perplexity: 7.9362CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2581/3236], Loss: 2.5715, Perplexity: 13.0852CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2582/3236], Loss: 2.0918, Perplexity: 8.0994CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 36])\n",
      "Epoch [1/1], Step [2583/3236], Loss: 4.1436, Perplexity: 63.0295CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2584/3236], Loss: 1.8999, Perplexity: 6.6851CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2585/3236], Loss: 2.1746, Perplexity: 8.7989CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2586/3236], Loss: 2.1226, Perplexity: 8.3524CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2587/3236], Loss: 2.1590, Perplexity: 8.6626CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2588/3236], Loss: 1.9688, Perplexity: 7.1621CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2589/3236], Loss: 2.3255, Perplexity: 10.2315CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2590/3236], Loss: 2.4211, Perplexity: 11.2580CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2591/3236], Loss: 2.1228, Perplexity: 8.3546CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2592/3236], Loss: 2.2554, Perplexity: 9.5392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2593/3236], Loss: 2.1664, Perplexity: 8.7267CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2594/3236], Loss: 2.0719, Perplexity: 7.9397CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2595/3236], Loss: 2.0446, Perplexity: 7.7257CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2596/3236], Loss: 2.3554, Perplexity: 10.5427CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2597/3236], Loss: 2.1595, Perplexity: 8.6666CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2598/3236], Loss: 1.9325, Perplexity: 6.9069CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2599/3236], Loss: 1.9911, Perplexity: 7.3236CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2600/3236], Loss: 2.0337, Perplexity: 7.6426\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2601/3236], Loss: 2.2825, Perplexity: 9.8011CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2602/3236], Loss: 2.1436, Perplexity: 8.5297CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2603/3236], Loss: 2.3150, Perplexity: 10.1251CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2604/3236], Loss: 2.2142, Perplexity: 9.1545CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2605/3236], Loss: 2.1295, Perplexity: 8.4105CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2606/3236], Loss: 2.1948, Perplexity: 8.9783CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2607/3236], Loss: 2.0563, Perplexity: 7.8171CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2608/3236], Loss: 2.1401, Perplexity: 8.4999CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2609/3236], Loss: 1.9957, Perplexity: 7.3573CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2610/3236], Loss: 2.4666, Perplexity: 11.7826CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2611/3236], Loss: 2.0523, Perplexity: 7.7858CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2612/3236], Loss: 1.9996, Perplexity: 7.3859CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2613/3236], Loss: 1.9721, Perplexity: 7.1857CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2614/3236], Loss: 2.0862, Perplexity: 8.0545CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2615/3236], Loss: 1.9754, Perplexity: 7.2093CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2616/3236], Loss: 2.0231, Perplexity: 7.5616CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2617/3236], Loss: 1.9558, Perplexity: 7.0698CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2618/3236], Loss: 2.1199, Perplexity: 8.3305CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2619/3236], Loss: 1.9768, Perplexity: 7.2197CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2620/3236], Loss: 2.0507, Perplexity: 7.7735CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2621/3236], Loss: 2.0606, Perplexity: 7.8506CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2622/3236], Loss: 2.3504, Perplexity: 10.4895CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2623/3236], Loss: 2.0852, Perplexity: 8.0464CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2624/3236], Loss: 2.1578, Perplexity: 8.6519CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2625/3236], Loss: 1.9479, Perplexity: 7.0141CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2626/3236], Loss: 2.0532, Perplexity: 7.7932CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2627/3236], Loss: 1.9655, Perplexity: 7.1387CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2628/3236], Loss: 2.3149, Perplexity: 10.1237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2629/3236], Loss: 2.0673, Perplexity: 7.9034CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2630/3236], Loss: 1.9173, Perplexity: 6.8025CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2631/3236], Loss: 1.9218, Perplexity: 6.8335CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2632/3236], Loss: 2.0982, Perplexity: 8.1518CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2633/3236], Loss: 2.0256, Perplexity: 7.5807CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2634/3236], Loss: 1.9420, Perplexity: 6.9726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2635/3236], Loss: 2.1317, Perplexity: 8.4290CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2636/3236], Loss: 2.0523, Perplexity: 7.7855CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2637/3236], Loss: 2.1908, Perplexity: 8.9422CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2638/3236], Loss: 2.0900, Perplexity: 8.0853CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2639/3236], Loss: 1.9379, Perplexity: 6.9445CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2640/3236], Loss: 2.1859, Perplexity: 8.8982CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2641/3236], Loss: 2.1073, Perplexity: 8.2262CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2642/3236], Loss: 2.0625, Perplexity: 7.8659CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [2643/3236], Loss: 2.2561, Perplexity: 9.5454CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2644/3236], Loss: 2.2379, Perplexity: 9.3735CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2645/3236], Loss: 1.9707, Perplexity: 7.1757CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2646/3236], Loss: 2.0583, Perplexity: 7.8330CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2647/3236], Loss: 1.9219, Perplexity: 6.8342CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2648/3236], Loss: 2.0164, Perplexity: 7.5114CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2649/3236], Loss: 2.0516, Perplexity: 7.7805CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2650/3236], Loss: 1.9798, Perplexity: 7.2411CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2651/3236], Loss: 2.1008, Perplexity: 8.1726CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2652/3236], Loss: 2.0197, Perplexity: 7.5358CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2653/3236], Loss: 2.4364, Perplexity: 11.4322CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2654/3236], Loss: 1.9763, Perplexity: 7.2159CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2655/3236], Loss: 2.0086, Perplexity: 7.4526CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2656/3236], Loss: 1.9631, Perplexity: 7.1216CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2657/3236], Loss: 2.0632, Perplexity: 7.8712CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2658/3236], Loss: 1.9929, Perplexity: 7.3369CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2659/3236], Loss: 2.2098, Perplexity: 9.1143CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2660/3236], Loss: 2.0342, Perplexity: 7.6462CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2661/3236], Loss: 1.9049, Perplexity: 6.7185CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2662/3236], Loss: 1.9569, Perplexity: 7.0776CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2663/3236], Loss: 2.2407, Perplexity: 9.3999CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2664/3236], Loss: 2.0894, Perplexity: 8.0798CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2665/3236], Loss: 2.0975, Perplexity: 8.1457CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2666/3236], Loss: 1.9908, Perplexity: 7.3211CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2667/3236], Loss: 1.9775, Perplexity: 7.2247CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2668/3236], Loss: 2.0712, Perplexity: 7.9340CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2669/3236], Loss: 2.0972, Perplexity: 8.1430CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2670/3236], Loss: 2.1020, Perplexity: 8.1827CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2671/3236], Loss: 2.1591, Perplexity: 8.6637CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2672/3236], Loss: 2.0161, Perplexity: 7.5091CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2673/3236], Loss: 2.1107, Perplexity: 8.2538CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2674/3236], Loss: 1.9549, Perplexity: 7.0631CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2675/3236], Loss: 2.2864, Perplexity: 9.8392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2676/3236], Loss: 2.0422, Perplexity: 7.7074CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2677/3236], Loss: 2.0132, Perplexity: 7.4872CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [2678/3236], Loss: 2.2512, Perplexity: 9.4992CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2679/3236], Loss: 1.9429, Perplexity: 6.9790CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2680/3236], Loss: 1.9810, Perplexity: 7.2498CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2681/3236], Loss: 2.2833, Perplexity: 9.8090CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2682/3236], Loss: 2.0697, Perplexity: 7.9221CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2683/3236], Loss: 2.0158, Perplexity: 7.5068CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2684/3236], Loss: 2.0597, Perplexity: 7.8433CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2685/3236], Loss: 2.2275, Perplexity: 9.2764CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2686/3236], Loss: 2.0986, Perplexity: 8.1548CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2687/3236], Loss: 2.1789, Perplexity: 8.8367CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2688/3236], Loss: 2.1175, Perplexity: 8.3107CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2689/3236], Loss: 2.1377, Perplexity: 8.4801CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2690/3236], Loss: 2.5422, Perplexity: 12.7076CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2691/3236], Loss: 2.1006, Perplexity: 8.1712CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2692/3236], Loss: 1.9675, Perplexity: 7.1531CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [2693/3236], Loss: 2.9378, Perplexity: 18.8736CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2694/3236], Loss: 2.2101, Perplexity: 9.1168CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2695/3236], Loss: 1.9216, Perplexity: 6.8316CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2696/3236], Loss: 1.9868, Perplexity: 7.2919CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2697/3236], Loss: 2.0063, Perplexity: 7.4359CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2698/3236], Loss: 2.0842, Perplexity: 8.0382CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2699/3236], Loss: 1.9781, Perplexity: 7.2293CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2700/3236], Loss: 2.0241, Perplexity: 7.5696\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2701/3236], Loss: 2.1046, Perplexity: 8.2038CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2702/3236], Loss: 2.0346, Perplexity: 7.6493CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2703/3236], Loss: 2.1637, Perplexity: 8.7036CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2704/3236], Loss: 2.3735, Perplexity: 10.7351CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2705/3236], Loss: 2.1456, Perplexity: 8.5474CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2706/3236], Loss: 1.9703, Perplexity: 7.1731CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2707/3236], Loss: 2.1163, Perplexity: 8.3003CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2708/3236], Loss: 1.9993, Perplexity: 7.3836CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2709/3236], Loss: 2.1875, Perplexity: 8.9127CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2710/3236], Loss: 2.2580, Perplexity: 9.5636CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2711/3236], Loss: 2.0020, Perplexity: 7.4035CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2712/3236], Loss: 2.0218, Perplexity: 7.5522CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2713/3236], Loss: 2.0156, Perplexity: 7.5053CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2714/3236], Loss: 2.0550, Perplexity: 7.8071CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2715/3236], Loss: 2.0633, Perplexity: 7.8715CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2716/3236], Loss: 2.2252, Perplexity: 9.2553CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2717/3236], Loss: 2.0878, Perplexity: 8.0669CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2718/3236], Loss: 1.8721, Perplexity: 6.5021CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2719/3236], Loss: 2.0399, Perplexity: 7.6897CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2720/3236], Loss: 2.2482, Perplexity: 9.4707CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2721/3236], Loss: 2.0246, Perplexity: 7.5733CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [2722/3236], Loss: 2.3073, Perplexity: 10.0475CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2723/3236], Loss: 2.0111, Perplexity: 7.4715CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2724/3236], Loss: 2.1311, Perplexity: 8.4242CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2725/3236], Loss: 2.0907, Perplexity: 8.0908CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [2726/3236], Loss: 2.8497, Perplexity: 17.2826CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2727/3236], Loss: 2.2169, Perplexity: 9.1785CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2728/3236], Loss: 1.8989, Perplexity: 6.6782CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2729/3236], Loss: 2.0502, Perplexity: 7.7696CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2730/3236], Loss: 1.9984, Perplexity: 7.3770CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2731/3236], Loss: 2.0991, Perplexity: 8.1584CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2732/3236], Loss: 2.0490, Perplexity: 7.7599CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2733/3236], Loss: 1.9535, Perplexity: 7.0534CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2734/3236], Loss: 1.9320, Perplexity: 6.9031CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2735/3236], Loss: 2.2785, Perplexity: 9.7619CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2736/3236], Loss: 1.9120, Perplexity: 6.7669CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2737/3236], Loss: 1.9761, Perplexity: 7.2145CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2738/3236], Loss: 1.9703, Perplexity: 7.1728CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2739/3236], Loss: 1.9644, Perplexity: 7.1304CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2740/3236], Loss: 2.0183, Perplexity: 7.5253CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2741/3236], Loss: 2.2262, Perplexity: 9.2648CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2742/3236], Loss: 2.0608, Perplexity: 7.8522CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2743/3236], Loss: 1.9865, Perplexity: 7.2900CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2744/3236], Loss: 2.0192, Perplexity: 7.5325CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2745/3236], Loss: 2.1398, Perplexity: 8.4978CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2746/3236], Loss: 2.0696, Perplexity: 7.9215CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2747/3236], Loss: 2.0100, Perplexity: 7.4631CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2748/3236], Loss: 2.1557, Perplexity: 8.6338CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2749/3236], Loss: 2.2397, Perplexity: 9.3907CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2750/3236], Loss: 2.1268, Perplexity: 8.3881CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2751/3236], Loss: 2.0074, Perplexity: 7.4436CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2752/3236], Loss: 1.9751, Perplexity: 7.2071CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2753/3236], Loss: 2.4106, Perplexity: 11.1405CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2754/3236], Loss: 2.1311, Perplexity: 8.4242CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2755/3236], Loss: 2.1392, Perplexity: 8.4925CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2756/3236], Loss: 2.0614, Perplexity: 7.8571CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2757/3236], Loss: 2.6389, Perplexity: 13.9983CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2758/3236], Loss: 1.9665, Perplexity: 7.1453CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2759/3236], Loss: 1.9301, Perplexity: 6.8902CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2760/3236], Loss: 2.0761, Perplexity: 7.9734CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2761/3236], Loss: 2.3040, Perplexity: 10.0139CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2762/3236], Loss: 1.9331, Perplexity: 6.9112CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2763/3236], Loss: 2.0765, Perplexity: 7.9766CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2764/3236], Loss: 2.2838, Perplexity: 9.8143CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2765/3236], Loss: 2.1367, Perplexity: 8.4717CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2766/3236], Loss: 2.0446, Perplexity: 7.7257CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2767/3236], Loss: 1.9692, Perplexity: 7.1653CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2768/3236], Loss: 1.9214, Perplexity: 6.8303CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 32])\n",
      "Epoch [1/1], Step [2769/3236], Loss: 3.7177, Perplexity: 41.1705CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2770/3236], Loss: 2.2085, Perplexity: 9.1025CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2771/3236], Loss: 1.9742, Perplexity: 7.2009CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 29])\n",
      "Epoch [1/1], Step [2772/3236], Loss: 3.1484, Perplexity: 23.2996CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2773/3236], Loss: 2.0175, Perplexity: 7.5193CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2774/3236], Loss: 2.0284, Perplexity: 7.6022CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2775/3236], Loss: 2.1323, Perplexity: 8.4345CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2776/3236], Loss: 2.0897, Perplexity: 8.0822CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2777/3236], Loss: 2.0072, Perplexity: 7.4424CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2778/3236], Loss: 2.2982, Perplexity: 9.9565CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2779/3236], Loss: 2.0845, Perplexity: 8.0407CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2780/3236], Loss: 2.0578, Perplexity: 7.8286CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2781/3236], Loss: 2.0457, Perplexity: 7.7346CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2782/3236], Loss: 2.0099, Perplexity: 7.4625CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2783/3236], Loss: 1.9782, Perplexity: 7.2296CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2784/3236], Loss: 2.2955, Perplexity: 9.9294CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2785/3236], Loss: 2.0913, Perplexity: 8.0952CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2786/3236], Loss: 2.0432, Perplexity: 7.7154CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2787/3236], Loss: 2.6813, Perplexity: 14.6045CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2788/3236], Loss: 2.2485, Perplexity: 9.4736CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2789/3236], Loss: 2.1052, Perplexity: 8.2086CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2790/3236], Loss: 2.0464, Perplexity: 7.7397CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2791/3236], Loss: 1.9403, Perplexity: 6.9606CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2792/3236], Loss: 2.1698, Perplexity: 8.7564CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [2793/3236], Loss: 2.6349, Perplexity: 13.9423CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2794/3236], Loss: 1.8199, Perplexity: 6.1713CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2795/3236], Loss: 2.4115, Perplexity: 11.1502CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2796/3236], Loss: 2.0248, Perplexity: 7.5749CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2797/3236], Loss: 2.0953, Perplexity: 8.1281CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2798/3236], Loss: 2.2989, Perplexity: 9.9627CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2799/3236], Loss: 2.0690, Perplexity: 7.9171CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2800/3236], Loss: 2.2194, Perplexity: 9.2015\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2801/3236], Loss: 2.0633, Perplexity: 7.8717CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2802/3236], Loss: 2.3393, Perplexity: 10.3738CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2803/3236], Loss: 2.2971, Perplexity: 9.9456CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2804/3236], Loss: 2.1191, Perplexity: 8.3238CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2805/3236], Loss: 2.0182, Perplexity: 7.5250CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2806/3236], Loss: 2.1080, Perplexity: 8.2315CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2807/3236], Loss: 2.0420, Perplexity: 7.7059CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2808/3236], Loss: 1.9502, Perplexity: 7.0299CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2809/3236], Loss: 2.3939, Perplexity: 10.9559CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2810/3236], Loss: 1.9835, Perplexity: 7.2685CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2811/3236], Loss: 2.2172, Perplexity: 9.1816CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2812/3236], Loss: 2.2704, Perplexity: 9.6834CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2813/3236], Loss: 1.9212, Perplexity: 6.8295CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2814/3236], Loss: 2.1263, Perplexity: 8.3840CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2815/3236], Loss: 2.0261, Perplexity: 7.5841CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2816/3236], Loss: 2.2349, Perplexity: 9.3456CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2817/3236], Loss: 2.0206, Perplexity: 7.5430CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2818/3236], Loss: 2.1047, Perplexity: 8.2044CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2819/3236], Loss: 2.0290, Perplexity: 7.6065CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2820/3236], Loss: 2.3678, Perplexity: 10.6735CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2821/3236], Loss: 2.0233, Perplexity: 7.5633CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2822/3236], Loss: 1.9476, Perplexity: 7.0120CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2823/3236], Loss: 2.1433, Perplexity: 8.5278CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2824/3236], Loss: 2.0976, Perplexity: 8.1467CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2825/3236], Loss: 2.0552, Perplexity: 7.8082CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2826/3236], Loss: 2.1954, Perplexity: 8.9835CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2827/3236], Loss: 1.9584, Perplexity: 7.0878CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2828/3236], Loss: 2.2880, Perplexity: 9.8555CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2829/3236], Loss: 1.9078, Perplexity: 6.7385CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2830/3236], Loss: 1.9746, Perplexity: 7.2037CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2831/3236], Loss: 2.2389, Perplexity: 9.3831CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2832/3236], Loss: 2.0425, Perplexity: 7.7099CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2833/3236], Loss: 2.1543, Perplexity: 8.6217CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2834/3236], Loss: 1.9548, Perplexity: 7.0623CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2835/3236], Loss: 2.1072, Perplexity: 8.2253CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2836/3236], Loss: 2.5289, Perplexity: 12.5400CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2837/3236], Loss: 2.0861, Perplexity: 8.0537CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2838/3236], Loss: 1.9682, Perplexity: 7.1575CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2839/3236], Loss: 2.2941, Perplexity: 9.9150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2840/3236], Loss: 2.0682, Perplexity: 7.9103CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2841/3236], Loss: 1.9792, Perplexity: 7.2372CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2842/3236], Loss: 2.1337, Perplexity: 8.4457CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2843/3236], Loss: 2.0710, Perplexity: 7.9326CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2844/3236], Loss: 2.0602, Perplexity: 7.8477CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2845/3236], Loss: 2.0925, Perplexity: 8.1048CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2846/3236], Loss: 2.3320, Perplexity: 10.2985CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2847/3236], Loss: 2.5213, Perplexity: 12.4442CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2848/3236], Loss: 2.1195, Perplexity: 8.3268CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2849/3236], Loss: 2.1107, Perplexity: 8.2540CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2850/3236], Loss: 2.2517, Perplexity: 9.5039CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2851/3236], Loss: 2.0077, Perplexity: 7.4461CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2852/3236], Loss: 1.9624, Perplexity: 7.1166CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2853/3236], Loss: 1.9802, Perplexity: 7.2440CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2854/3236], Loss: 2.0098, Perplexity: 7.4622CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2855/3236], Loss: 2.4137, Perplexity: 11.1753CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 28])\n",
      "Epoch [1/1], Step [2856/3236], Loss: 3.2115, Perplexity: 24.8155CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2857/3236], Loss: 2.0020, Perplexity: 7.4039CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2858/3236], Loss: 2.0585, Perplexity: 7.8340CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2859/3236], Loss: 2.1158, Perplexity: 8.2965CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2860/3236], Loss: 2.0711, Perplexity: 7.9334CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2861/3236], Loss: 2.0010, Perplexity: 7.3967CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2862/3236], Loss: 2.2669, Perplexity: 9.6494CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2863/3236], Loss: 2.1447, Perplexity: 8.5397CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2864/3236], Loss: 2.0774, Perplexity: 7.9840CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2865/3236], Loss: 1.9589, Perplexity: 7.0916CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2866/3236], Loss: 1.9597, Perplexity: 7.0969CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2867/3236], Loss: 2.0374, Perplexity: 7.6703CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2868/3236], Loss: 2.0930, Perplexity: 8.1095CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2869/3236], Loss: 2.0059, Perplexity: 7.4326CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2870/3236], Loss: 1.9055, Perplexity: 6.7230CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2871/3236], Loss: 2.1673, Perplexity: 8.7349CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2872/3236], Loss: 2.0772, Perplexity: 7.9818CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2873/3236], Loss: 2.0188, Perplexity: 7.5295CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2874/3236], Loss: 2.1839, Perplexity: 8.8806CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2875/3236], Loss: 2.0302, Perplexity: 7.6157CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2876/3236], Loss: 2.1450, Perplexity: 8.5416CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [2877/3236], Loss: 2.2109, Perplexity: 9.1237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2878/3236], Loss: 2.1025, Perplexity: 8.1868CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2879/3236], Loss: 2.0525, Perplexity: 7.7874CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2880/3236], Loss: 2.0294, Perplexity: 7.6098CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2881/3236], Loss: 2.0962, Perplexity: 8.1353CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2882/3236], Loss: 2.1463, Perplexity: 8.5532CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2883/3236], Loss: 2.0504, Perplexity: 7.7713CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2884/3236], Loss: 2.1462, Perplexity: 8.5521CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2885/3236], Loss: 1.9802, Perplexity: 7.2444CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2886/3236], Loss: 2.1203, Perplexity: 8.3339CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2887/3236], Loss: 2.4469, Perplexity: 11.5530CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2888/3236], Loss: 2.2503, Perplexity: 9.4910CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2889/3236], Loss: 2.1788, Perplexity: 8.8353CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2890/3236], Loss: 2.1054, Perplexity: 8.2108CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2891/3236], Loss: 2.2925, Perplexity: 9.8998CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2892/3236], Loss: 2.3364, Perplexity: 10.3440CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2893/3236], Loss: 2.1069, Perplexity: 8.2226CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2894/3236], Loss: 2.0208, Perplexity: 7.5446CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2895/3236], Loss: 1.9940, Perplexity: 7.3446CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2896/3236], Loss: 1.9425, Perplexity: 6.9764CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2897/3236], Loss: 2.0824, Perplexity: 8.0236CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2898/3236], Loss: 2.0417, Perplexity: 7.7036CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2899/3236], Loss: 2.3057, Perplexity: 10.0310CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2900/3236], Loss: 2.0398, Perplexity: 7.6890\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2901/3236], Loss: 1.8864, Perplexity: 6.5955CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2902/3236], Loss: 1.9283, Perplexity: 6.8779CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2903/3236], Loss: 2.1014, Perplexity: 8.1775CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2904/3236], Loss: 2.0557, Perplexity: 7.8120CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2905/3236], Loss: 1.9447, Perplexity: 6.9916CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2906/3236], Loss: 2.0457, Perplexity: 7.7347CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2907/3236], Loss: 1.9809, Perplexity: 7.2493CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2908/3236], Loss: 2.6640, Perplexity: 14.3533CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2909/3236], Loss: 2.0740, Perplexity: 7.9566CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2910/3236], Loss: 2.0292, Perplexity: 7.6079CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2911/3236], Loss: 1.9752, Perplexity: 7.2078CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2912/3236], Loss: 2.0076, Perplexity: 7.4451CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2913/3236], Loss: 2.1082, Perplexity: 8.2335CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2914/3236], Loss: 2.0150, Perplexity: 7.5011CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2915/3236], Loss: 2.0187, Perplexity: 7.5286CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2916/3236], Loss: 2.1642, Perplexity: 8.7080CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2917/3236], Loss: 2.0762, Perplexity: 7.9744CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2918/3236], Loss: 1.8876, Perplexity: 6.6035CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2919/3236], Loss: 1.9749, Perplexity: 7.2059CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2920/3236], Loss: 2.1532, Perplexity: 8.6122CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2921/3236], Loss: 2.1170, Perplexity: 8.3063CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2922/3236], Loss: 2.1872, Perplexity: 8.9100CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2923/3236], Loss: 1.9463, Perplexity: 7.0030CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2924/3236], Loss: 2.1583, Perplexity: 8.6560CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2925/3236], Loss: 2.0359, Perplexity: 7.6592CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2926/3236], Loss: 1.9793, Perplexity: 7.2379CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2927/3236], Loss: 2.3496, Perplexity: 10.4810CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2928/3236], Loss: 1.9926, Perplexity: 7.3344CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2929/3236], Loss: 2.1877, Perplexity: 8.9150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2930/3236], Loss: 2.0090, Perplexity: 7.4561CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2931/3236], Loss: 2.1361, Perplexity: 8.4662CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2932/3236], Loss: 2.0299, Perplexity: 7.6136CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2933/3236], Loss: 2.1170, Perplexity: 8.3066CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2934/3236], Loss: 2.0917, Perplexity: 8.0983CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2935/3236], Loss: 2.0083, Perplexity: 7.4506CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2936/3236], Loss: 2.0871, Perplexity: 8.0612CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2937/3236], Loss: 2.2171, Perplexity: 9.1807CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2938/3236], Loss: 1.8811, Perplexity: 6.5609CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2939/3236], Loss: 2.1891, Perplexity: 8.9276CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2940/3236], Loss: 1.9952, Perplexity: 7.3537CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2941/3236], Loss: 1.9600, Perplexity: 7.0994CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2942/3236], Loss: 2.0426, Perplexity: 7.7106CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2943/3236], Loss: 1.8922, Perplexity: 6.6341CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2944/3236], Loss: 2.1164, Perplexity: 8.3014CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2945/3236], Loss: 2.0095, Perplexity: 7.4596CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2946/3236], Loss: 2.4416, Perplexity: 11.4911CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2947/3236], Loss: 2.0214, Perplexity: 7.5490CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 9])\n",
      "Epoch [1/1], Step [2948/3236], Loss: 2.2528, Perplexity: 9.5139CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2949/3236], Loss: 1.9451, Perplexity: 6.9946CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2950/3236], Loss: 2.1129, Perplexity: 8.2720CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2951/3236], Loss: 1.9503, Perplexity: 7.0306CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2952/3236], Loss: 1.9714, Perplexity: 7.1806CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2953/3236], Loss: 2.1145, Perplexity: 8.2856CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2954/3236], Loss: 2.0605, Perplexity: 7.8502CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2955/3236], Loss: 2.0409, Perplexity: 7.6976CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2956/3236], Loss: 2.0337, Perplexity: 7.6425CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2957/3236], Loss: 2.0762, Perplexity: 7.9738CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2958/3236], Loss: 2.0313, Perplexity: 7.6237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2959/3236], Loss: 2.0764, Perplexity: 7.9755CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2960/3236], Loss: 2.0408, Perplexity: 7.6970CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2961/3236], Loss: 2.1254, Perplexity: 8.3766CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2962/3236], Loss: 1.9970, Perplexity: 7.3669CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2963/3236], Loss: 2.0391, Perplexity: 7.6837CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2964/3236], Loss: 2.1695, Perplexity: 8.7541CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2965/3236], Loss: 2.0056, Perplexity: 7.4309CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2966/3236], Loss: 2.0792, Perplexity: 7.9980CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2967/3236], Loss: 2.0250, Perplexity: 7.5759CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2968/3236], Loss: 1.9769, Perplexity: 7.2204CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2969/3236], Loss: 2.0360, Perplexity: 7.6599CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [2970/3236], Loss: 2.7619, Perplexity: 15.8292CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 22])\n",
      "Epoch [1/1], Step [2971/3236], Loss: 2.7941, Perplexity: 16.3472CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2972/3236], Loss: 2.0858, Perplexity: 8.0510CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2973/3236], Loss: 2.0463, Perplexity: 7.7392CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [2974/3236], Loss: 2.2750, Perplexity: 9.7277CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2975/3236], Loss: 2.1494, Perplexity: 8.5799CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2976/3236], Loss: 1.9809, Perplexity: 7.2490CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2977/3236], Loss: 2.0510, Perplexity: 7.7760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2978/3236], Loss: 2.0915, Perplexity: 8.0971CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2979/3236], Loss: 2.2056, Perplexity: 9.0760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2980/3236], Loss: 1.9486, Perplexity: 7.0190CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [2981/3236], Loss: 2.7868, Perplexity: 16.2298CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2982/3236], Loss: 1.9600, Perplexity: 7.0995CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2983/3236], Loss: 1.9445, Perplexity: 6.9901CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [2984/3236], Loss: 2.1079, Perplexity: 8.2306CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2985/3236], Loss: 1.9844, Perplexity: 7.2745CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2986/3236], Loss: 1.9780, Perplexity: 7.2281CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [2987/3236], Loss: 1.9938, Perplexity: 7.3432CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [2988/3236], Loss: 2.5846, Perplexity: 13.2585CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [2989/3236], Loss: 2.3652, Perplexity: 10.6457CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2990/3236], Loss: 2.0456, Perplexity: 7.7338CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2991/3236], Loss: 2.1471, Perplexity: 8.5602CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2992/3236], Loss: 1.9699, Perplexity: 7.1697CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2993/3236], Loss: 2.1203, Perplexity: 8.3335CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2994/3236], Loss: 2.1705, Perplexity: 8.7630CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2995/3236], Loss: 2.1343, Perplexity: 8.4512CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [2996/3236], Loss: 2.1044, Perplexity: 8.2026CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [2997/3236], Loss: 2.0962, Perplexity: 8.1349CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [2998/3236], Loss: 2.2081, Perplexity: 9.0986CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [2999/3236], Loss: 2.1213, Perplexity: 8.3416CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3000/3236], Loss: 2.0491, Perplexity: 7.7608\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3001/3236], Loss: 2.0666, Perplexity: 7.8982CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3002/3236], Loss: 1.9091, Perplexity: 6.7467CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3003/3236], Loss: 2.1621, Perplexity: 8.6894CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [3004/3236], Loss: 2.4432, Perplexity: 11.5103CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3005/3236], Loss: 1.9010, Perplexity: 6.6925CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3006/3236], Loss: 1.9669, Perplexity: 7.1486CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3007/3236], Loss: 1.9151, Perplexity: 6.7875CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [3008/3236], Loss: 2.6024, Perplexity: 13.4957CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3009/3236], Loss: 1.9867, Perplexity: 7.2913CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3010/3236], Loss: 2.1115, Perplexity: 8.2606CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3011/3236], Loss: 2.1047, Perplexity: 8.2043CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3012/3236], Loss: 1.9994, Perplexity: 7.3847CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3013/3236], Loss: 1.9467, Perplexity: 7.0054CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3014/3236], Loss: 2.3666, Perplexity: 10.6614CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3015/3236], Loss: 1.9103, Perplexity: 6.7550CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3016/3236], Loss: 1.9998, Perplexity: 7.3873CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3017/3236], Loss: 2.1241, Perplexity: 8.3650CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 24])\n",
      "Epoch [1/1], Step [3018/3236], Loss: 3.0580, Perplexity: 21.2846CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3019/3236], Loss: 1.9880, Perplexity: 7.3012CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3020/3236], Loss: 2.1564, Perplexity: 8.6403CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3021/3236], Loss: 2.3523, Perplexity: 10.5096CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3022/3236], Loss: 2.4586, Perplexity: 11.6883CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3023/3236], Loss: 2.0090, Perplexity: 7.4556CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3024/3236], Loss: 2.2102, Perplexity: 9.1176CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3025/3236], Loss: 1.9880, Perplexity: 7.3007CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3026/3236], Loss: 2.0613, Perplexity: 7.8565CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3027/3236], Loss: 1.9876, Perplexity: 7.2983CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3028/3236], Loss: 2.1570, Perplexity: 8.6449CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3029/3236], Loss: 1.9882, Perplexity: 7.3023CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3030/3236], Loss: 1.9596, Perplexity: 7.0967CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3031/3236], Loss: 1.9789, Perplexity: 7.2348CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3032/3236], Loss: 1.9500, Perplexity: 7.0286CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3033/3236], Loss: 1.9151, Perplexity: 6.7875CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3034/3236], Loss: 2.0313, Perplexity: 7.6243CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3035/3236], Loss: 2.0147, Perplexity: 7.4985CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [3036/3236], Loss: 2.7704, Perplexity: 15.9649CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3037/3236], Loss: 2.3284, Perplexity: 10.2616CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [3038/3236], Loss: 2.8749, Perplexity: 17.7238CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3039/3236], Loss: 1.9734, Perplexity: 7.1951CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3040/3236], Loss: 1.9374, Perplexity: 6.9410CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3041/3236], Loss: 1.9656, Perplexity: 7.1391CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3042/3236], Loss: 2.0754, Perplexity: 7.9675CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3043/3236], Loss: 2.3548, Perplexity: 10.5359CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3044/3236], Loss: 2.1278, Perplexity: 8.3965CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3045/3236], Loss: 2.1043, Perplexity: 8.2016CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [3046/3236], Loss: 2.2301, Perplexity: 9.3004CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3047/3236], Loss: 2.0252, Perplexity: 7.5778CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3048/3236], Loss: 1.9351, Perplexity: 6.9245CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [3049/3236], Loss: 2.1758, Perplexity: 8.8092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3050/3236], Loss: 2.1540, Perplexity: 8.6189CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3051/3236], Loss: 1.9581, Perplexity: 7.0862CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3052/3236], Loss: 1.9426, Perplexity: 6.9771CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3053/3236], Loss: 2.0031, Perplexity: 7.4116CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3054/3236], Loss: 2.1413, Perplexity: 8.5107CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3055/3236], Loss: 1.9825, Perplexity: 7.2609CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3056/3236], Loss: 2.3165, Perplexity: 10.1404CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3057/3236], Loss: 2.1794, Perplexity: 8.8414CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3058/3236], Loss: 1.9887, Perplexity: 7.3057CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3059/3236], Loss: 1.9990, Perplexity: 7.3813CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [3060/3236], Loss: 2.1452, Perplexity: 8.5440CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3061/3236], Loss: 1.9745, Perplexity: 7.2028CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3062/3236], Loss: 2.1402, Perplexity: 8.5011CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [3063/3236], Loss: 2.5396, Perplexity: 12.6747CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3064/3236], Loss: 1.9621, Perplexity: 7.1143CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3065/3236], Loss: 2.0852, Perplexity: 8.0464CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3066/3236], Loss: 2.0109, Perplexity: 7.4697CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [3067/3236], Loss: 2.5998, Perplexity: 13.4614CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [3068/3236], Loss: 2.2429, Perplexity: 9.4207CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3069/3236], Loss: 2.0208, Perplexity: 7.5446CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3070/3236], Loss: 1.9790, Perplexity: 7.2353CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3071/3236], Loss: 2.0520, Perplexity: 7.7831CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3072/3236], Loss: 1.9236, Perplexity: 6.8457CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [3073/3236], Loss: 2.7639, Perplexity: 15.8621CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3074/3236], Loss: 2.0213, Perplexity: 7.5484CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3075/3236], Loss: 2.0635, Perplexity: 7.8735CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3076/3236], Loss: 2.0150, Perplexity: 7.5010CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3077/3236], Loss: 2.0533, Perplexity: 7.7936CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3078/3236], Loss: 2.0629, Perplexity: 7.8685CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3079/3236], Loss: 2.1003, Perplexity: 8.1688CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3080/3236], Loss: 2.1562, Perplexity: 8.6385CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3081/3236], Loss: 2.0999, Perplexity: 8.1652CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3082/3236], Loss: 1.9549, Perplexity: 7.0634CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3083/3236], Loss: 2.0252, Perplexity: 7.5778CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3084/3236], Loss: 2.0047, Perplexity: 7.4240CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3085/3236], Loss: 1.9863, Perplexity: 7.2886CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3086/3236], Loss: 2.1203, Perplexity: 8.3333CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3087/3236], Loss: 1.9975, Perplexity: 7.3710CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3088/3236], Loss: 2.1113, Perplexity: 8.2594CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3089/3236], Loss: 2.0109, Perplexity: 7.4700CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3090/3236], Loss: 2.0845, Perplexity: 8.0406CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3091/3236], Loss: 2.0479, Perplexity: 7.7513CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3092/3236], Loss: 2.0828, Perplexity: 8.0272CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3093/3236], Loss: 1.9851, Perplexity: 7.2795CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3094/3236], Loss: 1.9184, Perplexity: 6.8097CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [3095/3236], Loss: 2.0904, Perplexity: 8.0884CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3096/3236], Loss: 2.1792, Perplexity: 8.8390CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 23])\n",
      "Epoch [1/1], Step [3097/3236], Loss: 2.8572, Perplexity: 17.4125CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3098/3236], Loss: 2.0584, Perplexity: 7.8336CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [3099/3236], Loss: 2.5017, Perplexity: 12.2037CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3100/3236], Loss: 2.1236, Perplexity: 8.3610\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3101/3236], Loss: 2.0972, Perplexity: 8.1434CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3102/3236], Loss: 1.9828, Perplexity: 7.2634CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3103/3236], Loss: 2.1479, Perplexity: 8.5670CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3104/3236], Loss: 1.9868, Perplexity: 7.2921CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3105/3236], Loss: 2.0742, Perplexity: 7.9584CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3106/3236], Loss: 2.3602, Perplexity: 10.5935CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3107/3236], Loss: 2.0287, Perplexity: 7.6039CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3108/3236], Loss: 2.0396, Perplexity: 7.6879CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3109/3236], Loss: 2.0342, Perplexity: 7.6463CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3110/3236], Loss: 1.9480, Perplexity: 7.0145CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3111/3236], Loss: 2.3042, Perplexity: 10.0158CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3112/3236], Loss: 2.1192, Perplexity: 8.3246CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3113/3236], Loss: 1.8690, Perplexity: 6.4816CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3114/3236], Loss: 2.1083, Perplexity: 8.2340CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3115/3236], Loss: 2.1241, Perplexity: 8.3657CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3116/3236], Loss: 1.9829, Perplexity: 7.2640CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 24])\n",
      "Epoch [1/1], Step [3117/3236], Loss: 2.8420, Perplexity: 17.1499CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3118/3236], Loss: 2.3162, Perplexity: 10.1366CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3119/3236], Loss: 2.0793, Perplexity: 7.9987CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3120/3236], Loss: 2.1481, Perplexity: 8.5683CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3121/3236], Loss: 1.9542, Perplexity: 7.0583CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3122/3236], Loss: 1.9450, Perplexity: 6.9934CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3123/3236], Loss: 2.1416, Perplexity: 8.5132CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3124/3236], Loss: 2.0061, Perplexity: 7.4345CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3125/3236], Loss: 1.9659, Perplexity: 7.1411CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3126/3236], Loss: 1.9112, Perplexity: 6.7615CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3127/3236], Loss: 2.1826, Perplexity: 8.8690CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3128/3236], Loss: 2.2680, Perplexity: 9.6598CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3129/3236], Loss: 1.9918, Perplexity: 7.3290CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3130/3236], Loss: 2.0309, Perplexity: 7.6209CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3131/3236], Loss: 1.9481, Perplexity: 7.0150CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3132/3236], Loss: 1.9214, Perplexity: 6.8307CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3133/3236], Loss: 1.9744, Perplexity: 7.2024CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3134/3236], Loss: 1.9790, Perplexity: 7.2356CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3135/3236], Loss: 2.0425, Perplexity: 7.7100CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3136/3236], Loss: 1.9893, Perplexity: 7.3106CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3137/3236], Loss: 2.0760, Perplexity: 7.9723CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3138/3236], Loss: 2.2402, Perplexity: 9.3948CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3139/3236], Loss: 2.0569, Perplexity: 7.8220CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3140/3236], Loss: 1.9376, Perplexity: 6.9421CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3141/3236], Loss: 1.9052, Perplexity: 6.7209CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3142/3236], Loss: 2.2383, Perplexity: 9.3778CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3143/3236], Loss: 2.1693, Perplexity: 8.7521CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3144/3236], Loss: 2.3072, Perplexity: 10.0459CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3145/3236], Loss: 2.1070, Perplexity: 8.2237CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3146/3236], Loss: 2.0161, Perplexity: 7.5090CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3147/3236], Loss: 1.9702, Perplexity: 7.1718CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3148/3236], Loss: 2.0415, Perplexity: 7.7018CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3149/3236], Loss: 2.0158, Perplexity: 7.5068CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3150/3236], Loss: 1.9602, Perplexity: 7.1007CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3151/3236], Loss: 2.0299, Perplexity: 7.6129CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3152/3236], Loss: 2.2485, Perplexity: 9.4732CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3153/3236], Loss: 1.9982, Perplexity: 7.3760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 21])\n",
      "Epoch [1/1], Step [3154/3236], Loss: 2.8406, Perplexity: 17.1268CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3155/3236], Loss: 2.1920, Perplexity: 8.9531CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [3156/3236], Loss: 2.4289, Perplexity: 11.3460CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [3157/3236], Loss: 2.5258, Perplexity: 12.5003CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3158/3236], Loss: 1.9642, Perplexity: 7.1293CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3159/3236], Loss: 2.0610, Perplexity: 7.8536CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3160/3236], Loss: 1.9560, Perplexity: 7.0713CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3161/3236], Loss: 1.9846, Perplexity: 7.2760CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3162/3236], Loss: 2.0276, Perplexity: 7.5961CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 18])\n",
      "Epoch [1/1], Step [3163/3236], Loss: 2.4650, Perplexity: 11.7638CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3164/3236], Loss: 1.9331, Perplexity: 6.9112CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [3165/3236], Loss: 2.0980, Perplexity: 8.1502CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3166/3236], Loss: 2.0676, Perplexity: 7.9061CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3167/3236], Loss: 1.9492, Perplexity: 7.0228CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3168/3236], Loss: 2.0152, Perplexity: 7.5026CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 19])\n",
      "Epoch [1/1], Step [3169/3236], Loss: 2.5062, Perplexity: 12.2584CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3170/3236], Loss: 1.9312, Perplexity: 6.8977CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3171/3236], Loss: 1.9614, Perplexity: 7.1092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3172/3236], Loss: 2.0649, Perplexity: 7.8848CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3173/3236], Loss: 1.9972, Perplexity: 7.3686CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3174/3236], Loss: 2.0435, Perplexity: 7.7176CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3175/3236], Loss: 1.9872, Perplexity: 7.2951CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3176/3236], Loss: 2.0744, Perplexity: 7.9594CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3177/3236], Loss: 2.2780, Perplexity: 9.7576CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3178/3236], Loss: 2.1125, Perplexity: 8.2685CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3179/3236], Loss: 2.3445, Perplexity: 10.4278CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3180/3236], Loss: 1.9801, Perplexity: 7.2435CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3181/3236], Loss: 1.9574, Perplexity: 7.0808CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3182/3236], Loss: 2.2287, Perplexity: 9.2874CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3183/3236], Loss: 1.9773, Perplexity: 7.2233CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 17])\n",
      "Epoch [1/1], Step [3184/3236], Loss: 2.3308, Perplexity: 10.2858CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3185/3236], Loss: 2.0580, Perplexity: 7.8306CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3186/3236], Loss: 2.3525, Perplexity: 10.5123CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3187/3236], Loss: 1.9355, Perplexity: 6.9276CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3188/3236], Loss: 2.0400, Perplexity: 7.6905CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3189/3236], Loss: 1.9478, Perplexity: 7.0129CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3190/3236], Loss: 1.9549, Perplexity: 7.0633CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3191/3236], Loss: 1.7893, Perplexity: 5.9850CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3192/3236], Loss: 2.0485, Perplexity: 7.7565CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3193/3236], Loss: 1.9737, Perplexity: 7.1970CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3194/3236], Loss: 2.1737, Perplexity: 8.7908CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3195/3236], Loss: 2.0122, Perplexity: 7.4797CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3196/3236], Loss: 1.9328, Perplexity: 6.9088CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3197/3236], Loss: 2.2645, Perplexity: 9.6262CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3198/3236], Loss: 1.9446, Perplexity: 6.9908CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3199/3236], Loss: 2.0010, Perplexity: 7.3963CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3200/3236], Loss: 2.1227, Perplexity: 8.3536\n",
      "CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3201/3236], Loss: 2.0113, Perplexity: 7.4730CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3202/3236], Loss: 2.1081, Perplexity: 8.2326CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3203/3236], Loss: 2.0599, Perplexity: 7.8449CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3204/3236], Loss: 2.1052, Perplexity: 8.2090CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3205/3236], Loss: 2.0059, Perplexity: 7.4324CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3206/3236], Loss: 1.9627, Perplexity: 7.1182CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3207/3236], Loss: 2.1306, Perplexity: 8.4201CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3208/3236], Loss: 2.0537, Perplexity: 7.7970CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3209/3236], Loss: 2.1957, Perplexity: 8.9866CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3210/3236], Loss: 2.1164, Perplexity: 8.3010CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3211/3236], Loss: 2.0552, Perplexity: 7.8088CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3212/3236], Loss: 2.0366, Perplexity: 7.6646CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3213/3236], Loss: 1.9822, Perplexity: 7.2587CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3214/3236], Loss: 1.9492, Perplexity: 7.0233CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3215/3236], Loss: 1.9951, Perplexity: 7.3529CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 10])\n",
      "Epoch [1/1], Step [3216/3236], Loss: 2.4250, Perplexity: 11.3019CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3217/3236], Loss: 1.9953, Perplexity: 7.3541CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3218/3236], Loss: 2.0208, Perplexity: 7.5443CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3219/3236], Loss: 2.0275, Perplexity: 7.5951CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3220/3236], Loss: 2.0224, Perplexity: 7.5568CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3221/3236], Loss: 1.9265, Perplexity: 6.8651CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 26])\n",
      "Epoch [1/1], Step [3222/3236], Loss: 3.2199, Perplexity: 25.0259CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3223/3236], Loss: 2.1174, Perplexity: 8.3092CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3224/3236], Loss: 2.0696, Perplexity: 7.9213CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 16])\n",
      "Epoch [1/1], Step [3225/3236], Loss: 2.3634, Perplexity: 10.6270CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3226/3236], Loss: 1.9066, Perplexity: 6.7301CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 20])\n",
      "Epoch [1/1], Step [3227/3236], Loss: 2.6225, Perplexity: 13.7703CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 15])\n",
      "Epoch [1/1], Step [3228/3236], Loss: 2.1279, Perplexity: 8.3976CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3229/3236], Loss: 2.0927, Perplexity: 8.1068CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3230/3236], Loss: 1.9861, Perplexity: 7.2871CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3231/3236], Loss: 2.0192, Perplexity: 7.5322CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3232/3236], Loss: 2.0171, Perplexity: 7.5162CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 12])\n",
      "Epoch [1/1], Step [3233/3236], Loss: 1.8622, Perplexity: 6.4380CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 11])\n",
      "Epoch [1/1], Step [3234/3236], Loss: 2.0581, Perplexity: 7.8312CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 13])\n",
      "Epoch [1/1], Step [3235/3236], Loss: 1.9572, Perplexity: 7.0795CNN features: torch.Size([128, 512]) and captions: torch.Size([128, 14])\n",
      "Epoch [1/1], Step [3236/3236], Loss: 2.0710, Perplexity: 7.9328"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        print ('CNN features: {0} and captions: {1}'.format(features.shape, captions.shape))\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "#             to save intermediate models after 100 steps, so as to obtain quicker feedbacks\n",
    "#             torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-step-v3-%d.pkl' % i_step))\n",
    "#             torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-step-v3-%d.pkl' % i_step))\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-v1-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-v1-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
